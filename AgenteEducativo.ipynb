{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generador de Contenido Educativo basado en LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Descargamos e importamos las librerías necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install backoff\n",
        "!pip install python-docx\n",
        "!pip install PyPDF2\n",
        "!pip install nltk\n",
        "!pip install markdown-it-py python-docx  \n",
        "!pip install streamlit\n",
        "!pip install ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "import time\n",
        "import json\n",
        "import logging\n",
        "from typing import Dict, List, Any, Optional, Union\n",
        "import backoff\n",
        "import re\n",
        "\n",
        "# Bibliotecas para procesamiento de documentos\n",
        "import PyPDF2\n",
        "import docx\n",
        "\n",
        "# Bibliotecas para generación de texto\n",
        "import pypandoc\n",
        "import markdown\n",
        "from markdown_it import MarkdownIt\n",
        "from docx import Document\n",
        "from docx.shared import Pt\n",
        "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
        "\n",
        "#Bibliotecas para procesamiento de texto\n",
        "\n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Bibliotecas para visualización\n",
        "from IPython.display import display, HTML, FileLink, clear_output\n",
        "import ipywidgets as widgets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comenzamos inicializando la configuración \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Config:\n",
        "  def __init__(self):\n",
        "    # Configuración para el LLM y las plantillas\n",
        "    self.gemini_model = 'gemini-2.0-flash-001'  # Modelo de Google Gemini\n",
        "    self.llm_tokens_per_minute = 50000  # Límite de tokens por minuto\n",
        "    self.llm_max_tokens_per_request = 4000  # Máximo tokens por solicitud\n",
        "    self.google_api_key = os.environ['GOOGLE_API_KEY']\n",
        "    self.prompt_templates_path = \"prompts.json\"  # Archivo JSON con las plantillas de prompt\n",
        "    # Parámetros para la evaluación (pueden extenderse)\n",
        "    self.readability_threshold = 60.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creamos el rate limit para evitar que se bloquee la ejecución del código\n",
        "y definimos la clase para el manejo de la API de Gemini\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbT4ldvj08Er"
      },
      "outputs": [],
      "source": [
        "\n",
        "class RateLimiter:\n",
        "    \"\"\"Implementa limitación de tasa para llamadas a la API.\"\"\"\n",
        "\n",
        "    def __init__(self, tokens_per_minute: int, max_tokens_per_request: int):\n",
        "        self.tokens_per_minute = tokens_per_minute\n",
        "        self.max_tokens_per_request = max_tokens_per_request\n",
        "        self.tokens_used_in_minute = 0\n",
        "        self.last_reset = time.time()\n",
        "\n",
        "    def wait_if_needed(self, tokens: int) -> None:\n",
        "        \"\"\"Espera si es necesario para respetar los límites de tasa.\"\"\"\n",
        "        # Verificar si ha pasado un minuto desde el último reset\n",
        "        now = time.time()\n",
        "        if now - self.last_reset >= 60:\n",
        "            self.tokens_used_in_minute = 0\n",
        "            self.last_reset = now\n",
        "\n",
        "        # Verificar si estamos por encima del límite de tokens por minuto\n",
        "        if self.tokens_used_in_minute + tokens > self.tokens_per_minute:\n",
        "            # Calcular el tiempo que tenemos que esperar\n",
        "            time_to_wait = 60 - (now - self.last_reset)\n",
        "            if time_to_wait > 0:\n",
        "                time.sleep(time_to_wait)\n",
        "                self.tokens_used_in_minute = tokens\n",
        "                self.last_reset = time.time()\n",
        "        else:\n",
        "            self.tokens_used_in_minute += tokens\n",
        "\n",
        "class LLMEngine:\n",
        "    \"\"\"Gestiona la interacción con Google Gemini API.\"\"\"\n",
        "\n",
        "    def __init__(self, config: Config):\n",
        "        \"\"\"Inicializa el motor LLM con la configuración especificada.\"\"\"\n",
        "        self.config = config\n",
        "        self.logger = logging.getLogger(\"educational_agent.llm_engine\")\n",
        "\n",
        "        # Configurar Gemini API\n",
        "        genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
        "        self.model = genai.GenerativeModel(self.config.gemini_model)\n",
        "\n",
        "        # Configurar el limitador de tasa\n",
        "        self.rate_limiter = RateLimiter(\n",
        "            tokens_per_minute=self.config.llm_tokens_per_minute,\n",
        "            max_tokens_per_request=self.config.llm_max_tokens_per_request\n",
        "        )\n",
        "\n",
        "        # Cargar las plantillas de prompts\n",
        "        self.prompt_templates = self._load_prompt_templates()\n",
        "\n",
        "    def _load_prompt_templates(self) -> Dict[str, str]:\n",
        "        \"\"\"Carga las plantillas de prompts desde un archivo.\"\"\"\n",
        "        try:\n",
        "            with open(self.config.prompt_templates_path, 'r') as f:\n",
        "                return json.load(f)\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"No se pudieron cargar las plantillas: {str(e)}\")\n",
        "            # Plantillas por defecto\n",
        "            return {\n",
        "                \"lecture_notes\": \"\"\"Genera notas de clase detalladas para el tema: {topic_title}.\n",
        "                                  Incluye los siguientes subtemas: {subtopics}.\n",
        "                                  Las notas deben incluir definiciones, explicaciones claras, ejemplos y casos de aplicación.\"\"\",\n",
        "\n",
        "                \"practice_problems\": \"\"\"Crea problemas de práctica con soluciones paso a paso para el tema: {topic_title}.\n",
        "                                      Los problemas deben cubrir: {subtopics}.\n",
        "                                      Incluye problemas de distintos niveles de dificultad.\"\"\",\n",
        "\n",
        "                \"discussion_questions\": \"\"\"Genera preguntas para discusión sobre el tema: {topic_title}, considerando: {subtopics}.\n",
        "                                        Las preguntas deben promover el pensamiento crítico y el análisis profundo.\"\"\",\n",
        "\n",
        "                \"learning_objectives\": \"\"\"Crea objetivos de aprendizaje específicos y medibles para el tema: {topic_title}.\n",
        "                                       Considera los siguientes subtemas: {subtopics}.\n",
        "                                       Usa verbos de la taxonomía de Bloom apropiados.\"\"\",\n",
        "\n",
        "                \"suggested_resources\": \"\"\"Sugiere recursos de aprendizaje adicionales para el tema: {topic_title}.\n",
        "                                       Incluye libros, artículos, videos, cursos en línea y otros materiales relevantes para: {subtopics}.\"\"\"\n",
        "            }\n",
        "\n",
        "    @backoff.on_exception(\n",
        "        backoff.expo,\n",
        "        Exception,\n",
        "        max_tries=3,\n",
        "        jitter=backoff.full_jitter\n",
        "    )\n",
        "    def generate_content(self, prompt: str, max_tokens: int = 1000) -> str:\n",
        "        \"\"\"\n",
        "        Genera contenido llamando a la API de Google Gemini.\n",
        "\n",
        "        Args:\n",
        "            prompt: Instrucción para el modelo\n",
        "            max_tokens: Máximo número de tokens a generar\n",
        "\n",
        "        Returns:\n",
        "            Texto generado por el LLM\n",
        "        \"\"\"\n",
        "        self.logger.debug(f\"Generando contenido con prompt: {prompt[:100]}...\")\n",
        "\n",
        "        # Estimar tokens en el prompt (aproximado)\n",
        "        prompt_tokens = len(prompt.split())\n",
        "        response_tokens = max_tokens\n",
        "        total_tokens = prompt_tokens + response_tokens\n",
        "\n",
        "        # Esperar si es necesario para respetar límites de tasa\n",
        "        self.rate_limiter.wait_if_needed(total_tokens)\n",
        "\n",
        "        try:\n",
        "            # Agregar un sistema de instrucciones\n",
        "            system_instruction = \"Eres un asistente educativo experto en crear materiales didácticos de alta calidad para cursos universitarios. Tu tarea es generar contenido educativo claro, preciso y bien estructurado.\"\n",
        "\n",
        "            # Configurar generación con Gemini\n",
        "            generation_config = {\n",
        "                \"max_output_tokens\": max_tokens,\n",
        "                \"temperature\": 0.7,\n",
        "                \"top_p\": 0.9,\n",
        "                \"top_k\": 40\n",
        "            }\n",
        "\n",
        "            # Llamar a la API de Gemini\n",
        "            response = self.model.generate_content(\n",
        "                contents=[\n",
        "                    {\"role\": \"user\", \"parts\": [{\"text\": system_instruction + \"\\n\\n\" + prompt}]}\n",
        "                ],\n",
        "                generation_config=generation_config\n",
        "            )\n",
        "\n",
        "            # Extraer el texto generado\n",
        "            generated_text = response.text\n",
        "\n",
        "            return generated_text\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error al generar contenido con Gemini: {str(e)}\")\n",
        "            raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a crear la clase que nos permitirá crear el contenido educativo, tales como:\n",
        "\n",
        "- Notas de clase que explican en detalle cada tema.\n",
        "- Problemas de práctica con soluciones paso a paso.\n",
        "- Preguntas para discusión que estimulan el pensamiento crítico.\n",
        "- Objetivos de aprendizaje claros y medibles.\n",
        "- Recursos adicionales sugeridos que complementan el estudio.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nKplizrd1IQo"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Módulo para generar los diferentes tipos de contenido educativo\n",
        "class ContentGenerator:\n",
        "    \"\"\"Genera contenido educativo utilizando un motor LLM.\"\"\"\n",
        "\n",
        "    def __init__(self, llm_engine: LLMEngine, config: Config):\n",
        "        \"\"\"Inicializa el generador de contenido.\"\"\"\n",
        "        self.llm_engine = llm_engine\n",
        "        self.config = config\n",
        "        self.logger = logging.getLogger(\"educational_agent.content_generator\")\n",
        "\n",
        "    def generate_all_materials(self, syllabus_data: Dict[str, Any]) -> Dict[str, Dict[str, str]]:\n",
        "        \"\"\"\n",
        "        Genera todos los materiales didácticos para cada tema del programa.\n",
        "\n",
        "        Args:\n",
        "            syllabus_data: Datos estructurados del programa de curso\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con todos los materiales generados por tema\n",
        "        \"\"\"\n",
        "        all_content = {}\n",
        "\n",
        "        # Obtener información del curso para contexto\n",
        "        course_context = {\n",
        "            \"course_title\": syllabus_data[\"course_title\"],\n",
        "            \"course_code\": syllabus_data[\"course_code\"],\n",
        "            \"course_description\": syllabus_data[\"description\"],\n",
        "            \"course_objectives\": syllabus_data[\"objectives\"]\n",
        "        }\n",
        "\n",
        "        # Generar contenido para cada tema\n",
        "        for topic in syllabus_data[\"topics\"]:\n",
        "            topic_id = topic[\"id\"]\n",
        "            self.logger.info(f\"Generando contenido para el tema {topic_id}: {topic['title']}\")\n",
        "\n",
        "            # Generar los diferentes tipos de contenido\n",
        "            topic_content = {\n",
        "                \"lecture_notes\": self.generate_lecture_notes(topic, course_context),\n",
        "                \"practice_problems\": self.generate_practice_problems(topic, course_context),\n",
        "                \"discussion_questions\": self.generate_discussion_questions(topic, course_context),\n",
        "                \"learning_objectives\": self.generate_learning_objectives(topic, course_context),\n",
        "                \"suggested_resources\": self.generate_suggested_resources(topic, course_context)\n",
        "            }\n",
        "\n",
        "            all_content[topic_id] = topic_content\n",
        "\n",
        "        return all_content\n",
        "\n",
        "    def generate_lecture_notes(self, topic: Dict[str, Any], course_context: Dict[str, Any]) -> str:\n",
        "        \"\"\"Genera notas de clase para un tema específico.\"\"\"\n",
        "        self.logger.info(f\"Generando notas de clase para: {topic['title']}\")\n",
        "\n",
        "        # Construir el prompt usando la plantilla\n",
        "        prompt_template = self.llm_engine.prompt_templates[\"lecture_notes\"]\n",
        "        subtopics_text = \", \".join(topic[\"subtopics\"])\n",
        "\n",
        "        prompt = prompt_template.format(\n",
        "            topic_title=topic[\"title\"],\n",
        "            subtopics=subtopics_text\n",
        "        )\n",
        "\n",
        "        # Añadir contexto del curso\n",
        "        course_context_text = f\"\"\"\n",
        "        Información del curso:\n",
        "        - Título: {course_context['course_title']}\n",
        "        - Código: {course_context['course_code']}\n",
        "        - Descripción: {course_context['course_description']}\n",
        "\n",
        "        Genera notas de clase completas y detalladas que cubran el tema a profundidad.\n",
        "        Usa un estilo académico pero claro, incluyendo definiciones precisas, ejemplos prácticos,\n",
        "        y casos de aplicación relevantes. Organiza el contenido de manera lógica y estructurada.\n",
        "        \"\"\"\n",
        "\n",
        "        final_prompt = course_context_text + \"\\n\\n\" + prompt\n",
        "\n",
        "        # Generar el contenido con un límite mayor de tokens\n",
        "        content = self.llm_engine.generate_content(final_prompt, max_tokens=4000)\n",
        "\n",
        "        return content\n",
        "\n",
        "    def generate_practice_problems(self, topic: Dict[str, Any], course_context: Dict[str, Any]) -> str:\n",
        "        \"\"\"Genera problemas de práctica para un tema específico.\"\"\"\n",
        "        self.logger.info(f\"Generando problemas de práctica para: {topic['title']}\")\n",
        "\n",
        "        # Construir el prompt usando la plantilla\n",
        "        prompt_template = self.llm_engine.prompt_templates[\"practice_problems\"]\n",
        "        subtopics_text = \", \".join(topic[\"subtopics\"])\n",
        "\n",
        "        prompt = prompt_template.format(\n",
        "            topic_title=topic[\"title\"],\n",
        "            subtopics=subtopics_text\n",
        "        )\n",
        "\n",
        "        # Añadir contexto y instrucciones específicas\n",
        "        additional_context = f\"\"\"\n",
        "        Para el curso: {course_context['course_title']} ({course_context['course_code']})\n",
        "\n",
        "        Genera un conjunto de problemas de práctica que cubran todos los aspectos importantes del tema.\n",
        "        Incluye:\n",
        "        1. Al menos 5 problemas de diferentes niveles de dificultad (básico, intermedio, avanzado)\n",
        "        2. Cada problema debe tener una solución paso a paso detallada\n",
        "        3. Los problemas deben ser relevantes para el contexto del curso\n",
        "        4. Incluye una mezcla de problemas conceptuales y aplicados\n",
        "        \"\"\"\n",
        "\n",
        "        final_prompt = additional_context + \"\\n\\n\" + prompt\n",
        "\n",
        "        # Generar el contenido\n",
        "        content = self.llm_engine.generate_content(final_prompt, max_tokens=3000)\n",
        "\n",
        "        return content\n",
        "\n",
        "    def generate_discussion_questions(self, topic: Dict[str, Any], course_context: Dict[str, Any]) -> str:\n",
        "        \"\"\"Genera preguntas para discusión sobre un tema específico.\"\"\"\n",
        "        self.logger.info(f\"Generando preguntas para discusión para: {topic['title']}\")\n",
        "\n",
        "        # Construir el prompt usando la plantilla\n",
        "        prompt_template = self.llm_engine.prompt_templates[\"discussion_questions\"]\n",
        "        subtopics_text = \", \".join(topic[\"subtopics\"])\n",
        "\n",
        "        prompt = prompt_template.format(\n",
        "            topic_title=topic[\"title\"],\n",
        "            subtopics=subtopics_text\n",
        "        )\n",
        "\n",
        "        # Añadir contexto y instrucciones específicas\n",
        "        additional_context = f\"\"\"\n",
        "        Para el curso: {course_context['course_title']}\n",
        "\n",
        "        Genera un conjunto de preguntas para discusión que:\n",
        "        1. Promuevan el pensamiento crítico y reflexivo\n",
        "        2. Estimulen el debate y el intercambio de ideas\n",
        "        3. Conecten el tema con problemas actuales o aplicaciones reales\n",
        "        4. Exploren implicaciones éticas o sociales cuando sea apropiado\n",
        "        5. Fomenten la conexión entre este tema y otros del curso\n",
        "\n",
        "        Para cada pregunta, incluye una breve nota para el instructor sobre puntos clave a considerar.\n",
        "        \"\"\"\n",
        "\n",
        "        final_prompt = additional_context + \"\\n\\n\" + prompt\n",
        "\n",
        "        # Generar el contenido\n",
        "        content = self.llm_engine.generate_content(final_prompt, max_tokens=2000)\n",
        "\n",
        "        return content\n",
        "\n",
        "    def generate_learning_objectives(self, topic: Dict[str, Any], course_context: Dict[str, Any]) -> str:\n",
        "        \"\"\"Genera objetivos de aprendizaje para un tema específico.\"\"\"\n",
        "        self.logger.info(f\"Generando objetivos de aprendizaje para: {topic['title']}\")\n",
        "\n",
        "        # Construir el prompt usando la plantilla\n",
        "        prompt_template = self.llm_engine.prompt_templates[\"learning_objectives\"]\n",
        "        subtopics_text = \", \".join(topic[\"subtopics\"])\n",
        "\n",
        "        prompt = prompt_template.format(\n",
        "            topic_title=topic[\"title\"],\n",
        "            subtopics=subtopics_text\n",
        "        )\n",
        "\n",
        "        # Añadir contexto y instrucciones específicas\n",
        "        additional_context = f\"\"\"\n",
        "        Para el curso: {course_context['course_title']}\n",
        "\n",
        "        Genera objetivos de aprendizaje que:\n",
        "        1. Sean específicos, medibles, alcanzables, relevantes y con tiempo definido (SMART)\n",
        "        2. Utilicen verbos de acción de la taxonomía de Bloom apropiados para el nivel universitario\n",
        "        3. Cubran diferentes niveles cognitivos (conocimiento, comprensión, aplicación, análisis, evaluación, creación)\n",
        "        4. Se alineen con los objetivos generales del curso\n",
        "        5. Sean claros y comprensibles para los estudiantes\n",
        "\n",
        "        Los objetivos generales del curso son:\n",
        "        {', '.join(course_context['course_objectives'])}\n",
        "        \"\"\"\n",
        "\n",
        "        final_prompt = additional_context + \"\\n\\n\" + prompt\n",
        "\n",
        "        # Generar el contenido\n",
        "        content = self.llm_engine.generate_content(final_prompt, max_tokens=1500)\n",
        "\n",
        "        return content\n",
        "\n",
        "    def generate_suggested_resources(self, topic: Dict[str, Any], course_context: Dict[str, Any]) -> str:\n",
        "        \"\"\"Genera recursos sugeridos para un tema específico.\"\"\"\n",
        "        self.logger.info(f\"Generando recursos sugeridos para: {topic['title']}\")\n",
        "\n",
        "        # Construir el prompt usando la plantilla\n",
        "        prompt_template = self.llm_engine.prompt_templates[\"suggested_resources\"]\n",
        "        subtopics_text = \", \".join(topic[\"subtopics\"])\n",
        "\n",
        "        prompt = prompt_template.format(\n",
        "            topic_title=topic[\"title\"],\n",
        "            subtopics=subtopics_text\n",
        "        )\n",
        "\n",
        "        # Añadir contexto y instrucciones específicas\n",
        "        additional_context = f\"\"\"\n",
        "        Para el curso: {course_context['course_title']}\n",
        "\n",
        "        Genera una lista de recursos de aprendizaje que incluya:\n",
        "        1. Libros de texto principales y complementarios (con autores y años)\n",
        "        2. Artículos académicos relevantes y actualizados\n",
        "        3. Recursos en línea de calidad (cursos, tutoriales, videos)\n",
        "        4. Herramientas o software relevantes cuando sea aplicable\n",
        "        5. Recursos para diferentes niveles de conocimiento previo\n",
        "\n",
        "        Para cada recurso, incluye una breve descripción de su relevancia y utilidad.\n",
        "        \"\"\"\n",
        "\n",
        "        final_prompt = additional_context + \"\\n\\n\" + prompt\n",
        "\n",
        "        # Generar el contenido\n",
        "        content = self.llm_engine.generate_content(final_prompt, max_tokens=2000)\n",
        "\n",
        "        return content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a crear la clase que nos permitirá obtener el archivo con la estructura del curso y extraer la informacion importante para que el agente pueda generar el contenido educativo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZR4IyHGk1TRm"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Módulo para procesar y extraer información de documentos (PDF, DOCX, TXT)\n",
        "\n",
        "class DocumentProcessor:\n",
        "    \"\"\"Clase para procesar y extraer información de programas de cursos.\"\"\"\n",
        "\n",
        "    def __init__(self, config: Config):\n",
        "        \"\"\"Inicializa el procesador de documentos.\"\"\"\n",
        "        self.config = config\n",
        "        self.logger = logging.getLogger(\"educational_agent.document_processor\")\n",
        "\n",
        "        # Descargar recursos de NLTK si es necesario\n",
        "        try:\n",
        "            nltk.data.find('tokenizers/punkt')\n",
        "        except LookupError:\n",
        "            nltk.download('punkt')\n",
        "\n",
        "    def process_file(self, file_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Procesa un archivo de programa de curso y extrae su estructura.\n",
        "\n",
        "        Args:\n",
        "            file_path: Ruta al archivo de programa de curso\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con la información estructurada del programa\n",
        "        \"\"\"\n",
        "        if not os.path.exists(file_path):\n",
        "            raise FileNotFoundError(f\"No se encontró el archivo: {file_path}\")\n",
        "\n",
        "        # Determinar el tipo de archivo por su extensión\n",
        "        file_ext = os.path.splitext(file_path)[1].lower()\n",
        "\n",
        "        # Extraer texto según el tipo de archivo\n",
        "        if file_ext == '.pdf':\n",
        "            text = self._extract_text_from_pdf(file_path)\n",
        "        elif file_ext == '.docx':\n",
        "            text = self._extract_text_from_docx(file_path)\n",
        "        elif file_ext == '.txt':\n",
        "            text = self._extract_text_from_txt(file_path)\n",
        "        else:\n",
        "            raise ValueError(f\"Formato de archivo no soportado: {file_ext}\")\n",
        "\n",
        "        # Analizar el texto extraído para obtener la estructura del curso\n",
        "        syllabus_data = self._parse_syllabus(text)\n",
        "\n",
        "        return syllabus_data\n",
        "\n",
        "    def _extract_text_from_pdf(self, file_path: str) -> str:\n",
        "        \"\"\"Extrae texto de un archivo PDF.\"\"\"\n",
        "        self.logger.info(f\"Extrayendo texto de PDF: {file_path}\")\n",
        "\n",
        "        text = \"\"\n",
        "        try:\n",
        "            with open(file_path, 'rb') as file:\n",
        "                reader = PyPDF2.PdfReader(file)\n",
        "                for page_num in range(len(reader.pages)):\n",
        "                    page = reader.pages[page_num]\n",
        "                    text += page.extract_text() + \"\\n\"\n",
        "\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error al extraer texto de PDF: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _extract_text_from_docx(self, file_path: str) -> str:\n",
        "        \"\"\"Extrae texto de un archivo DOCX.\"\"\"\n",
        "        self.logger.info(f\"Extrayendo texto de DOCX: {file_path}\")\n",
        "\n",
        "        try:\n",
        "            doc = docx.Document(file_path)\n",
        "            text = \"\\n\".join([paragraph.text for paragraph in doc.paragraphs])\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error al extraer texto de DOCX: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _extract_text_from_txt(self, file_path: str) -> str:\n",
        "        \"\"\"Extrae texto de un archivo de texto plano.\"\"\"\n",
        "        self.logger.info(f\"Extrayendo texto de TXT: {file_path}\")\n",
        "\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                return file.read()\n",
        "        except UnicodeDecodeError:\n",
        "            # Intentar con otra codificación si utf-8 falla\n",
        "            with open(file_path, 'r', encoding='latin-1') as file:\n",
        "                return file.read()\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error al extraer texto de TXT: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _parse_syllabus(self, text: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Analiza el texto del programa para extraer su estructura.\n",
        "\n",
        "        Args:\n",
        "            text: Texto completo del programa de curso\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con la información estructurada del programa\n",
        "        \"\"\"\n",
        "        self.logger.info(\"Analizando estructura del programa de curso\")\n",
        "\n",
        "        # Inicializar estructura de datos del programa\n",
        "        syllabus_data = {\n",
        "            \"course_title\": \"\",\n",
        "            \"course_code\": \"\",\n",
        "            \"instructor\": \"\",\n",
        "            \"description\": \"\",\n",
        "            \"objectives\": [],\n",
        "            \"topics\": [],\n",
        "            \"evaluation_methods\": [],\n",
        "            \"bibliography\": []\n",
        "        }\n",
        "\n",
        "        # Dividir en secciones\n",
        "        sections = self._split_into_sections(text)\n",
        "\n",
        "        # Extraer información básica del curso\n",
        "        syllabus_data[\"course_title\"] = self._extract_course_title(sections)\n",
        "        syllabus_data[\"course_code\"] = self._extract_course_code(sections)\n",
        "        syllabus_data[\"instructor\"] = self._extract_instructor(sections)\n",
        "        syllabus_data[\"description\"] = self._extract_description(sections)\n",
        "\n",
        "        # Extraer objetivos del curso\n",
        "        syllabus_data[\"objectives\"] = self._extract_objectives(sections)\n",
        "\n",
        "        # Extraer temario (la parte más importante)\n",
        "        syllabus_data[\"topics\"] = self._extract_topics(sections)\n",
        "\n",
        "        # Extraer métodos de evaluación\n",
        "        syllabus_data[\"evaluation_methods\"] = self._extract_evaluation_methods(sections)\n",
        "\n",
        "        # Extraer bibliografía\n",
        "        syllabus_data[\"bibliography\"] = self._extract_bibliography(sections)\n",
        "\n",
        "        return syllabus_data\n",
        "\n",
        "    def _split_into_sections(self, text: str) -> Dict[str, str]:\n",
        "        \"\"\"Divide el texto en secciones basadas en encabezados comunes.\"\"\"\n",
        "        # Lista de posibles encabezados de secciones en programas de curso\n",
        "        section_headers = [\n",
        "            r\"(?:TÍTULO|NOMBRE)\\s+DEL\\s+CURSO\",\n",
        "            r\"(?:CÓDIGO|CLAVE)\",\n",
        "            r\"(?:PROFESOR|INSTRUCTOR|DOCENTE)\",\n",
        "            r\"(?:DESCRIPCIÓN|DESCRIPCION)\",\n",
        "            r\"(?:OBJETIVOS|METAS)\",\n",
        "            r\"(?:TEMARIO|CONTENIDO|PROGRAMA|UNIDADES)\",\n",
        "            r\"(?:EVALUACIÓN|EVALUACION|CALIFICACIÓN)\",\n",
        "            r\"(?:BIBLIOGRAFÍA|BIBLIOGRAFIA|REFERENCIAS)\"\n",
        "        ]\n",
        "\n",
        "        sections = {}\n",
        "        current_section = \"preamble\"\n",
        "        sections[current_section] = \"\"\n",
        "\n",
        "        # Dividir el texto en líneas\n",
        "        lines = text.split('\\n')\n",
        "\n",
        "        for line in lines:\n",
        "            # Comprobar si la línea es un encabezado de sección\n",
        "            is_header = False\n",
        "            for pattern in section_headers:\n",
        "                if re.search(pattern, line, re.IGNORECASE):\n",
        "                    current_section = line.strip()\n",
        "                    sections[current_section] = \"\"\n",
        "                    is_header = True\n",
        "                    break\n",
        "\n",
        "            if not is_header:\n",
        "                sections[current_section] += line + \"\\n\"\n",
        "\n",
        "        return sections\n",
        "\n",
        "    def _extract_course_title(self, sections: Dict[str, str]) -> str:\n",
        "        \"\"\"Extrae el título del curso de las secciones.\"\"\"\n",
        "        for header, content in sections.items():\n",
        "            if re.search(r\"(?:TÍTULO|NOMBRE)\\s+DEL\\s+CURSO\", header, re.IGNORECASE):\n",
        "                return content.strip()\n",
        "\n",
        "        # Si no hay sección específica, buscar en el preámbulo\n",
        "        if \"preamble\" in sections:\n",
        "            lines = sections[\"preamble\"].split('\\n')\n",
        "            for line in lines[:5]:  # Buscar en las primeras 5 líneas\n",
        "                if len(line.strip()) > 0:\n",
        "                    return line.strip()\n",
        "\n",
        "        return \"No se pudo determinar el título del curso\"\n",
        "\n",
        "    def _extract_course_code(self, sections: Dict[str, str]) -> str:\n",
        "        \"\"\"Extrae el código del curso de las secciones.\"\"\"\n",
        "        for header, content in sections.items():\n",
        "            if re.search(r\"(?:CÓDIGO|CLAVE)\", header, re.IGNORECASE):\n",
        "                return content.strip()\n",
        "\n",
        "        # Buscar patrones de código en todo el texto\n",
        "        for _, content in sections.items():\n",
        "            # Buscar patrones típicos de códigos de curso (letras y números)\n",
        "            code_match = re.search(r\"\\b[A-Z]{2,4}\\s*\\d{3,4}\\b\", content)\n",
        "            if code_match:\n",
        "                return code_match.group(0).strip()\n",
        "\n",
        "        return \"No se pudo determinar el código del curso\"\n",
        "\n",
        "    def _extract_instructor(self, sections: Dict[str, str]) -> str:\n",
        "        \"\"\"Extrae el nombre del instructor del curso.\"\"\"\n",
        "        for header, content in sections.items():\n",
        "            if re.search(r\"(?:PROFESOR|INSTRUCTOR|DOCENTE)\", header, re.IGNORECASE):\n",
        "                return content.strip()\n",
        "\n",
        "        return \"No se pudo determinar el instructor del curso\"\n",
        "\n",
        "    def _extract_description(self, sections: Dict[str, str]) -> str:\n",
        "        \"\"\"Extrae la descripción del curso.\"\"\"\n",
        "        for header, content in sections.items():\n",
        "            if re.search(r\"(?:DESCRIPCIÓN|DESCRIPCION)\", header, re.IGNORECASE):\n",
        "                return content.strip()\n",
        "\n",
        "        return \"No se encontró descripción del curso\"\n",
        "\n",
        "    def _extract_objectives(self, sections: Dict[str, str]) -> List[str]:\n",
        "        \"\"\"Extrae los objetivos del curso.\"\"\"\n",
        "        objectives = []\n",
        "\n",
        "        for header, content in sections.items():\n",
        "            if re.search(r\"(?:OBJETIVOS|METAS)\", header, re.IGNORECASE):\n",
        "                lines = content.split('\\n')\n",
        "                for line in lines:\n",
        "                    line = line.strip()\n",
        "                    if line and (line.startswith('-') or line.startswith('•') or re.match(r\"^\\d+\\.\", line)):\n",
        "                        objectives.append(line.lstrip('-•0123456789. '))\n",
        "                    elif len(line) > 20 and not re.match(r\"^\\s*$\", line):\n",
        "                        # Líneas largas que podrían ser objetivos sin formato de lista\n",
        "                        sentences = sent_tokenize(line)\n",
        "                        for sentence in sentences:\n",
        "                            if len(sentence) > 20:\n",
        "                                objectives.append(sentence.strip())\n",
        "\n",
        "        return objectives\n",
        "\n",
        "    def _extract_topics(self, sections: Dict[str, str]) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Extrae el temario del curso.\"\"\"\n",
        "        topics = []\n",
        "\n",
        "        for header, content in sections.items():\n",
        "            if re.search(r\"(?:TEMARIO|CONTENIDO|PROGRAMA|UNIDADES)\", header, re.IGNORECASE):\n",
        "                # Dividir en posibles unidades o temas principales\n",
        "                unit_pattern = r\"(?:Unidad|Tema|Módulo|Capítulo)\\s+(\\d+|[IVXLCDM]+)[\\s:.]+(.+?)(?=(?:Unidad|Tema|Módulo|Capítulo)\\s+\\d+|$)\"\n",
        "                units = re.finditer(unit_pattern, content, re.IGNORECASE | re.DOTALL)\n",
        "\n",
        "                for match in units:\n",
        "                    unit_num = match.group(1)\n",
        "                    unit_content = match.group(2).strip()\n",
        "\n",
        "                    # Extraer subtemas\n",
        "                    subtopics = []\n",
        "                    lines = unit_content.split('\\n')\n",
        "                    for line in lines:\n",
        "                        line = line.strip()\n",
        "                        if line and (line.startswith('-') or line.startswith('•') or re.match(r\"^\\d+\\.\\d+\", line)):\n",
        "                            subtopics.append(line.lstrip('-•0123456789. '))\n",
        "\n",
        "                    # Si no encontramos subtemas con el formato de lista, intentar por oraciones\n",
        "                    if not subtopics:\n",
        "                        sentences = sent_tokenize(unit_content)\n",
        "                        title = sentences[0] if sentences else \"Sin título\"\n",
        "                        subtopics = [s.strip() for s in sentences[1:] if len(s.strip()) > 10]\n",
        "                    else:\n",
        "                        # El título probablemente sea la primera línea\n",
        "                        title = lines[0].strip() if lines else \"Sin título\"\n",
        "                        # Limpiar el título de numeraciones\n",
        "                        title = re.sub(r\"^\\d+\\.\\s*\", \"\", title)\n",
        "\n",
        "                    topics.append({\n",
        "                        \"id\": unit_num,\n",
        "                        \"title\": title,\n",
        "                        \"subtopics\": subtopics\n",
        "                    })\n",
        "\n",
        "                # Si no se detectaron unidades con el patrón anterior\n",
        "                if not topics:\n",
        "                    # Intento más simple por líneas con numeración\n",
        "                    numbered_lines = re.finditer(r\"^\\s*(\\d+)\\.\\s*(.+)$\", content, re.MULTILINE)\n",
        "                    current_topic = None\n",
        "\n",
        "                    for match in numbered_lines:\n",
        "                        num = match.group(1)\n",
        "                        text = match.group(2).strip()\n",
        "\n",
        "                        # Si es un número de un solo dígito, probablemente es un tema principal\n",
        "                        if len(num) == 1:\n",
        "                            current_topic = {\n",
        "                                \"id\": num,\n",
        "                                \"title\": text,\n",
        "                                \"subtopics\": []\n",
        "                            }\n",
        "                            topics.append(current_topic)\n",
        "                        # Si tenemos un tema actual y este es un subtema\n",
        "                        elif current_topic is not None:\n",
        "                            current_topic[\"subtopics\"].append(text)\n",
        "\n",
        "                # Si aún no tenemos temas, dividir por líneas no vacías\n",
        "                if not topics:\n",
        "                    current_id = 1\n",
        "                    for line in content.split('\\n'):\n",
        "                        line = line.strip()\n",
        "                        if line and len(line) > 5:\n",
        "                            topics.append({\n",
        "                                \"id\": str(current_id),\n",
        "                                \"title\": line,\n",
        "                                \"subtopics\": []\n",
        "                            })\n",
        "                            current_id += 1\n",
        "\n",
        "        return topics\n",
        "\n",
        "    def _extract_evaluation_methods(self, sections: Dict[str, str]) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Extrae los métodos de evaluación del curso.\"\"\"\n",
        "        evaluation_methods = []\n",
        "\n",
        "        for header, content in sections.items():\n",
        "            if re.search(r\"(?:EVALUACIÓN|EVALUACION|CALIFICACIÓN)\", header, re.IGNORECASE):\n",
        "                # Buscar elementos de evaluación y sus porcentajes\n",
        "                eval_items = re.finditer(r\"([^:]+):\\s*(\\d+)%\", content)\n",
        "\n",
        "                for match in eval_items:\n",
        "                    item = match.group(1).strip()\n",
        "                    percentage = int(match.group(2))\n",
        "\n",
        "                    evaluation_methods.append({\n",
        "                        \"method\": item,\n",
        "                        \"percentage\": percentage\n",
        "                    })\n",
        "\n",
        "                # Si no encontramos con el patrón anterior, buscar líneas con porcentajes\n",
        "                if not evaluation_methods:\n",
        "                    for line in content.split('\\n'):\n",
        "                        line = line.strip()\n",
        "                        if '%' in line:\n",
        "                            parts = line.split('%')\n",
        "                            percentage_part = parts[0].strip()\n",
        "                            # Extraer el último número antes del %\n",
        "                            percentage_match = re.search(r\"(\\d+)\\s*$\", percentage_part)\n",
        "\n",
        "                            if percentage_match:\n",
        "                                percentage = int(percentage_match.group(1))\n",
        "                                # El método es todo antes del número\n",
        "                                method = re.sub(r\"\\d+\\s*$\", \"\", percentage_part).strip()\n",
        "\n",
        "                                evaluation_methods.append({\n",
        "                                    \"method\": method,\n",
        "                                    \"percentage\": percentage\n",
        "                                })\n",
        "\n",
        "        return evaluation_methods\n",
        "\n",
        "    def _extract_bibliography(self, sections: Dict[str, str]) -> List[str]:\n",
        "        \"\"\"Extrae la bibliografía del curso.\"\"\"\n",
        "        bibliography = []\n",
        "\n",
        "        for header, content in sections.items():\n",
        "            if re.search(r\"(?:BIBLIOGRAFÍA|BIBLIOGRAFIA|REFERENCIAS)\", header, re.IGNORECASE):\n",
        "                lines = content.split('\\n')\n",
        "                current_entry = \"\"\n",
        "\n",
        "                for line in lines:\n",
        "                    line = line.strip()\n",
        "                    if not line:\n",
        "                        if current_entry:\n",
        "                            bibliography.append(current_entry)\n",
        "                            current_entry = \"\"\n",
        "                    else:\n",
        "                        if not current_entry and (line.startswith('-') or line.startswith('•') or re.match(r\"^\\d+\\.\", line)):\n",
        "                            current_entry = line.lstrip('-•0123456789. ')\n",
        "                        elif not current_entry:\n",
        "                            current_entry = line\n",
        "                        else:\n",
        "                            current_entry += \" \" + line\n",
        "\n",
        "                # No olvidar la última entrada\n",
        "                if current_entry:\n",
        "                    bibliography.append(current_entry)\n",
        "\n",
        "                # Si no hay entradas con el formato anterior, dividir por líneas no vacías\n",
        "                if not bibliography:\n",
        "                    bibliography = [line.strip() for line in lines if line.strip() and len(line.strip()) > 10]\n",
        "\n",
        "        return bibliography"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a probar la clase para verificar que se obtiene la información necesaria para generar el contenido educativo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QZXugfJa2cJ8"
      },
      "outputs": [],
      "source": [
        "config = Config()\n",
        "processor = DocumentProcessor(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "L_7netlS3R24"
      },
      "outputs": [],
      "source": [
        "syllabus_data = processor.process_file('PROGRAMA_DE_CURSO.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "HpZY4XZE5c0g"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No se pudieron cargar las plantillas: [Errno 2] No such file or directory: 'prompts.json'\n"
          ]
        }
      ],
      "source": [
        "# Initialize instances of the required classes\n",
        "config = Config() #Assuming Config is defined and accessible\n",
        "llm_engine = LLMEngine(config) #Initialize LLMEngine before EducationalAgent\n",
        "\n",
        "\n",
        "# Create a ContentGenerator instance, passing the LLMEngine instance\n",
        "generador = ContentGenerator(llm_engine,config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "p4DegLxt4i9i",
        "outputId": "d5ac58ce-2479-4ccd-957f-9eb86b8ba272"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:educational_agent.content_generator:Generando contenido para el tema 1: Introducción a la IA\n",
            "INFO:educational_agent.content_generator:Generando notas de clase para: Introducción a la IA\n",
            "INFO:educational_agent.content_generator:Generando problemas de práctica para: Introducción a la IA\n",
            "INFO:educational_agent.content_generator:Generando preguntas para discusión para: Introducción a la IA\n",
            "INFO:educational_agent.content_generator:Generando objetivos de aprendizaje para: Introducción a la IA\n",
            "INFO:educational_agent.content_generator:Generando recursos sugeridos para: Introducción a la IA\n",
            "INFO:educational_agent.content_generator:Generando contenido para el tema 2: Algoritmos de Búsqueda\n",
            "INFO:educational_agent.content_generator:Generando notas de clase para: Algoritmos de Búsqueda\n",
            "INFO:educational_agent.content_generator:Generando problemas de práctica para: Algoritmos de Búsqueda\n",
            "INFO:educational_agent.content_generator:Generando preguntas para discusión para: Algoritmos de Búsqueda\n",
            "INFO:educational_agent.content_generator:Generando objetivos de aprendizaje para: Algoritmos de Búsqueda\n",
            "INFO:educational_agent.content_generator:Generando recursos sugeridos para: Algoritmos de Búsqueda\n",
            "INFO:educational_agent.content_generator:Generando contenido para el tema 3: Machine Learning Básico\n",
            "INFO:educational_agent.content_generator:Generando notas de clase para: Machine Learning Básico\n",
            "INFO:educational_agent.content_generator:Generando problemas de práctica para: Machine Learning Básico\n",
            "INFO:educational_agent.content_generator:Generando preguntas para discusión para: Machine Learning Básico\n",
            "INFO:educational_agent.content_generator:Generando objetivos de aprendizaje para: Machine Learning Básico\n",
            "INFO:educational_agent.content_generator:Generando recursos sugeridos para: Machine Learning Básico\n"
          ]
        }
      ],
      "source": [
        "contenido = generador.generate_all_materials(syllabus_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'1': {'lecture_notes': '## Notas de Clase: Introducción a la Inteligencia Artificial\\n\\n**Curso:** Introducción a la Inteligencia Artificial\\n**Código:** [Dejar espacio para el código del curso]\\n**Descripción:** Este curso introductorio cubre los conceptos básicos de la Inteligencia Artificial, incluyendo algoritmos de búsqueda, aprendizaje automático y procesamiento del lenguaje natural. Los estudiantes desarrollarán habilidades prácticas mediante proyectos aplicados.\\n\\n**Tema:** Introducción a la IA\\n\\n**Objetivo:** Proporcionar una comprensión fundamental de la historia, los conceptos clave, las arquitecturas y las consideraciones éticas de la Inteligencia Artificial (IA).\\n\\n**Índice:**\\n\\n1.  **¿Qué es la Inteligencia Artificial?**\\n    *   1.1 Definición y Alcance\\n    *   1.2 Tipos de IA: Débil vs. Fuerte\\n2.  **Historia de la IA**\\n    *   2.1 Los Inicios (1943-1956): El Nacimiento de una Idea\\n    *   2.2 Los Años Dorados (1956-1974): Optimismo y Primeros Logros\\n    *   2.3 El Primer Invierno de la IA (1974-1980): Limitaciones y Financiamiento Reducido\\n    *   2.4 El Resurgimiento (1980-1987): Sistemas Expertos y la Quinta Generación\\n    *   2.5 El Segundo Invierno de la IA (1987-1993): Nuevas Limitaciones y Desilusión\\n    *   2.6 La IA Moderna (1993-Presente): Aprendizaje Automático, Big Data y el Renacimiento\\n3.  **Agentes Inteligentes**\\n    *   3.1 Definición de Agente\\n    *   3.2 Racionalidad\\n    *   3.3 Tipos de Agentes: Simples, Reactivos Basados en Modelo, Basados en Objetivos, Basados en Utilidad\\n    *   3.4 Arquitectura de un Agente Inteligente\\n4.  **Entornos y Tareas**\\n    *   4.1 Tipos de Entornos: Accesibilidad, Determinismo, Episódicos, Estáticos, Discretos\\n    *   4.2 Ejemplos de Tareas en IA: Juegos, Robótica, Diagnóstico Médico\\n5.  **Ética en la IA**\\n    *   5.1 Sesgos en los Datos y Algoritmos\\n    *   5.2 Transparencia y Explicabilidad (XAI)\\n    *   5.3 Responsabilidad y Rendición de Cuentas\\n    *   5.4 Privacidad y Seguridad\\n    *   5.5 El Futuro del Trabajo y el Impacto Social\\n\\n---\\n\\n**1. ¿Qué es la Inteligencia Artificial?**\\n\\n**1.1 Definición y Alcance:**\\n\\nLa Inteligencia Artificial (IA) se define como la capacidad de una máquina para imitar las funciones cognitivas humanas, como el aprendizaje, el razonamiento, la resolución de problemas, la percepción y el lenguaje natural. En términos más técnicos, la IA busca diseñar y desarrollar sistemas informáticos que puedan realizar tareas que normalmente requieren inteligencia humana.\\n\\nEl alcance de la IA es vasto y en constante expansión. Abarca desde sistemas simples que automatizan tareas repetitivas hasta sistemas complejos que toman decisiones autónomas en entornos dinámicos.\\n\\n**Ejemplo:**\\n\\n*   Un sistema de recomendación de películas (IA simple)\\n*   Un coche autónomo (IA compleja)\\n\\n**1.2 Tipos de IA: Débil vs. Fuerte:**\\n\\n*   **IA Débil (o IA Estrecha):** Se centra en realizar una tarea específica de manera eficiente. Estos sistemas no poseen conciencia ni autoconciencia. La mayoría de las aplicaciones actuales de IA entran en esta categoría.\\n\\n    **Ejemplo:** Un programa de ajedrez que juega a nivel de Gran Maestro, pero no puede hacer nada más.\\n\\n*   **IA Fuerte (o IA General):** Se refiere a sistemas que poseen la capacidad de entender, aprender y aplicar su inteligencia a cualquier tarea que un humano pueda realizar.  La IA fuerte implica la conciencia y la autoconciencia, y actualmente es un objetivo de investigación a largo plazo.\\n\\n    **Ejemplo:** Una máquina que puede razonar, aprender y resolver problemas en una amplia gama de dominios, igual que un humano.  *Aún no existe.*\\n\\n**2. Historia de la IA**\\n\\n**2.1 Los Inicios (1943-1956): El Nacimiento de una Idea**\\n\\n*   **1943:** Warren McCulloch y Walter Pitts publican \"A Logical Calculus of the Ideas Immanent in Nervous Activity\", un modelo matemático para redes neuronales artificiales, sentando las bases para el conexionismo en IA.\\n*   **1950:** Alan Turing publica \"Computing Machinery and Intelligence\", proponiendo el \"Test de Turing\" como criterio para determinar si una máquina puede \"pensar\".\\n*   **1956:** La Conferencia de Dartmouth, organizada por John McCarthy, Marvin Minsky, Nathaniel Rochester y Claude Shannon, se considera el evento fundacional de la IA como campo de estudio.\\n\\n**2.2 Los Años Dorados (1956-1974): Optimismo y Primeros Logros**\\n\\n*   Se desarrollan los primeros programas de IA que pueden resolver problemas algebraicos, jugar damas y hablar inglés limitado.\\n*   Se crea ELIZA (Joseph Weizenbaum), un programa que simula una conversación terapéutica, demostrando la capacidad de las máquinas para interactuar con humanos.\\n*   Aparecen los primeros robots con capacidades limitadas de percepción y movimiento.\\n\\n**2.3 El Primer Invierno de la IA (1974-1980): Limitaciones y Financiamiento Reducido**\\n\\n*   Las expectativas iniciales no se cumplen. Los programas de IA demuestran ser frágiles y difíciles de escalar.\\n*   El informe Lighthill (1973) critica la investigación en IA en el Reino Unido, lo que lleva a la reducción del financiamiento.\\n*   Las limitaciones de los sistemas basados en reglas y la falta de poder computacional dificultan el progreso.\\n\\n**2.4 El Resurgimiento (1980-1987): Sistemas Expertos y la Quinta Generación**\\n\\n*   El desarrollo de sistemas expertos, programas que emulan el razonamiento de expertos humanos en dominios específicos (como diagnóstico médico), revitaliza el campo.\\n*   Japón lanza el proyecto \"Quinta Generación\", con el objetivo de construir computadoras inteligentes capaces de razonamiento simbólico.\\n*   Aumenta la inversión en IA, tanto en el sector público como privado.\\n\\n**2.5 El Segundo Invierno de la IA (1987-1993): Nuevas Limitaciones y Desilusión**\\n\\n*   Los sistemas expertos demuestran ser costosos de mantener y difíciles de generalizar a nuevos dominios.\\n*   El proyecto \"Quinta Generación\" no cumple con las expectativas.\\n*   Disminuye nuevamente el financiamiento en IA.\\n\\n**2.6 La IA Moderna (1993-Presente): Aprendizaje Automático, Big Data y el Renacimiento**\\n\\n*   El auge del Aprendizaje Automático (Machine Learning), especialmente el Aprendizaje Profundo (Deep Learning), transforma el campo.\\n*   La disponibilidad de grandes cantidades de datos (Big Data) y el aumento del poder computacional permiten entrenar modelos complejos con alta precisión.\\n*   La IA encuentra aplicaciones exitosas en diversos campos, como reconocimiento de voz, visión por computadora, procesamiento del lenguaje natural, robótica, finanzas y medicina.\\n\\n**3. Agentes Inteligentes**\\n\\n**3.1 Definición de Agente:**\\n\\nUn agente es cualquier entidad que percibe su entorno a través de sensores y actúa sobre ese entorno a través de actuadores.  Un agente puede ser un humano, un robot, un programa de software, o cualquier otra cosa.\\n\\n**Ejemplo:**\\n\\n*   Un robot aspiradora percibe la suciedad en el suelo a través de sensores y actúa limpiando el suelo a través de actuadores (motores).\\n*   Un programa de recomendación de películas percibe las preferencias del usuario a través de datos de visualización y actúa recomendando películas a través de la interfaz de usuario.\\n\\n**3.2 Racionalidad:**\\n\\nUn agente racional es aquel que actúa de manera que maximiza la consecución de sus objetivos, basándose en la información disponible y en su conocimiento del entorno.  La racionalidad no implica necesariamente omnisciencia; un agente racional puede cometer errores debido a información incompleta o limitada capacidad computacional.\\n\\n**3.3 Tipos de Agentes:**\\n\\n*   **Agente Simple Reflexivo:**  Reacciona directamente a las percepciones actuales, sin mantener un historial de percepciones anteriores. Se basa en reglas simples del tipo \"Si (condición) entonces (acción)\".\\n\\n    **Ejemplo:** Un termostato que enciende el calentador si la temperatura es inferior a un cierto umbral.\\n\\n*   **Agente Reflexivo Basado en Modelo:**  Mantiene un modelo interno del mundo que le permite razonar sobre el estado actual del entorno y predecir cómo las acciones afectarán ese estado.\\n\\n    **Ejemplo:** Un coche autónomo que utiliza un mapa y sensores para construir un modelo del entorno y predecir el movimiento de otros vehículos.\\n\\n*   **Agente Basado en Objetivos:**  Además de un modelo del mundo, tiene un objetivo que desea alcanzar. El agente busca acciones que le permitan acercarse a su objetivo.\\n\\n    **Ejemplo:** Un robot que debe navegar por un laberinto para encontrar la salida.\\n\\n*   **Agente Basado en Utilidad:**  Similar a un agente basado en objetivos, pero asigna una utilidad a cada estado del mundo. El agente busca acciones que maximicen su utilidad esperada.\\n\\n    **Ejemplo:** Un agente que juega al póker y busca maximizar sus ganancias a largo plazo.\\n\\n**3.4 Arquitectura de un Agente Inteligente:**\\n\\nLa arquitectura de un agente inteligente describe cómo se organizan sus componentes internos.  Una arquitectura típica incluye:\\n\\n*   **Sensores:**  Reciben información del entorno.\\n*   **Actuadores:**  Realizan acciones en el entorno.\\n*   **Modelo del Mundo:**  Representación interna del estado del entorno.\\n*   **Algoritmo de Decisión:**  Determina qué acción debe realizar el agente en función de la información disponible y sus objetivos.\\n\\n**4. Entornos y Tareas**\\n\\n**4.1 Tipos de Entornos:**\\n\\n*   **Accesible vs. Inaccesible:** Un entorno es accesible si el agente tiene acceso completo al estado del entorno en todo momento.  Es inaccesible si el agente solo tiene acceso parcial o ruidoso al estado del entorno.\\n\\n    **Ejemplo:** Un juego de ajedrez es un entorno accesible; el póker es un entorno inaccesible.\\n\\n*   **Determinista vs. No Determinista:** Un entorno es determinista si el resultado de cada acción del agente está completamente determinado.  Es no determinista si el resultado de una acción puede variar debido a factores aleatorios o desconocidos.\\n\\n    **Ejemplo:** El ajedrez es determinista; el tráfico en la carretera es no determinista.\\n\\n*   **Episódico vs. No Episódico:** Un entorno es episódico si la experiencia del agente se divide en episodios independientes.  Es no episódico si las acciones del agente en un episodio afectan los episodios futuros.\\n\\n    **Ejemplo:** Clasificar correos electrónicos como spam o no spam es un entorno episódico; jugar al ajedrez es no episódico.\\n\\n*   **Estático vs. Dinámico:** Un entorno es estático si el entorno no cambia mientras el agente está pensando.  Es dinámico si el entorno puede cambiar mientras el agente está pensando.\\n\\n    **Ejemplo:** Resolver un crucigrama es un entorno estático; conducir en una carretera con tráfico es dinámico.\\n\\n*   **Discreto vs. Continuo:** Un entorno es discreto si el número de posibles estados y acciones es finito o contable.  Es continuo si el número de posibles estados y acciones es infinito o incontable.\\n\\n    **Ejemplo:** Jugar al ajedrez es un entorno discreto; controlar la temperatura de una habitación es continuo.\\n\\n**4.2 Ejemplos de Tareas en IA:**\\n\\n*   **Juegos:** Ajedrez, Go, videojuegos.  Permiten probar algoritmos de búsqueda, aprendizaje y toma de decisiones en entornos controlados.\\n*   **Robótica:** Navegación autónoma, manipulación de objetos, interacción humano-robot.  Requiere percepción, planificación y control en entornos físicos complejos.\\n*   **Diagnóstico Médico:**  Identificación de enfermedades a partir de síntomas y datos de laboratorio.  Requiere razonamiento probabilístico y manejo de incertidumbre.\\n*   **Procesamiento del Lenguaje Natural (PLN):** Traducción automática, análisis de sentimientos, chatbots.  Requiere comprensión del lenguaje humano y generación de respuestas coherentes.\\n*   **Visión por Computadora:** Reconocimiento de objetos, detección de rostros, análisis de imágenes médicas.  Requiere procesamiento de imágenes y reconocimiento de patrones.\\n\\n**5. Ética en la IA**\\n\\n**5.1 Sesgos en los Datos y Algoritmos:**\\n\\nLos sistemas de IA pueden heredar sesgos presentes en los datos con los que son entrenados, lo que puede llevar a decisiones discriminatorias.\\n\\n**Ejemplo:** Un algoritmo de reconocimiento facial entrenado principalmente con imágenes de personas de una raza puede tener un rendimiento inferior con personas de otras razas.\\n\\n**5.2 Transparencia y Explicabilidad (XAI):**\\n\\nEs importante que los sistemas de IA sean transparentes y que sus decisiones puedan ser explicadas a los usuarios. Esto ayuda a comprender cómo funciona el sistema y a identificar posibles sesgos o errores.\\n\\n**5.3 Responsabilidad y Rendición de Cuentas:**\\n\\nEs necesario establecer quién es responsable de las decisiones tomadas por los sistemas de IA, especialmente en casos de errores o daños.\\n\\n**5.4 Privacidad y Seguridad:**\\n\\nLos sistemas de IA pueden recopilar y procesar grandes cantidades de datos personales, lo que plantea preocupaciones sobre la privacidad y la seguridad de la información.\\n\\n**5.5 El Futuro del Trabajo y el Impacto Social:**\\n\\nLa automatización impulsada por la IA puede tener un impacto significativo en el mercado laboral, creando nuevos empleos pero también desplazando a otros.  Es importante considerar las implicaciones sociales de la IA y tomar medidas para mitigar sus efectos negativos.\\n\\n---\\n\\nEstas notas de clase proporcionan una introducción completa a la Inteligencia Artificial, cubriendo su historia, conceptos clave, arquitecturas y consideraciones éticas.  Este conocimiento fundamental es esencial para comprender las aplicaciones actuales de la IA y participar en el desarrollo futuro de esta tecnología transformadora.\\n',\n",
              "  'practice_problems': '¡Excelente! Aquí tienes un conjunto de problemas de práctica sobre \"Introducción a la IA\" diseñados para un curso universitario, con soluciones paso a paso y cubriendo los temas que especificaste:\\n\\n**Problemas de Práctica: Introducción a la Inteligencia Artificial**\\n\\n**I. Historia de la IA**\\n\\n*   **Problema 1 (Básico):**\\n\\n    *   Describe brevemente dos hitos importantes en la historia temprana de la IA (antes de 1980) y explica por qué fueron significativos.\\n    *   **Solución:**\\n        1.  **El Test de Turing (1950):** Alan Turing propuso un criterio para determinar si una máquina puede \"pensar\". Fue significativo porque estableció un objetivo claro y medible para la IA, impulsando la investigación y el debate sobre la posibilidad de la inteligencia artificial.\\n        2.  **ELIZA (1966):** Joseph Weizenbaum creó ELIZA, un programa de procesamiento del lenguaje natural que simulaba un terapeuta. Fue significativo porque demostró la capacidad de una máquina para interactuar con humanos de manera conversacional, aunque superficial, generando interés en el potencial de la IA.\\n*   **Problema 2 (Intermedio):**\\n\\n    *   Explica la diferencia entre el enfoque \"simbólico\" (o \"basado en reglas\") y el enfoque \"conexionista\" (o \"basado en redes neuronales\") en la IA. ¿Cuáles fueron las ventajas y desventajas de cada uno en sus primeras etapas?\\n    *   **Solución:**\\n        *   **Enfoque Simbólico:** Se basa en representar el conocimiento mediante símbolos y reglas lógicas. Los programas manipulan estos símbolos para razonar y resolver problemas.\\n            *   **Ventajas iniciales:** Fácil de entender y depurar, bueno para problemas bien definidos con reglas claras.\\n            *   **Desventajas iniciales:** Frágil ante información incompleta o ruidosa, difícil de escalar a problemas complejos del mundo real, requiere una gran cantidad de conocimiento explícito.\\n        *   **Enfoque Conexionista:** Se basa en redes neuronales artificiales que aprenden a partir de datos. Las conexiones entre las neuronas se ajustan durante el entrenamiento.\\n            *   **Ventajas iniciales:** Potencial para aprender patrones complejos a partir de datos, robusto ante información incompleta, inspirado en la estructura del cerebro humano.\\n            *   **Desventajas iniciales:** Difícil de interpretar el razonamiento interno, requiere grandes cantidades de datos para el entrenamiento, computacionalmente costoso.\\n*   **Problema 3 (Avanzado):**\\n\\n    *   Investiga y describe un \"invierno de la IA\". ¿Cuáles fueron las causas principales de este período de declive en la investigación y el financiamiento de la IA?\\n    *   **Solución:**\\n        *   Un \"invierno de la IA\" es un período de reducción significativa en la financiación y el interés en la investigación de la IA. Uno de los más notables fue en la década de 1970.\\n        *   **Causas principales:**\\n            1.  **Promesas Exageradas:** Los primeros investigadores de la IA hicieron predicciones demasiado optimistas sobre la rapidez con la que se lograría la inteligencia artificial general (AGI).\\n            2.  **Limitaciones Tecnológicas:** El hardware y el software disponibles en ese momento no eran lo suficientemente potentes para abordar los problemas complejos que la IA intentaba resolver.\\n            3.  **Falta de Aplicaciones Prácticas:** Muchas de las aplicaciones de IA propuestas no se materializaron, lo que llevó a una disminución de la confianza y el financiamiento.\\n            4.  **Informe Lighthill (1973):** Un informe influyente del profesor Sir James Lighthill criticó la investigación en IA en el Reino Unido, argumentando que no había producido resultados significativos.\\n\\n**II. Agentes Inteligentes**\\n\\n*   **Problema 4 (Básico):**\\n\\n    *   Define qué es un \"agente\" en el contexto de la IA. Da dos ejemplos de agentes y describe sus principales características.\\n    *   **Solución:**\\n        *   Un agente es cualquier entidad que percibe su entorno a través de sensores y actúa sobre ese entorno a través de actuadores.\\n        *   **Ejemplos:**\\n            1.  **Robot aspiradora:** Percibe la suciedad a través de sensores, actúa moviéndose y aspirando.\\n            2.  **Sistema de recomendación de películas:** Percibe las preferencias del usuario (historial de visionado, calificaciones), actúa recomendando películas.\\n*   **Problema 5 (Intermedio):**\\n\\n    *   Explica la diferencia entre un agente reflexivo simple y un agente basado en modelos. ¿Cuáles son las ventajas y desventajas de cada uno?\\n    *   **Solución:**\\n        *   **Agente Reflexivo Simple:** Toma decisiones basándose únicamente en la percepción actual del entorno. Tiene reglas del tipo \"si veo X, entonces hago Y\".\\n            *   **Ventajas:** Simple de implementar, rápido.\\n            *   **Desventajas:** No puede manejar entornos complejos o parcialmente observables, no tiene memoria del pasado.\\n        *   **Agente Basado en Modelos:** Mantiene un modelo interno del mundo, que le permite predecir cómo sus acciones afectarán el entorno.\\n            *   **Ventajas:** Puede manejar entornos complejos y parcialmente observables, puede planificar y anticipar las consecuencias de sus acciones.\\n            *   **Desventajas:** Requiere más recursos computacionales, la precisión del modelo interno es crucial.\\n*   **Problema 6 (Avanzado):**\\n\\n    *   Diseña un agente para jugar al juego del \"gato\" (tic-tac-toe). Describe sus sensores, actuadores, el modelo interno que podría utilizar y la función de utilidad que maximizaría.\\n    *   **Solución:**\\n        *   **Agente para el juego del gato:**\\n            *   **Sensores:** El estado actual del tablero (X, O, vacío).\\n            *   **Actuadores:** Colocar una \"X\" en una celda vacía del tablero.\\n            *   **Modelo Interno:** Representación del tablero, reglas del juego, posible árbol de búsqueda de movimientos.\\n            *   **Función de Utilidad:**\\n                *   +1 si el agente gana.\\n                *   -1 si el agente pierde.\\n                *   0 si el juego termina en empate.\\n                *   Se podría usar el algoritmo Minimax para explorar el árbol de búsqueda y elegir el movimiento que maximice la utilidad, asumiendo que el oponente juega de manera óptima.\\n\\n**III. Entornos y Tareas**\\n\\n*   **Problema 7 (Básico):**\\n\\n    *   Define qué es un \"entorno\" en el contexto de la IA. Da dos ejemplos de entornos y descríbelos en términos de accesibilidad (totalmente observable vs. parcialmente observable), determinismo (determinista vs. estocástico) y continuidad (discreto vs. continuo).\\n    *   **Solución:**\\n        *   Un entorno es el mundo que rodea a un agente y con el que interactúa.\\n        *   **Ejemplos:**\\n            1.  **Juego de ajedrez:**\\n                *   Accesibilidad: Totalmente observable (el agente ve todas las piezas).\\n                *   Determinismo: Determinista (el resultado de un movimiento es predecible).\\n                *   Continuidad: Discreto (un número finito de acciones posibles).\\n            2.  **Conducción autónoma:**\\n                *   Accesibilidad: Parcialmente observable (el agente no ve todo el entorno simultáneamente, depende de los sensores).\\n                *   Determinismo: Estocástico (el comportamiento de otros vehículos y peatones es impredecible).\\n                *   Continuidad: Continuo (la posición y la velocidad del vehículo pueden variar continuamente).\\n*   **Problema 8 (Intermedio):**\\n\\n    *   Explica la diferencia entre una tarea de \"clasificación\" y una tarea de \"regresión\" en el aprendizaje automático. Da un ejemplo de cada una.\\n    *   **Solución:**\\n        *   **Clasificación:** El objetivo es predecir la categoría a la que pertenece una entrada. La salida es una etiqueta discreta.\\n            *   **Ejemplo:** Clasificar correos electrónicos como \"spam\" o \"no spam\".\\n        *   **Regresión:** El objetivo es predecir un valor numérico continuo.\\n            *   **Ejemplo:** Predecir el precio de una casa en función de su tamaño, ubicación y otras características.\\n*   **Problema 9 (Avanzado):**\\n\\n    *   Considera una tarea de control de un robot que debe navegar por un laberinto. Describe los desafíos que presenta un entorno \"parcialmente observable\" para este robot. ¿Qué estrategias podría utilizar el robot para superar estos desafíos?\\n    *   **Solución:**\\n        *   **Desafíos de la Observabilidad Parcial:**\\n            1.  **Incertidumbre:** El robot no tiene información completa sobre el laberinto, lo que dificulta la planificación de la ruta.\\n            2.  **Ambigüedad:** Diferentes ubicaciones en el laberinto pueden parecer similares al robot, lo que puede llevar a errores de navegación.\\n            3.  **Exploración:** El robot debe explorar activamente el laberinto para descubrir nuevas áreas y construir un mapa.\\n        *   **Estrategias:**\\n            1.  **Mapeo:** Crear un mapa interno del laberinto a medida que lo explora.\\n            2.  **Localización:** Utilizar sensores y algoritmos para estimar su posición actual en el mapa.\\n            3.  **Planificación:** Planificar una ruta basada en el mapa y la posición estimada.\\n            4.  **Exploración:** Utilizar estrategias de exploración (por ejemplo, seguir la pared) para descubrir nuevas áreas del laberinto.\\n            5.  **Memoria:** Recordar las áreas que ya ha explorado para evitar repetir los mismos caminos.\\n\\n**IV. Ética en IA**\\n\\n*   **Problema 10 (Básico):**\\n\\n    *   Da un ejemplo de un posible sesgo en un algoritmo de IA y explica por qué es importante abordar estos sesgos.\\n    *   **Solución:**\\n        *   **Ejemplo:** Un algoritmo de reconocimiento facial entrenado principalmente con imágenes de personas de una etnia puede tener un rendimiento inferior al reconocer rostros de otras etnias.\\n        *   **Importancia:** Los sesgos pueden llevar a resultados injustos o discriminatorios, perpetuando desigualdades sociales. Es crucial abordar estos sesgos para garantizar que la IA se utilice de manera equitativa y responsable.\\n*   **Problema 11 (Intermedio):**\\n\\n    *   Discute los desafíos éticos relacionados con la privacidad de los datos en la IA. ¿Cómo se pueden proteger los datos personales al mismo tiempo que se aprovechan los beneficios de la IA?\\n    *   **Solución:**\\n        *   **Desafíos:** La IA a menudo requiere grandes cantidades de datos personales para su entrenamiento y funcionamiento, lo que plantea preocupaciones sobre la privacidad, la seguridad y el uso indebido de la información.\\n        *   **Soluciones:**\\n            1.  **Anonimización de datos:** Eliminar o enmascarar la información que pueda identificar a las personas.\\n            2.  **Cifrado de datos:** Proteger los datos mediante técnicas de cifrado.\\n            3.  **Acceso controlado a los datos:** Limitar el acceso a los datos a las personas que lo necesitan.\\n            4.  **Transparencia:** Informar a los usuarios sobre cómo se utilizan sus datos.\\n            5.  **Regulación:** Establecer leyes y regulaciones para proteger la privacidad de los datos.\\n*   **Problema 12 (Avanzado):**\\n\\n    *   Investiga y discute el debate sobre la \"responsabilidad\" en los sistemas de IA. ¿Quién debería ser responsable cuando un sistema de IA causa daño? ¿El diseñador, el programador, el usuario o el propio sistema de IA? Justifica tu respuesta.\\n    *   **Solución:**\\n        *   El tema de la responsabilidad en los sistemas de IA es complejo y no tiene una respuesta única.\\n        *   **Argumentos a considerar:**\\n            1.  **Diseñador/Programador:** Son responsables de diseñar y construir el sistema de IA, por lo que deberían ser responsables de los errores o sesgos que introduzcan en el sistema.\\n            2.  **Usuario:** En algunos casos, el usuario puede ser responsable si utiliza el sistema de IA de manera negligente o inapropiada.\\n            3.  **Sistema de IA:** Actualmente, la IA no tiene personalidad jurídica, por lo que no puede ser considerada responsable en el sentido legal. Sin embargo, algunos argumentan que, a medida que la IA se vuelve más autónoma, se debería explorar la posibilidad de asignarle algún tipo de responsabilidad.\\n        *   **Justificación:**\\n            *   En la mayoría de los casos, la responsabilidad debería recaer principalmente en el diseñador y el programador, ya que son quienes tienen el control sobre el diseño y la implementación del sistema. Sin embargo, la responsabilidad también puede ser compartida con el usuario si este utiliza el sistema de manera negligente o inapropiada.\\n            *   Es importante establecer marcos legales y éticos claros para determinar la responsabilidad en los sistemas de IA y garantizar que las víctimas de daños causados por la IA reciban una compensación justa.\\n\\nEspero que estos problemas de práctica sean útiles para tu curso de Introducción a la IA. ¡Mucho éxito!\\n',\n",
              "  'discussion_questions': '¡Excelente! Aquí tienes un conjunto de preguntas para discusión sobre la \"Introducción a la IA\" diseñadas para fomentar el pensamiento crítico y la reflexión profunda en estudiantes universitarios, junto con notas para el instructor:\\n\\n**Preguntas para Discusión: Introducción a la IA**\\n\\n**Sección 1: Historia de la IA**\\n\\n1.  **Pregunta:** A lo largo de la historia de la IA, ha habido ciclos de optimismo (veranos de la IA) y desilusión (inviernos de la IA). ¿Cuáles fueron las principales razones detrás de estos ciclos? ¿Qué lecciones podemos aprender de estos ciclos para gestionar las expectativas actuales sobre la IA?\\n\\n    *   **Nota para el Instructor:** Animar a los estudiantes a identificar factores tecnológicos (limitaciones de hardware, algoritmos), factores económicos (financiamiento de la investigación) y factores sociales (expectativas poco realistas) que contribuyeron a los veranos e inviernos.  Es crucial que los alumnos entiendan que el progreso en IA no es lineal y que la gestión de las expectativas es fundamental para un desarrollo sostenible.\\n\\n2.  **Pregunta:**  Considerando los diferentes enfoques (simbólico, conexionista, estadístico) que han dominado la IA en diferentes épocas, ¿cuáles son las fortalezas y debilidades inherentes de cada uno? ¿Podemos identificar elementos de estos enfoques que se están combinando en las técnicas de IA modernas?\\n\\n    *   **Nota para el Instructor:** El objetivo es que los estudiantes comprendan que no hay un \"enfoque único\" para la IA.  Fomentar la discusión sobre cómo las redes neuronales (conexionismo) se benefician de técnicas estadísticas y cómo el razonamiento simbólico podría complementar el aprendizaje profundo.\\n\\n**Sección 2: Agentes Inteligentes**\\n\\n3.  **Pregunta:**  El concepto de \"agente racional\" es fundamental en IA. ¿Qué significa ser \"racional\" en el contexto de un agente inteligente? ¿Es siempre posible o deseable que un agente sea perfectamente racional? ¿Qué limitaciones prácticas o éticas podrían impedir la racionalidad perfecta?\\n\\n    *   **Nota para el Instructor:** Introducir la idea de racionalidad limitada (bounded rationality).  Discutir cómo la complejidad del mundo real, la incertidumbre y los recursos computacionales limitados hacen que la racionalidad perfecta sea inalcanzable.  También, explorar escenarios donde la \"racionalidad\" podría entrar en conflicto con valores humanos o consideraciones éticas.\\n\\n4.  **Pregunta:**  Considerando los diferentes tipos de agentes (simples reflejos, basados en modelos, basados en objetivos, basados en utilidad), ¿en qué tipo de entornos sería más apropiado utilizar cada uno? ¿Qué desafíos específicos presenta el diseño de agentes inteligentes para entornos complejos y dinámicos?\\n\\n    *   **Nota para el Instructor:**  Animar a los estudiantes a relacionar el tipo de agente con las características del entorno (observabilidad, determinismo, etc.).  Discutir la importancia de la representación del conocimiento, el aprendizaje y la adaptación en entornos complejos.\\n\\n**Sección 3: Entornos y Tareas**\\n\\n5.  **Pregunta:**  La elección del entorno y la tarea es crucial para el desarrollo y la evaluación de sistemas de IA.  ¿Cómo influye el tipo de entorno (totalmente observable vs. parcialmente observable, determinista vs. estocástico, etc.) en el diseño del agente? ¿Qué métricas son apropiadas para evaluar el rendimiento de un agente en diferentes tipos de tareas?\\n\\n    *   **Nota para el Instructor:**  Resaltar la importancia de la alineación entre el entorno, la tarea y el diseño del agente.  Introducir conceptos como precisión, recall, F1-score, y otras métricas relevantes para diferentes tipos de tareas (clasificación, regresión, etc.).\\n\\n6.  **Pregunta:**  Considerando el auge del aprendizaje por refuerzo, ¿qué tipos de problemas son particularmente adecuados para este enfoque? ¿Cuáles son los desafíos clave para aplicar el aprendizaje por refuerzo en el mundo real, como la definición de la función de recompensa, la exploración y la explotación, y la seguridad?\\n\\n    *   **Nota para el Instructor:**  Discutir ejemplos de aplicaciones exitosas del aprendizaje por refuerzo (juegos, robótica, etc.).  Explorar los desafíos relacionados con la especificación de recompensas que reflejen los objetivos deseados, el equilibrio entre la exploración de nuevas acciones y la explotación de acciones conocidas, y la garantía de que el agente no aprenda comportamientos no deseados o peligrosos.\\n\\n**Sección 4: Ética en IA**\\n\\n7.  **Pregunta:**  La IA plantea importantes cuestiones éticas relacionadas con el sesgo, la equidad, la transparencia y la responsabilidad.  ¿Cómo pueden los sesgos presentes en los datos de entrenamiento influir en el comportamiento de los sistemas de IA? ¿Qué medidas se pueden tomar para mitigar estos sesgos y garantizar la equidad en las decisiones automatizadas?\\n\\n    *   **Nota para el Instructor:**  Presentar ejemplos concretos de sesgos en datos y algoritmos.  Discutir técnicas para la detección y mitigación de sesgos, como el re-muestreo de datos, la modificación de algoritmos y la evaluación del impacto en diferentes grupos demográficos.\\n\\n8.  **Pregunta:**  A medida que la IA se vuelve más autónoma, ¿cómo podemos garantizar la transparencia y la explicabilidad de sus decisiones? ¿Por qué es importante la explicabilidad en ciertos contextos (medicina, justicia, etc.)? ¿Qué desafíos técnicos y éticos presenta el desarrollo de sistemas de IA explicables (XAI)?\\n\\n    *   **Nota para el Instructor:**  Introducir el concepto de \"caja negra\" en la IA.  Discutir las ventajas y desventajas de diferentes enfoques para la explicabilidad, como la visualización de características importantes, la generación de reglas y la explicación contrafactual.  Resaltar la tensión entre la precisión y la explicabilidad.\\n\\n9.  **Pregunta:**  ¿Qué tipo de regulación o gobernanza creen que es necesaria para el desarrollo y el despliegue responsables de la IA? ¿Quién debería ser responsable de las consecuencias negativas de las decisiones tomadas por sistemas de IA autónomos?\\n\\n    *   **Nota para el Instructor:**  Invitar a los estudiantes a considerar diferentes perspectivas sobre la regulación de la IA (desde la autorregulación hasta la regulación gubernamental).  Discutir la necesidad de un marco legal y ético claro para la IA, así como la importancia de la responsabilidad y la rendición de cuentas.\\n\\n**Sección 5: Conexión con Problemas Actuales y Aplicaciones Reales**\\n\\n10. **Pregunta:**  La IA está transformando rápidamente muchos aspectos de nuestras vidas, desde la atención médica hasta el transporte. ¿Cuáles son algunas de las aplicaciones más prometedoras de la IA en la actualidad? ¿Qué desafíos técnicos, económicos o sociales impiden una adopción más amplia de estas aplicaciones?\\n\\n    *   **Nota para el Instructor:**  Animar a los estudiantes a investigar ejemplos concretos de aplicaciones de la IA en diferentes dominios.  Discutir la importancia de la colaboración interdisciplinaria para abordar los desafíos relacionados con la implementación de la IA en el mundo real.\\n\\n11. **Pregunta:**  Considerando el impacto potencial de la IA en el mercado laboral, ¿qué habilidades y conocimientos serán más valiosos en el futuro? ¿Cómo podemos preparar a la fuerza laboral para adaptarse a los cambios impulsados por la IA?\\n\\n    *   **Nota para el Instructor:**  Fomentar la discusión sobre la necesidad de la readaptación profesional y la formación continua.  Resaltar la importancia de las habilidades blandas (comunicación, pensamiento crítico, creatividad) en un mundo cada vez más automatizado.\\n\\nEstas preguntas están diseñadas para ser un punto de partida.  El instructor puede adaptarlas y modificarlas según las necesidades específicas del curso y los intereses de los estudiantes.  Lo importante es fomentar un ambiente de debate abierto y respetuoso donde los estudiantes se sientan cómodos compartiendo sus ideas y perspectivas.\\n',\n",
              "  'learning_objectives': '¡Excelente! Aquí tienes una propuesta de objetivos de aprendizaje SMART para el tema \"Introducción a la IA\", considerando los subtemas que has especificado, los objetivos generales del curso y la taxonomía de Bloom:\\n\\n**Tema: Introducción a la IA**\\n\\n**Subtemas:**\\n\\n*   Historia de la IA\\n*   Agentes inteligentes\\n*   Entornos y tareas\\n*   Ética en IA\\n\\n**Objetivos de Aprendizaje SMART:**\\n\\n1.  **Conocimiento (Recordar/Identificar):**\\n\\n    *   **Objetivo:**  *En la primera semana, los estudiantes serán capaces de **enumerar** al menos tres hitos clave en la historia de la IA, incluyendo el año aproximado y la figura principal asociada a cada hito, demostrando comprensión básica de la evolución del campo.* (Verbo: Enumerar - Nivel Conocimiento/Recordar)\\n\\n2.  **Comprensión (Entender/Explicar):**\\n\\n    *   **Objetivo:** *Al finalizar la discusión sobre agentes inteligentes, los estudiantes **explicarán** con sus propias palabras, en un párrafo conciso, la diferencia entre un agente racional y un agente omnisciente, justificando la importancia de la racionalidad en el diseño de sistemas de IA prácticos.* (Verbo: Explicar - Nivel Comprensión)\\n\\n3.  **Aplicación (Aplicar/Utilizar):**\\n\\n    *   **Objetivo:** *Después de la presentación sobre entornos y tareas, los estudiantes **clasificarán** correctamente al menos cinco escenarios del mundo real (ej: conducción autónoma, diagnóstico médico, recomendación de películas) en una tabla, según las propiedades del entorno (accesible vs. inaccesible, determinista vs. estocástico, etc.), justificando su elección para cada escenario.* (Verbo: Clasificar - Nivel Aplicación)\\n\\n4.  **Análisis (Analizar/Diferenciar):**\\n\\n    *   **Objetivo:** *Al concluir la sección de ética en IA, los estudiantes **analizarán** un caso de estudio proporcionado (ej: sesgos en algoritmos de reconocimiento facial), **identificando** al menos tres dilemas éticos relevantes y **comparando** diferentes perspectivas sobre cómo abordar estos dilemas, en un ensayo corto de 500 palabras.* (Verbos: Analizar, Identificar, Comparar - Nivel Análisis)\\n\\n5.  **Evaluación (Evaluar/Justificar):**\\n\\n    *   **Objetivo:** *Durante el debate final del módulo, los estudiantes **evaluarán** críticamente el impacto potencial de la IA en el mercado laboral, **justificando** con argumentos sólidos y evidencia (ej: datos de informes recientes) si la IA conducirá a una pérdida masiva de empleos o a la creación de nuevas oportunidades, presentando sus conclusiones en un breve discurso de 3 minutos.* (Verbos: Evaluar, Justificar - Nivel Evaluación)\\n\\n6.  **Creación (Crear/Diseñar):**\\n\\n    *   **Objetivo:** *Como parte de un proyecto grupal, los estudiantes **diseñarán** un agente inteligente conceptual para resolver un problema específico (ej: gestión de tráfico urbano), **especificando** claramente sus sensores, actuadores, objetivos y la función que utiliza para tomar decisiones, presentando su diseño en un informe detallado que incluya un diagrama de flujo del agente.* (Verbo: Diseñar, Especificar - Nivel Creación)\\n\\n**Consideraciones Adicionales:**\\n\\n*   **Alineación con Objetivos Generales:** Estos objetivos están diseñados para sentar las bases para la comprensión de los fundamentos teóricos (historia, agentes), la aplicación de algoritmos (diseño del agente), el análisis de casos de estudio (ética) y la implementación de soluciones simples (diseño del agente).\\n*   **Claridad y Comprensibilidad:** El lenguaje utilizado es accesible y evita la jerga innecesaria. Se proporcionan ejemplos para ayudar a los estudiantes a comprender las expectativas.\\n*   **Medibilidad:** Cada objetivo incluye un criterio específico que permite evaluar si el estudiante ha alcanzado el objetivo (ej: \"al menos tres hitos\", \"en un párrafo conciso\", \"al menos cinco escenarios\").\\n*   **Realismo:** Los objetivos son ambiciosos pero alcanzables dentro del marco de tiempo y los recursos disponibles para el curso.\\n*   **Relevancia:** Los temas elegidos son fundamentales para una introducción a la IA y están directamente relacionados con las aplicaciones prácticas y las implicaciones éticas del campo.\\n*   **Tiempo Definido:**  Se especifica un marco de tiempo (ej: \"en la primera semana\", \"al finalizar la discusión\", \"durante el debate final\") para ayudar a los estudiantes a gestionar su tiempo y priorizar su aprendizaje.\\n\\nEspero que esto te sea de gran utilidad. Puedes adaptar y modificar estos objetivos según las necesidades específicas de tu curso. ¡Mucha suerte!\\n',\n",
              "  'suggested_resources': '¡Excelente! Asumiré el rol de un asistente educativo experto para crear una lista de recursos de aprendizaje completa y bien organizada para un curso de \"Introducción a la Inteligencia Artificial (IA)\".\\n\\n**Curso: Introducción a la Inteligencia Artificial (IA)**\\n\\n**Objetivo General:** Proporcionar a los estudiantes una comprensión fundamental de los conceptos, la historia, las técnicas y las implicaciones éticas de la Inteligencia Artificial.\\n\\n**Lista de Recursos de Aprendizaje:**\\n\\n**1. Libros de Texto Principales y Complementarios:**\\n\\n*   **Principal:**\\n    *   **\"Artificial Intelligence: A Modern Approach\" (4th Edition) by Stuart Russell and Peter Norvig (2020)**\\n        *   **Relevancia:** Considerado el libro de texto estándar en el campo. Cubre una amplia gama de temas, desde la búsqueda y el razonamiento hasta el aprendizaje automático y la robótica.\\n        *   **Utilidad:** Proporciona una base sólida en los principios fundamentales de la IA.\\n*   **Complementarios:**\\n    *   **\"Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow\" (3rd Edition) by Aurélien Géron (2022)**\\n        *   **Relevancia:** Un libro práctico que guía a los lectores a través de la implementación de algoritmos de aprendizaje automático utilizando bibliotecas populares de Python.\\n        *   **Utilidad:** Permite a los estudiantes aplicar los conceptos teóricos a problemas del mundo real.\\n    *   **\"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville (2016)**\\n        *   **Relevancia:** Un recurso exhaustivo sobre el aprendizaje profundo, una subárea clave de la IA.\\n        *   **Utilidad:** Proporciona una comprensión profunda de las redes neuronales y sus aplicaciones.\\n    *   **\"AI Ethics\" edited by Mark Coeckelbergh (2020)**\\n        *   **Relevancia:** Una colección de ensayos que exploran las consideraciones éticas de la IA.\\n        *   **Utilidad:** Sensibiliza a los estudiantes sobre las implicaciones sociales y morales de la IA.\\n\\n**2. Artículos Académicos Relevantes y Actualizados:**\\n\\n*   **Relevancia General:** Los artículos académicos ofrecen la información más reciente sobre investigaciones y avances en IA. Se recomienda buscar en bases de datos como:\\n    *   **IEEE Xplore:** Amplia colección de artículos de ingeniería y computación.\\n    *   **ACM Digital Library:** Recursos de la Association for Computing Machinery.\\n    *   **arXiv:** Repositorio de preprints en física, matemáticas, informática y áreas relacionadas.\\n*   **Ejemplos Específicos (Sujetos a Actualización):**\\n    *   **\"Attention is All You Need\" by Ashish Vaswani et al. (2017):** Presenta la arquitectura Transformer, fundamental para el procesamiento del lenguaje natural.\\n        *   **Relevancia:** Introduce un mecanismo clave para el avance del NLP.\\n        *   **Utilidad:** Comprender la base de modelos como BERT y GPT.\\n    *   **\"Generative Adversarial Nets\" by Ian J. Goodfellow et al. (2014):** Introduce las Redes Generativas Antagónicas (GANs).\\n        *   **Relevancia:** Marca un hito en la generación de contenido realista.\\n        *   **Utilidad:** Comprender los principios detrás de la generación de imágenes, música y texto.\\n    *   **Artículos sobre \"Explainable AI (XAI)\":** Investigar artículos recientes sobre métodos para hacer que los modelos de IA sean más transparentes y comprensibles.\\n        *   **Relevancia:** Aborda la creciente preocupación por la interpretabilidad de la IA.\\n        *   **Utilidad:** Comprender cómo se toman las decisiones de IA y cómo mitigar los sesgos.\\n\\n**3. Recursos en Línea de Calidad:**\\n\\n*   **Cursos:**\\n    *   **\"Machine Learning\" by Andrew Ng (Coursera):** Un curso introductorio popular que cubre los fundamentos del aprendizaje automático.\\n        *   **Relevancia:** Proporciona una base sólida en los algoritmos de aprendizaje automático.\\n        *   **Utilidad:** Ideal para principiantes con poca o ninguna experiencia previa.\\n    *   **\"Deep Learning Specialization\" (Coursera):** Una serie de cursos que profundizan en el aprendizaje profundo.\\n        *   **Relevancia:** Cubre temas avanzados como redes neuronales convolucionales, redes recurrentes y modelos generativos.\\n        *   **Utilidad:** Permite a los estudiantes desarrollar habilidades prácticas en el aprendizaje profundo.\\n    *   **\"Artificial Intelligence (AI)\" (edX):** Ofrecido por universidades de prestigio.\\n        *   **Relevancia:** Amplio espectro de temas en IA.\\n        *   **Utilidad:** Proporciona una visión general completa del campo.\\n*   **Tutoriales:**\\n    *   **TensorFlow Tutorials:** Tutoriales oficiales de Google sobre el uso de TensorFlow, una biblioteca popular de aprendizaje automático.\\n        *   **Relevancia:** Proporciona ejemplos prácticos de cómo implementar algoritmos de aprendizaje automático con TensorFlow.\\n        *   **Utilidad:** Permite a los estudiantes desarrollar habilidades prácticas en el uso de TensorFlow.\\n    *   **PyTorch Tutorials:** Tutoriales oficiales de PyTorch, otra biblioteca popular de aprendizaje automático.\\n        *   **Relevancia:** Similar a los tutoriales de TensorFlow, pero con un enfoque diferente.\\n        *   **Utilidad:** Permite a los estudiantes desarrollar habilidades prácticas en el uso de PyTorch.\\n*   **Videos:**\\n    *   **YouTube Channels:** Canales como \"Two Minute Papers\", \"Lex Fridman Podcast\", \"Siraj Raval\" (con precaución, algunos contenidos pueden ser menos rigurosos).\\n        *   **Relevancia:** Ofrecen explicaciones visuales y entrevistas con expertos en IA.\\n        *   **Utilidad:** Ayudan a los estudiantes a comprender los conceptos de IA de una manera más intuitiva.\\n\\n**4. Herramientas o Software Relevantes:**\\n\\n*   **Python:** El lenguaje de programación dominante en IA.\\n    *   **Relevancia:** Amplia disponibilidad de bibliotecas y frameworks.\\n    *   **Utilidad:** Fundamental para la implementación de algoritmos de IA.\\n*   **Jupyter Notebook:** Un entorno interactivo para escribir y ejecutar código Python.\\n    *   **Relevancia:** Facilita la experimentación y el prototipado.\\n    *   **Utilidad:** Ideal para aprender y explorar conceptos de IA.\\n*   **Scikit-learn:** Una biblioteca de aprendizaje automático de código abierto para Python.\\n    *   **Relevancia:** Proporciona una amplia gama de algoritmos de aprendizaje automático.\\n    *   **Utilidad:** Permite a los estudiantes implementar y evaluar modelos de aprendizaje automático.\\n*   **TensorFlow:** Un framework de aprendizaje automático desarrollado por Google.\\n    *   **Relevancia:** Ampliamente utilizado en la industria y la investigación.\\n    *   **Utilidad:** Permite a los estudiantes desarrollar aplicaciones de aprendizaje automático a gran escala.\\n*   **PyTorch:** Un framework de aprendizaje automático desarrollado por Facebook.\\n    *   **Relevancia:** Popular en la investigación y conocido por su flexibilidad.\\n    *   **Utilidad:** Permite a los estudiantes desarrollar modelos de aprendizaje automático complejos.\\n\\n**5. Recursos para Diferentes Niveles de Conocimiento Previo:**\\n\\n*   **Principiantes Absolutos:**\\n    *   Cursos introductorios como \"Machine Learning\" de Andrew Ng (Coursera).\\n    *   Tutoriales básicos de Python.\\n    *   Libros de texto introductorios con un enfoque en los conceptos.\\n*   **Estudiantes con Conocimientos de Programación:**\\n    *   Cursos más avanzados como \"Deep Learning Specialization\" (Coursera).\\n    *   Tutoriales de TensorFlow y PyTorch.\\n    *   Libros de texto que cubren temas más avanzados.\\n*   **Estudiantes con Conocimientos de Matemáticas y Estadística:**\\n    *   Artículos académicos sobre temas específicos de IA.\\n    *   Libros de texto que profundizan en los fundamentos matemáticos de la IA.\\n\\n**Recursos Adicionales Específicos por Tema:**\\n\\n**A. Historia de la IA:**\\n\\n*   **Libros:**\\n    *   \"Machines Who Think\" by Pamela McCorduck (2004): Un relato completo de la historia de la IA.\\n    *   \"The Quest for Artificial Intelligence\" by Nils J. Nilsson (2009): Una perspectiva histórica de un investigador pionero.\\n*   **Artículos:**\\n    *   Artículos de revisión sobre la evolución de las técnicas de IA (buscar en IEEE Xplore o ACM Digital Library).\\n*   **Videos:**\\n    *   Documentales sobre la historia de la IA (buscar en YouTube).\\n    *   Entrevistas con pioneros de la IA (buscar en YouTube).\\n\\n**B. Agentes Inteligentes:**\\n\\n*   **Libros:**\\n    *   \"Artificial Intelligence: A Modern'},\n",
              " '2': {'lecture_notes': \"¡Excelente! Vamos a crear unas notas de clase detalladas sobre algoritmos de búsqueda para un curso universitario introductorio a la Inteligencia Artificial.\\n\\n**Notas de Clase: Algoritmos de Búsqueda**\\n\\n**Curso:** Introducción a la Inteligencia Artificial\\n**Código:** [Dejar espacio para el código del curso]\\n**Tema:** Algoritmos de Búsqueda\\n\\n**Introducción**\\n\\nLa búsqueda es un proceso fundamental en la Inteligencia Artificial (IA) que implica explorar un espacio de posibles soluciones para encontrar la mejor solución a un problema dado. Un algoritmo de búsqueda define la estrategia para explorar este espacio.  En muchos problemas de IA, la solución no es directamente computable, sino que debe ser encontrada a través de la exploración y evaluación de alternativas. Los algoritmos de búsqueda proporcionan métodos sistemáticos para realizar esta exploración de manera eficiente.\\n\\n**1. Búsqueda No Informada (Búsqueda a Ciegas)**\\n\\nLa búsqueda no informada, también conocida como búsqueda a ciegas, no utiliza información específica sobre el problema más allá de la definición del problema en sí. Estos algoritmos exploran el espacio de búsqueda de forma sistemática, pero sin una guía que les indique qué caminos son más prometedores.\\n\\n*   **Definición:** Algoritmos que exploran el espacio de búsqueda sin conocimiento previo del problema, excepto la definición del mismo.\\n\\n*   **Tipos Principales:**\\n\\n    *   **Búsqueda en Amplitud (Breadth-First Search - BFS):**\\n        *   **Descripción:** Explora todos los nodos a una profundidad dada antes de pasar a la siguiente profundidad.  Utiliza una cola (FIFO - First-In, First-Out) para gestionar los nodos a explorar.\\n        *   **Características:**\\n            *   Completa: Encuentra una solución si existe (si el factor de ramificación es finito).\\n            *   Óptima: Encuentra la solución más cercana a la raíz (si el costo de cada paso es el mismo).\\n            *   Complejidad Temporal: O(b<sup>d</sup>), donde *b* es el factor de ramificación y *d* es la profundidad de la solución.\\n            *   Complejidad Espacial: O(b<sup>d</sup>) (almacena todos los nodos en el nivel actual).\\n        *   **Ejemplo:** Encontrar la ruta más corta en un grafo donde todos los caminos tienen la misma longitud.\\n        *   **Caso de Aplicación:** Sistemas de recomendación básicos donde se exploran conexiones de primer nivel antes de avanzar a niveles más profundos.\\n\\n    *   **Búsqueda en Profundidad (Depth-First Search - DFS):**\\n        *   **Descripción:** Explora un camino hasta su final antes de retroceder y explorar otro camino. Utiliza una pila (LIFO - Last-In, First-Out) para gestionar los nodos a explorar.\\n        *   **Características:**\\n            *   Incompleta: Puede no encontrar una solución si el espacio de búsqueda es infinito o contiene ciclos.\\n            *   No Óptima: No garantiza encontrar la solución más cercana a la raíz.\\n            *   Complejidad Temporal: O(b<sup>m</sup>), donde *b* es el factor de ramificación y *m* es la profundidad máxima del árbol de búsqueda.\\n            *   Complejidad Espacial: O(bm) (solo necesita almacenar el camino actual).\\n        *   **Ejemplo:** Resolver un laberinto, explorando cada camino hasta encontrar la salida o llegar a un callejón sin salida.\\n        *   **Caso de Aplicación:** Análisis de dependencias en compiladores, detección de ciclos en grafos.\\n\\n    *   **Búsqueda en Profundidad Iterativa (Iterative Deepening Depth-First Search - IDDFS):**\\n        *   **Descripción:** Realiza una serie de búsquedas en profundidad, cada una con un límite de profundidad creciente.\\n        *   **Características:**\\n            *   Completa: Encuentra una solución si existe.\\n            *   Óptima: Encuentra la solución más cercana a la raíz (si el costo de cada paso es el mismo).\\n            *   Complejidad Temporal: O(b<sup>d</sup>) (asintóticamente igual a BFS).\\n            *   Complejidad Espacial: O(bd) (similar a DFS).\\n        *   **Ejemplo:** Similar a BFS, pero con la eficiencia espacial de DFS.\\n        *   **Caso de Aplicación:**  Problemas donde la profundidad de la solución no se conoce de antemano y se busca una solución óptima en un espacio de búsqueda grande.\\n\\n    *   **Búsqueda de Costo Uniforme (Uniform Cost Search - UCS):**\\n        *   **Descripción:** Expande el nodo con el costo de camino más bajo desde el nodo inicial. Utiliza una cola de prioridad para gestionar los nodos a explorar.\\n        *   **Características:**\\n            *   Completa: Encuentra una solución si existe y el costo de cada paso es mayor que cero.\\n            *   Óptima: Encuentra la solución de menor costo.\\n            *   Complejidad Temporal: O(b<sup>C*/ε</sup>), donde C* es el costo de la solución óptima y ε es el costo mínimo de un paso.\\n            *   Complejidad Espacial: O(b<sup>C*/ε</sup>).\\n        *   **Ejemplo:** Encontrar la ruta más barata entre dos ciudades, donde cada ruta tiene un costo diferente.\\n        *   **Caso de Aplicación:** Planificación de rutas en sistemas de navegación con diferentes costos asociados a cada tramo.\\n\\n*   **Limitaciones:** La búsqueda no informada puede ser ineficiente en espacios de búsqueda grandes, ya que explora todas las posibilidades sin una dirección clara.\\n\\n**2. Búsqueda Heurística (Búsqueda Informada)**\\n\\nLa búsqueda heurística utiliza información específica del problema (heurísticas) para guiar la búsqueda y explorar los caminos más prometedores.\\n\\n*   **Definición:** Algoritmos que utilizan conocimiento específico del problema, en forma de heurísticas, para guiar la búsqueda.\\n\\n*   **Heurística:** Una función heurística *h(n)* estima el costo de la ruta más barata desde el nodo *n* hasta un nodo objetivo.  Una buena heurística debe ser rápida de calcular y proporcionar una estimación razonable del costo real.\\n\\n*   **Tipos Principales:**\\n\\n    *   **Búsqueda Voraz (Greedy Best-First Search):**\\n        *   **Descripción:** Expande el nodo que parece estar más cerca del objetivo, según la función heurística *h(n)*.\\n        *   **Características:**\\n            *   Incompleta: Puede no encontrar una solución si se atasca en un camino no prometedor.\\n            *   No Óptima: No garantiza encontrar la solución de menor costo.\\n            *   Complejidad Temporal: O(b<sup>m</sup>), en el peor caso, pero puede ser mucho mejor con una buena heurística.\\n            *   Complejidad Espacial: O(b<sup>m</sup>).\\n        *   **Ejemplo:** Encontrar la ruta más corta entre dos ciudades usando la distancia en línea recta como heurística.\\n        *   **Caso de Aplicación:** Sistemas de navegación donde se priorizan las rutas que parecen más directas al destino.\\n\\n**3. Algoritmo A***\\n\\nEl algoritmo A* es uno de los algoritmos de búsqueda heurística más ampliamente utilizados. Combina el costo del camino recorrido hasta el momento con una estimación del costo restante para llegar al objetivo.\\n\\n*   **Definición:** Un algoritmo de búsqueda informada que utiliza una función de evaluación *f(n) = g(n) + h(n)* para guiar la búsqueda, donde *g(n)* es el costo del camino desde el nodo inicial hasta el nodo *n*, y *h(n)* es una heurística que estima el costo del camino desde el nodo *n* hasta el nodo objetivo.\\n\\n*   **Características:**\\n\\n    *   Completa: Encuentra una solución si existe.\\n    *   Óptima: Encuentra la solución de menor costo si la heurística *h(n)* es *admisible*.\\n    *   Admisibilidad: Una heurística es admisible si nunca sobreestima el costo real para alcanzar el objetivo.  Es decir, *h(n) ≤ h*(n)*, donde *h*(n)* es el costo real del camino óptimo desde *n* hasta el objetivo.\\n    *   Consistencia (o monotonicidad): Una heurística es consistente si *h(n) ≤ c(n, a, n') + h(n')*, donde *c(n, a, n')* es el costo de la acción *a* desde el nodo *n* hasta el nodo *n'*.  Una heurística consistente es también admisible.\\n    *   Complejidad Temporal: Depende de la heurística. En el peor caso, puede ser exponencial.\\n    *   Complejidad Espacial: O(b<sup>d</sup>) en el peor caso.\\n\\n*   **Ejemplo:** Planificación de rutas en un mapa utilizando la distancia en línea recta como heurística admisible.\\n\\n*   **Caso de Aplicación:**\\n    *   **Navegación robótica:** Planificación de movimientos para robots en entornos complejos.\\n    *   **Planificación de juegos:** Desarrollo de estrategias para personajes en videojuegos.\\n    *   **Optimización de rutas logísticas:** Encontrar las rutas más eficientes para la entrega de productos.\\n\\n**4. Optimización con Algoritmos Genéticos**\\n\\nLos algoritmos genéticos (AGs) son una técnica de búsqueda inspirada en la evolución biológica. Se utilizan para encontrar soluciones óptimas en problemas complejos donde los métodos de búsqueda tradicionales pueden ser ineficientes.\\n\\n*   **Definición:** Un algoritmo de búsqueda heurística que imita el proceso de selección natural para encontrar soluciones óptimas.\\n\\n*   **Conceptos Clave:**\\n\\n    *   **Población:** Un conjunto de posibles soluciones (individuos).\\n    *   **Cromosoma:** Representación de una solución (generalmente una cadena de bits o números).\\n    *   **Función de Aptitud (Fitness):** Evalúa la calidad de una solución.\\n    *   **Selección:** Proceso de elegir individuos para reproducirse, basándose en su aptitud.\\n    *   **Cruce (Crossover):** Combina la información genética de dos padres para crear nuevos individuos.\\n    *   **Mutación:** Introduce cambios aleatorios en los cromosomas para mantener la diversidad.\\n\\n*   **Proceso General:**\\n\\n    1.  **Inicialización:** Crear una población inicial de soluciones aleatorias.\\n    2.  **Evaluación:** Calcular la aptitud de cada individuo en la población.\\n    3.  **Selección:** Seleccionar individuos para reproducirse, basándose en su aptitud.\\n    4.  **Cruce:** Combinar la información genética de los padres seleccionados para crear nuevos individuos (hijos).\\n    5.  **Mutación:** Introducir cambios aleatorios en los cromosomas de los hijos.\\n    6.  **Reemplazo:** Reemplazar la población actual con la nueva población de hijos.\\n    7.  **Repetición:** Repetir los pasos 2-6 hasta que se alcance un criterio de terminación (por ejemplo, un número máximo de generaciones o una solución suficientemente buena).\\n\\n*   **Ejemplo:** Optimizar el diseño de un puente para que sea lo más resistente posible con la menor cantidad de material.\\n\\n*   **Casos de Aplicación:**\\n\\n    *   **Optimización de horarios:** Creación de horarios eficientes para transporte público o personal.\\n    *   **Diseño de circuitos electrónicos:** Optimización de la disposición de los componentes para minimizar el consumo de energía.\\n    *   **Aprendizaje automático:** Ajuste de los parámetros de un modelo de aprendizaje automático.\\n    *   **Robótica:** Planificación de trayectorias óptimas para robots.\\n\\n**Conclusión**\\n\\nLos algoritmos de búsqueda son herramientas esenciales en la Inteligencia Artificial. La elección del algoritmo adecuado depende del problema específico, la disponibilidad de información heurística y las restricciones de tiempo y espacio.  Comprender las fortalezas y debilidades de cada tipo de algoritmo es crucial para diseñar sistemas de IA eficientes y efectivos.\\n\",\n",
              "  'practice_problems': '¡Excelente! Aquí tienes un conjunto de problemas de práctica sobre algoritmos de búsqueda, diseñados para un curso universitario, con soluciones paso a paso y diferentes niveles de dificultad.\\n\\n**Curso:** Algoritmos y Estructuras de Datos / Inteligencia Artificial (dependiendo del enfoque)\\n\\n**Tema:** Algoritmos de Búsqueda\\n\\n**Objetivo:** Que los estudiantes comprendan y apliquen diferentes algoritmos de búsqueda, incluyendo búsquedas no informadas, heurísticas y optimización con algoritmos genéticos.\\n\\n---\\n\\n**Problemas de Práctica:**\\n\\n**1. Búsqueda No Informada (Nivel Básico)**\\n\\n*   **Problema:**  Dado el siguiente grafo no dirigido:\\n\\n    ```\\n    A -- B -- C\\n    |    |    |\\n    D -- E -- F\\n    |    |    |\\n    G -- H -- I\\n    ```\\n\\n    Utiliza el algoritmo de Búsqueda en Anchura (BFS) para encontrar el camino desde el nodo \\'A\\' al nodo \\'I\\'.  Muestra el orden en que se exploran los nodos.\\n\\n*   **Solución:**\\n\\n    1.  **Inicialización:** Cola = [A], Visitados = {A}\\n    2.  **Iteración 1:**\\n        *   Desencolar A.  Vecinos de A: B, D, G.\\n        *   Encolar B, D, G (en ese orden).  Visitados = {A, B, D, G}\\n        *   Cola = [B, D, G]\\n    3.  **Iteración 2:**\\n        *   Desencolar B. Vecinos de B: A, C, E.  A ya está visitado.\\n        *   Encolar C, E. Visitados = {A, B, D, G, C, E}\\n        *   Cola = [D, G, C, E]\\n    4.  **Iteración 3:**\\n        *   Desencolar D. Vecinos de D: A, E, G. A, G ya visitados.\\n        *   Encolar E (ya está en la cola, por lo que no se duplica). Visitados = {A, B, D, G, C, E}\\n        *   Cola = [G, C, E]\\n    5.  **Iteración 4:**\\n        *   Desencolar G. Vecinos de G: A, D, H. A, D ya visitados.\\n        *   Encolar H. Visitados = {A, B, D, G, C, E, H}\\n        *   Cola = [C, E, H]\\n    6.  **Iteración 5:**\\n        *   Desencolar C. Vecinos de C: B, F. B ya visitado.\\n        *   Encolar F. Visitados = {A, B, D, G, C, E, H, F}\\n        *   Cola = [E, H, F]\\n    7.  **Iteración 6:**\\n        *   Desencolar E. Vecinos de E: B, D, H. B, D ya visitados.\\n        *   Encolar H (ya está en la cola). Visitados = {A, B, D, G, C, E, H, F}\\n        *   Cola = [H, F]\\n    8.  **Iteración 7:**\\n        *   Desencolar H. Vecinos de H: G, E, I. G, E ya visitados.\\n        *   Encolar I. Visitados = {A, B, D, G, C, E, H, F, I}\\n        *   Cola = [F, I]\\n    9.  **Iteración 8:**\\n        *   Desencolar F. Vecinos de F: C, E, I. C, E ya visitados.\\n        *   Encolar I (ya está en la cola). Visitados = {A, B, D, G, C, E, H, F, I}\\n        *   Cola = [I]\\n    10. **Iteración 9:**\\n        *   Desencolar I.  ¡Objetivo encontrado!\\n\\n    **Camino encontrado (reconstruyendo desde I): I <- H <- G <- A  (o  I <- F <- C <- B <- A.  BFS puede dar múltiples caminos óptimos)**\\n\\n    **Orden de exploración:** A, B, D, G, C, E, H, F, I\\n\\n**2. Búsqueda Heurística (Nivel Intermedio)**\\n\\n*   **Problema:** Considera el problema del 8-puzzle.  El estado inicial es:\\n\\n    ```\\n    2 8 3\\n    1 6 4\\n    7 _ 5\\n    ```\\n\\n    El estado objetivo es:\\n\\n    ```\\n    1 2 3\\n    8 _ 4\\n    7 6 5\\n    ```\\n\\n    Utiliza el algoritmo de Búsqueda Avariciosa Primero el Mejor (Greedy Best-First Search) con la heurística \"número de piezas fuera de lugar\" para encontrar una solución. Muestra los primeros tres nodos expandidos.\\n\\n*   **Solución:**\\n\\n    1.  **Estado Inicial:**\\n        *   Heurística (h): 5 (5 piezas fuera de lugar)\\n        *   Cola de Prioridad: [(Estado Inicial, h=5)]\\n\\n    2.  **Expandir Estado Inicial:**\\n        *   Movimientos posibles: Mover el espacio en blanco hacia arriba o hacia la derecha.\\n        *   **Estado 1 (Mover arriba):**\\n\\n            ```\\n            2 8 3\\n            1 _ 4\\n            7 6 5\\n            ```\\n\\n            *   h = 4\\n        *   **Estado 2 (Mover derecha):**\\n\\n            ```\\n            2 8 3\\n            1 6\\n            7 5 4\\n            ```\\n            *   h = 5\\n\\n        *   Cola de Prioridad: [(Estado 1, h=4), (Estado 2, h=5)]\\n\\n    3.  **Expandir Estado 1 (Mover arriba):**\\n        *   Se selecciona Estado 1 porque tiene la heurística más baja.\\n        *   Movimientos posibles: Mover el espacio en blanco hacia abajo, izquierda o derecha.\\n        *   **Estado 3 (Mover abajo):**\\n\\n            ```\\n            2 8 3\\n            1 6 4\\n            7 _ 5\\n            ```\\n\\n            *   h = 5 (Este es el estado inicial, evitar expandir nodos ya visitados en una implementación real)\\n\\n        *   **Estado 4 (Mover izquierda):**\\n\\n            ```\\n            2 8 3\\n            _ 1 4\\n            7 6 5\\n            ```\\n            *   h = 4\\n        *   **Estado 5 (Mover derecha):**\\n\\n            ```\\n            2 8 3\\n            1 4 _\\n            7 6 5\\n            ```\\n\\n            *   h = 4\\n\\n        *   Cola de Prioridad: [(Estado 4, h=4), (Estado 5, h=4), (Estado 2, h=5), (Estado 3, h=5)]\\n\\n    **Primeros tres nodos expandidos:** Estado Inicial, Estado 1, Estado 4 (o Estado 5, dependiendo del orden en que se generen los nodos).\\n\\n**3. Algoritmo A* (Nivel Intermedio/Avanzado)**\\n\\n*   **Problema:**  Considera el siguiente grafo con costos asociados a cada arista y una heurística estimada para cada nodo hasta el nodo objetivo \\'G\\':\\n\\n    ```\\n    A --5-- B --4-- C\\n    |      |      |\\n    6      2      4\\n    |      |      |\\n    D --3-- E --2-- F --1-- G\\n    ```\\n\\n    Heurísticas: h(A) = 7, h(B) = 5, h(C) = 3, h(D) = 4, h(E) = 2, h(F) = 1, h(G) = 0\\n\\n    Utiliza el algoritmo A* para encontrar el camino más corto desde el nodo \\'A\\' al nodo \\'G\\'. Muestra la evolución de la cola de prioridad y el camino resultante.\\n\\n*   **Solución:**\\n\\n    1.  **Inicialización:** Cola de Prioridad = [(A, f=7, g=0)], Visitados = {}\\n    2.  **Iteración 1:**\\n        *   Expandir A.\\n        *   Vecinos: B (costo 5), D (costo 6)\\n        *   B: g(B) = 5, h(B) = 5, f(B) = 10\\n        *   D: g(D) = 6, h(D) = 4, f(D) = 10\\n        *   Cola de Prioridad = [(D, f=10, g=6), (B, f=10, g=5)]  (ordenados por f)\\n        *   Visitados = {A}\\n    3.  **Iteración 2:**\\n        *   Expandir D.\\n        *   Vecinos: A (ya visitado), E (costo 3)\\n        *   E: g(E) = 6 + 3 = 9, h(E) = 2, f(E) = 11\\n        *   Cola de Prioridad = [(B, f=10, g=5), (E, f=11, g=9)]\\n        *   Visitados = {A, D}\\n    4.  **Iteración 3:**\\n        *   Expandir B.\\n        *   Vecinos: A (ya visitado), C (costo 4), E (costo 2)\\n        *   C: g(C) = 5 + 4 = 9, h(C) = 3, f(C) = 12\\n        *   E: g(E) = 5 + 2 = 7, h(E) = 2, f(E) = 9\\n        *   Cola de Prioridad = [(E, f=9, g=7), (E, f=11, g=9), (C, f=12, g=9)]  (Hay dos nodos E, uno viene de D y otro de B)\\n        *   Visitados = {A, D, B}\\n    5.  **Iteración 4:**\\n        *   Expandir E (el E con f=9, g=7).\\n        *   Vecinos: B (ya visitado), D (ya visitado), F (costo 2)\\n        *   F: g(F) = 7 + 2 = 9, h(F) = 1, f(F) = 10\\n        *   Cola de Prioridad = [(F, f=10, g=9), (E, f=11, g=9), (C, f=12, g=9)]\\n        *   Visitados = {A, D, B, E}\\n    6.  **Iteración 5:**\\n        *   Expandir F.\\n        *   Vecinos: E (ya visitado), G (costo 1)\\n        *   G: g(G) = 9 + 1 = 10, h(G) = 0, f(G) = 10\\n        *   Cola de Prioridad = [(G, f=10, g=10), (E, f=11, g=9), (C, f=12, g=9)]\\n        *   Visitados = {A, D, B, E, F}\\n    7.  **Iteración 6:**\\n        *   Expandir G.  ¡Objetivo encontrado!\\n\\n    **Camino encontrado:** A -> B -> E -> F -> G\\n\\n    **Costo del camino:** 5 + 2 + 2 + 1 = 10\\n\\n**4. Algoritmos Genéticos (Nivel Avanzado)**\\n\\n*   **Problema:**  Tienes el problema del Viajante de Comercio (TSP) con las siguientes ciudades y distancias (matriz de adyacencia):\\n\\n    ```\\n         A  B  C  D\\n    A   0  10 15 20\\n    B  10  0  35 25\\n    C  15 35  0  30\\n    D  20 25  30  0\\n    ```\\n\\n    Implementa un algoritmo genético simple para encontrar una ruta (ciclo) aproximada de costo mínimo que visite cada ciudad exactamente una vez y regrese a la ciudad de inicio (A).\\n\\n    *   **Representación:** Una ruta es una permutación de las ciudades (ej: [A, B, C, D]).\\n    *   **Función de Aptitud (Fitness):** El inverso del costo total de la ruta (mayor fitness = mejor ruta).\\n    *   **Selección:** Selección por ruleta (probabilidad proporcional a la aptitud).\\n    *   **Cruce (Crossover):** Cruce de un punto (elige un punto aleatorio y combina las dos partes de los padres).\\n    *   **Mutación:** Intercamb',\n",
              "  'discussion_questions': '¡Excelente! Aquí tienes un conjunto de preguntas para discusión sobre algoritmos de búsqueda, diseñadas para fomentar el pensamiento crítico, el debate y la conexión con aplicaciones reales, implicaciones éticas y otros temas del curso.\\n\\n**Tema: Algoritmos de Búsqueda (Búsqueda no informada, Búsqueda heurística, Algoritmo A*, Optimización con Algoritmos Genéticos)**\\n\\n**Preguntas para Discusión:**\\n\\n1.  **Pregunta:** La búsqueda no informada, como BFS y DFS, a menudo se describe como \"ciega\". ¿En qué situaciones podría ser ventajoso utilizar una búsqueda no informada en lugar de una búsqueda informada (heurística), incluso si la búsqueda informada es teóricamente más eficiente? Considera escenarios donde la función heurística podría ser costosa de calcular o poco confiable.\\n\\n    **Nota para el Instructor:**\\n    *   **Puntos Clave:** Animar a los estudiantes a pensar en los costos computacionales de la heurística. Explorar escenarios donde la simplicidad de la búsqueda no informada supera la posible ineficiencia, como en espacios de búsqueda muy pequeños o donde la heurística es propensa a errores. Considerar el impacto de la representación del problema en la elección del algoritmo.\\n\\n2.  **Pregunta:** Las heurísticas son fundamentales para la eficiencia de los algoritmos de búsqueda informada.  ¿Cómo determinaría si una heurística dada es admisible y consistente? ¿Qué implicaciones tiene la admisibilidad y la consistencia en la optimalidad de la solución encontrada por el algoritmo A*? Da un ejemplo de una heurística que sea admisible pero no consistente.\\n\\n    **Nota para el Instructor:**\\n    *   **Puntos Clave:** Asegurarse de que los estudiantes comprendan las definiciones formales de admisibilidad y consistencia. Discutir cómo la inconsistencia puede llevar a A* a reabrir nodos previamente expandidos, afectando su eficiencia.  Proporcionar o pedir a los estudiantes que generen ejemplos concretos.\\n\\n3.  **Pregunta:** El algoritmo A* se considera óptimo bajo ciertas condiciones. Sin embargo, en problemas del mundo real, a menudo se utilizan variantes aproximadas de A*, como Weighted A*, o algoritmos que sacrifican la optimalidad por la velocidad. ¿En qué situaciones estaría justificado sacrificar la optimalidad en la búsqueda de una solución?  Considera aplicaciones como la planificación de rutas en videojuegos o la navegación en robots en tiempo real.\\n\\n    **Nota para el Instructor:**\\n    *   **Puntos Clave:** Introducir el concepto de \"optimalidad aceptable\" en contextos del mundo real. Discutir las limitaciones de tiempo y recursos que pueden hacer que una solución subóptima pero rápida sea preferible a una solución óptima pero tardía.  Explorar el concepto de *bounded rationality*.\\n\\n4.  **Pregunta:** Los algoritmos genéticos (AGs) ofrecen un enfoque diferente a la búsqueda y optimización en comparación con A*. ¿Cuáles son las principales ventajas y desventajas de los AGs en comparación con A*? ¿En qué tipos de problemas podría ser más apropiado utilizar un AG en lugar de A*, y viceversa?\\n\\n    **Nota para el Instructor:**\\n    *   **Puntos Clave:** Comparar la naturaleza probabilística de los AGs con la búsqueda sistemática de A*.  Discutir la capacidad de los AGs para manejar espacios de búsqueda complejos y no convexos, así como su susceptibilidad a converger a óptimos locales. A* es más adecuado cuando se requiere una solución óptima y el espacio de búsqueda puede representarse de manera eficiente.\\n\\n5.  **Pregunta:**  Considera el problema de diseñar un sistema de recomendación de películas. ¿Cómo podrías aplicar algoritmos de búsqueda y optimización (por ejemplo, A* o algoritmos genéticos) para encontrar las películas más relevantes para un usuario en particular, dadas sus preferencias históricas? ¿Qué desafíos éticos podrían surgir al utilizar estos algoritmos en este contexto?\\n\\n    **Nota para el Instructor:**\\n    *   **Puntos Clave:** Animar a los estudiantes a pensar en cómo representar las preferencias del usuario y las características de las películas como un espacio de búsqueda. Discutir cómo la heurística (en el caso de A*) o la función de aptitud (en el caso de los AGs) podrían diseñarse para reflejar la relevancia. Abordar las preocupaciones éticas relacionadas con el sesgo algorítmico, la privacidad del usuario y la creación de \"burbujas de filtro\".\\n\\n6.  **Pregunta:**  La búsqueda heurística y los algoritmos genéticos son ampliamente utilizados en inteligencia artificial. ¿Cómo se relacionan estos algoritmos con otros temas que hemos cubierto en el curso, como el aprendizaje automático o la planificación? ¿Podrías dar ejemplos concretos de cómo estos algoritmos podrían integrarse con otras técnicas de IA para resolver problemas complejos?\\n\\n    **Nota para el Instructor:**\\n    *   **Puntos Clave:**  Facilitar una discusión sobre la sinergia entre diferentes técnicas de IA.  Por ejemplo, la búsqueda heurística podría utilizarse para encontrar la mejor arquitectura para una red neuronal, o los algoritmos genéticos podrían emplearse para optimizar los parámetros de un modelo de aprendizaje automático.  Explorar cómo la planificación (por ejemplo, utilizando algoritmos como STRIPS) podría beneficiarse de la búsqueda heurística para encontrar secuencias de acciones óptimas.\\n\\n7.  **Pregunta:**  Imagina que estás trabajando en un proyecto para desarrollar un sistema de respuesta a emergencias que debe encontrar la ruta más rápida para que los vehículos de emergencia lleguen a una escena. ¿Qué consideraciones prácticas (más allá de la eficiencia algorítmica) serían cruciales para el éxito de este sistema? ¿Cómo abordarías la incertidumbre en la información disponible (por ejemplo, información de tráfico en tiempo real)?\\n\\n    **Nota para el Instructor:**\\n    *   **Puntos Clave:**  Enfatizar la importancia de la robustez y la adaptabilidad en aplicaciones del mundo real.  Discutir cómo incorporar información probabilística y manejar eventos inesperados.  Considerar la necesidad de una interfaz de usuario intuitiva y la integración con otras fuentes de datos.  Esto también puede ser un buen punto para introducir algoritmos de búsqueda en entornos dinámicos.\\n\\nEstas preguntas están diseñadas para ser un punto de partida para un debate profundo y significativo sobre los algoritmos de búsqueda. Anima a los estudiantes a cuestionar los supuestos, a explorar diferentes perspectivas y a aplicar sus conocimientos a problemas del mundo real. ¡Espero que sean útiles!\\n',\n",
              "  'learning_objectives': '¡Excelente! Aquí tienes una propuesta de objetivos de aprendizaje SMART para el tema \"Algoritmos de Búsqueda\", considerando los subtemas mencionados y alineados con los objetivos generales del curso:\\n\\n**Tema: Algoritmos de Búsqueda**\\n\\n**Objetivos de Aprendizaje:**\\n\\n*   **Búsqueda No Informada (Nivel: Conocimiento y Comprensión)**\\n\\n    *   **Objetivo:** *En la próxima evaluación, el estudiante **definirá** los conceptos clave de búsqueda no informada (BFS, DFS, UCS, DLS, IDS) y **comparará** sus características en términos de completitud, optimalidad, complejidad temporal y espacial, obteniendo al menos un 80% de respuestas correctas.* (SMART: Específico, Medible, Alcanzable, Relevante, con Tiempo Definido).\\n\\n*   **Búsqueda Heurística (Nivel: Comprensión y Aplicación)**\\n\\n    *   **Objetivo:** *Después de la clase práctica, el estudiante **explicará** el concepto de heurística y su impacto en la eficiencia de la búsqueda, y **aplicará** al menos dos heurísticas diferentes a un problema de búsqueda dado (e.g., el problema del laberinto), documentando y **justificando** la selección de la heurística en un informe conciso de una página.* (SMART)\\n\\n*   **Algoritmo A* (Nivel: Aplicación y Análisis)**\\n\\n    *   **Objetivo:** *Al finalizar la semana dedicada al algoritmo A*, el estudiante **implementará** el algoritmo A* en Python para resolver el problema del camino más corto en un grafo, **analizando** y **comparando** su rendimiento con la búsqueda no informada (UCS) en términos de nodos expandidos y tiempo de ejecución, presentando los resultados en un informe técnico con gráficos comparativos.* (SMART)\\n\\n*   **Optimización con Algoritmos Genéticos (Nivel: Análisis, Evaluación y Creación)**\\n\\n    *   **Objetivo:** *Al concluir el módulo de algoritmos genéticos, el estudiante **diseñará** e **implementará** un algoritmo genético para resolver un problema de optimización (e.g., el problema de la mochila, el problema del vendedor viajero para un número pequeño de ciudades), **evaluando** diferentes estrategias de selección, cruce y mutación, y **justificando** la configuración final del algoritmo en un informe que demuestre una mejora del 10% en la solución óptima en comparación con una solución aleatoria inicial.* (SMART)\\n\\n**Alineación con los Objetivos Generales del Curso:**\\n\\n*   Estos objetivos contribuyen a la \"Comprensión de los fundamentos teóricos de la IA\" al explorar los principios subyacentes a los algoritmos de búsqueda.\\n*   Se alinean con \"Aplicar algoritmos de búsqueda y optimización\" al exigir la implementación y aplicación práctica de los algoritmos.\\n*   Fomentan el \"Análisis de casos de estudio de aplicaciones reales\" al permitir que los estudiantes exploren problemas de optimización relevantes.\\n*   Preparan el terreno para \"Implementar soluciones simples de PLN\" al proporcionar una base en técnicas de búsqueda que se utilizan en el procesamiento del lenguaje natural.\\n\\n**Notas Adicionales:**\\n\\n*   **Evaluación:** La evaluación de estos objetivos se puede realizar a través de exámenes, tareas de programación, informes técnicos y presentaciones orales.\\n*   **Adaptación:** Estos objetivos son una base y pueden ser adaptados y ajustados para que se adapten mejor a las necesidades específicas del curso y los estudiantes.\\n*   **Claridad:** Es crucial comunicar estos objetivos de aprendizaje a los estudiantes al principio del tema para que comprendan lo que se espera de ellos.\\n\\nEspero que esta propuesta sea útil. ¡No dudes en solicitar más ajustes o refinamientos!\\n',\n",
              "  'suggested_resources': '¡Excelente! Vamos a generar una lista de recursos de aprendizaje robusta y diversificada para el tema de Algoritmos de Búsqueda, cubriendo los aspectos que mencionaste.\\n\\n**Recursos de Aprendizaje para Algoritmos de Búsqueda**\\n\\n**I. Libros de Texto (Principales y Complementarios)**\\n\\n*   **Principal: \"Artificial Intelligence: A Modern Approach\" (Stuart Russell & Peter Norvig, 2020, 4th Edition)**\\n\\n    *   **Relevancia y Utilidad:** Este es un libro de texto fundamental en IA.  Cubre la búsqueda en profundidad, desde búsqueda no informada hasta heurística, incluyendo A*, con explicaciones claras y ejemplos.  Ofrece una base teórica sólida y aborda las complejidades de la implementación.\\n    *   **Nivel:** Intermedio/Avanzado. Requiere conocimientos básicos de estructuras de datos y programación.\\n\\n*   **Principal: \"Introduction to Algorithms\" (Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, Clifford Stein, 2022, 4th Edition)**\\n\\n    *   **Relevancia y Utilidad:**  Aunque no se centra exclusivamente en búsqueda, proporciona una base sólida en análisis de algoritmos y estructuras de datos.  Contiene secciones relevantes sobre búsqueda en grafos y optimización.\\n    *   **Nivel:** Intermedio/Avanzado. Requiere conocimientos sólidos de matemáticas discretas y programación.\\n\\n*   **Complementario: \"Algorithms\" (Robert Sedgewick & Kevin Wayne, 2011, 4th Edition)**\\n\\n    *   **Relevancia y Utilidad:**  Presenta los algoritmos de manera práctica con implementaciones en Java. Tiene un capítulo dedicado a grafos que cubre algoritmos de búsqueda en profundidad y amplitud.\\n    *   **Nivel:** Intermedio. Útil para estudiantes que prefieren un enfoque más práctico con ejemplos de código.\\n\\n*   **Complementario: \"Heuristic Search: Theory and Applications\" (Stefan Edelkamp, Stefan Schroedl, 2011)**\\n\\n    *   **Relevancia y Utilidad:** Se centra en la búsqueda heurística. Cubre algoritmos avanzados como A*, IDA*, y algoritmos de búsqueda local. Es más especializado y adecuado para estudiantes que desean profundizar en la búsqueda heurística.\\n    *   **Nivel:** Avanzado. Requiere conocimientos previos de algoritmos de búsqueda y estructuras de datos.\\n\\n**II. Artículos Académicos Relevantes y Actualizados**\\n\\n*   **\"A Formal Basis for the Heuristic Determination of Minimum Cost Paths\" (Nils J. Nilsson, 1968)**\\n\\n    *   **Relevancia y Utilidad:** Artículo seminal que introduce el algoritmo A*. Es fundamental para comprender los fundamentos teóricos de este algoritmo.\\n    *   **Nivel:** Intermedio/Avanzado.\\n\\n*   **\"Learning Heuristic Functions for Search\" (Shahriar Iravani, Pascal Poupart, 2023)**\\n\\n    *   **Relevancia y Utilidad:** Examina cómo el aprendizaje automático se puede utilizar para aprender funciones heurísticas efectivas para problemas de búsqueda.  Aborda un área activa de investigación.\\n    *   **Nivel:** Avanzado. Requiere conocimientos de aprendizaje automático y algoritmos de búsqueda.\\n\\n*   **\"Genetic Algorithms\" (David E. Goldberg, 1989)**\\n\\n    *   **Relevancia y Utilidad:** Un texto fundamental sobre algoritmos genéticos. Explica los principios básicos, operadores genéticos y aplicaciones.\\n    *   **Nivel:** Intermedio/Avanzado.\\n\\n*   **\"A Fast and Elitist Multiobjective Genetic Algorithm: NSGA-II\" (Kalyanmoy Deb, Amrit Pratap, Sameer Agarwal, T. Meyarivan, 2002)**\\n\\n    *   **Relevancia y Utilidad:** Introduce NSGA-II, un algoritmo genético popular para problemas de optimización multiobjetivo.\\n    *   **Nivel:** Avanzado. Requiere conocimientos de algoritmos genéticos y optimización.\\n\\n*   **\"Real-Time Heuristic Search\" (Koenig, S., & Likhachev, M. 2005)**\\n\\n    *   **Relevancia y Utilidad:** Explora algoritmos de búsqueda heurística en tiempo real, importantes para aplicaciones donde las decisiones deben tomarse rápidamente.\\n    *   **Nivel:** Avanzado. Requiere conocimientos de algoritmos de búsqueda y estructuras de datos.\\n\\n**Dónde Encontrar Artículos Académicos:**\\n\\n*   **Google Scholar:**  Un motor de búsqueda excelente para artículos académicos.\\n*   **IEEE Xplore:**  Base de datos de la IEEE con artículos de ingeniería y computación.\\n*   **ACM Digital Library:**  Biblioteca digital de la Association for Computing Machinery.\\n*   **ScienceDirect:**  Base de datos de Elsevier con artículos científicos.\\n\\n**III. Recursos en Línea de Calidad**\\n\\n*   **Cursos:**\\n    *   **\"Artificial Intelligence (AI)\" (edX, Columbia University):**  Cubre búsqueda y otros temas de IA. (Nivel: Intermedio/Avanzado)\\n    *   **\"Algorithms, Part I\" (Coursera, Princeton University):**  Cubre estructuras de datos y algoritmos fundamentales, incluyendo búsqueda en grafos. (Nivel: Intermedio)\\n    *   **\"Artificial Intelligence Nanodegree\" (Udacity):**  Ofrece un aprendizaje en profundidad con proyectos prácticos. (Nivel: Intermedio/Avanzado)\\n    *   **MIT OpenCourseWare: \"Introduction to Algorithms\" (MIT):** Material del curso de MIT sobre algoritmos. (Nivel: Avanzado)\\n\\n*   **Tutoriales:**\\n    *   **GeeksforGeeks:**  Tiene excelentes tutoriales sobre algoritmos de búsqueda, con ejemplos de código en varios lenguajes. (Nivel: Básico/Intermedio)\\n    *   **Tutorialspoint:**  Ofrece tutoriales concisos sobre algoritmos de búsqueda. (Nivel: Básico/Intermedio)\\n\\n*   **Videos:**\\n    *   **\"A* Pathfinding Tutorial\" (Sebastian Lague):**  Una explicación visual e intuitiva del algoritmo A* en YouTube. (Nivel: Básico/Intermedio)\\n    *   **\"Genetic Algorithms Explained\" (Two Minute Papers):**  Una explicación rápida y visual de algoritmos genéticos. (Nivel: Básico/Intermedio)\\n    *   **Canales de YouTube de universidades (MIT, Stanford, etc.):**  A menudo publican conferencias y tutoriales sobre IA y algoritmos.\\n\\n**IV. Herramientas o Software Relevantes**\\n\\n*   **Lenguajes de Programación:**\\n    *   **Python:** Ampliamente utilizado en IA y tiene bibliotecas como `networkx` para grafos y `scikit-learn` para algoritmos genéticos.\\n    *   **Java:**  Popular para algoritmos y tiene bibliotecas para estructuras de datos y grafos.\\n    *   **C++:**  Ofrece alto rendimiento y control, útil para implementaciones optimizadas.\\n\\n*   **Bibliotecas:**\\n    *   **NetworkX (Python):**  Para trabajar con grafos. Facilita la implementación de algoritmos de búsqueda en grafos.\\n    *   **DEAP (Python):**  Una biblioteca para computación evolutiva, incluyendo algoritmos genéticos.\\n    *   **JMetal (Java):** Un framework para optimización multi-objetivo con algoritmos evolutivos.\\n\\n*   **Entornos de Desarrollo:**\\n    *   **Jupyter Notebook:** Ideal para experimentar con algoritmos y visualizar resultados en Python.\\n    *   **VS Code, IntelliJ IDEA:** IDEs potentes para desarrollo en Python, Java y C++.\\n\\n**V. Recursos para Diferentes Niveles de Conocimiento Previo**\\n\\n*   **Nivel Básico:**\\n    *   Tutoriales introductorios en GeeksforGeeks o Tutorialspoint.\\n    *   Videos explicativos en YouTube (como el de Sebastian Lague sobre A*).\\n    *   Capítulos introductorios de libros de texto como \"Algorithms\" de Sedgewick & Wayne.\\n\\n*   **Nivel Intermedio:**\\n    *   Cursos en Coursera o edX sobre algoritmos o IA.\\n    *   Libro de texto \"Artificial Intelligence: A Modern Approach\" (Russell & Norvig).\\n    *   Experimentación con bibliotecas como NetworkX y DEAP.\\n\\n*   **Nivel Avanzado:**\\n    *   Artículos académicos de investigación.\\n    *   Libro de texto \"Heuristic Search: Theory and Applications\" (Edelkamp & Schroedl).\\n    *   Implementación de algoritmos de búsqueda desde cero en C++.\\n    *   Participación en proyectos de investigación o competiciones de IA.\\n\\n**Recursos Específicos por Tipo de Búsqueda**\\n\\n*   **Búsqueda No Informada (Blind Search):**\\n    *   **Libro:** \"Artificial Intelligence: A Modern Approach\" (Russell & Norvig) - Capítulo sobre búsqueda no informada (BFS, DFS, etc.).\\n    *'},\n",
              " '3': {'lecture_notes': '¡Excelente! Vamos a crear unas notas de clase detalladas sobre Machine Learning Básico, cubriendo Regresión Lineal, Árboles de Decisión y Clustering.  El objetivo es que sean comprensibles, prácticas y aplicables.\\n\\n**Notas de Clase: Machine Learning Básico**\\n\\n**Curso:** [Añadir Título del Curso]\\n**Código:** [Añadir Código del Curso]\\n\\n**Descripción del Curso:** Este curso introductorio cubre los conceptos básicos de la Inteligencia Artificial, incluyendo algoritmos de búsqueda, aprendizaje automático y procesamiento del lenguaje natural. Los estudiantes desarrollarán habilidades prácticas mediante proyectos aplicados.\\n\\n**Tema:** Machine Learning Básico\\n\\n**Introducción**\\n\\nEl Machine Learning (ML), o Aprendizaje Automático, es una rama de la Inteligencia Artificial (IA) que permite a los sistemas aprender de los datos, identificar patrones y tomar decisiones con mínima intervención humana. En lugar de ser programados explícitamente para cada tarea, los algoritmos de ML utilizan datos para mejorar su rendimiento en una tarea específica.\\n\\nEl ML se clasifica principalmente en tres categorías:\\n\\n*   **Aprendizaje Supervisado:** El algoritmo aprende a partir de un conjunto de datos etiquetados, es decir, datos donde se conoce la salida deseada (variable objetivo). El objetivo es aprender una función que mapee las entradas a las salidas. Ejemplos: Regresión Lineal, Árboles de Decisión (para clasificación).\\n\\n*   **Aprendizaje No Supervisado:** El algoritmo aprende a partir de un conjunto de datos no etiquetados, buscando patrones y estructuras inherentes a los datos. Ejemplos: Clustering.\\n\\n*   **Aprendizaje por Refuerzo:** El algoritmo aprende a tomar decisiones mediante la interacción con un entorno, recibiendo recompensas o castigos por sus acciones.\\n\\nEn estas notas, nos centraremos en los dos primeros: Aprendizaje Supervisado (Regresión Lineal, Árboles de Decisión) y Aprendizaje No Supervisado (Clustering).\\n\\n**1. Regresión Lineal**\\n\\n**1.1 Definición**\\n\\nLa Regresión Lineal es un algoritmo de aprendizaje supervisado utilizado para predecir una variable continua (variable dependiente) basándose en una o más variables independientes (variables predictoras). El objetivo es encontrar la mejor línea (en el caso de una variable independiente) o hiperplano (en el caso de múltiples variables independientes) que mejor se ajuste a los datos.\\n\\n**1.2 Tipos de Regresión Lineal**\\n\\n*   **Regresión Lineal Simple:**  Una sola variable independiente.  La ecuación es:\\n\\n    `y = mx + b`\\n\\n    Donde:\\n    *   `y` es la variable dependiente (la que queremos predecir).\\n    *   `x` es la variable independiente (la que usamos para predecir).\\n    *   `m` es la pendiente de la línea (el cambio en `y` por cada unidad de cambio en `x`).\\n    *   `b` es la intersección con el eje y (el valor de `y` cuando `x` es 0).\\n\\n*   **Regresión Lineal Múltiple:** Múltiples variables independientes.  La ecuación es:\\n\\n    `y = b0 + b1x1 + b2x2 + ... + bnxn`\\n\\n    Donde:\\n    *   `y` es la variable dependiente.\\n    *   `x1, x2, ..., xn` son las variables independientes.\\n    *   `b0` es la intersección con el eje y.\\n    *   `b1, b2, ..., bn` son los coeficientes de las variables independientes.\\n\\n**1.3 Cómo Funciona**\\n\\nEl algoritmo de Regresión Lineal busca los valores de los coeficientes (m y b en la regresión simple, b0, b1, b2... en la regresión múltiple) que minimizan una función de costo. La función de costo más común es el Error Cuadrático Medio (MSE - Mean Squared Error), que calcula el promedio de los cuadrados de las diferencias entre los valores predichos y los valores reales.\\n\\n**1.4 Ejemplo Práctico**\\n\\nSupongamos que queremos predecir el precio de una casa (variable dependiente) basándonos en su tamaño en metros cuadrados (variable independiente). Tenemos los siguientes datos:\\n\\n| Tamaño (m²) | Precio (€) |\\n|-------------|-------------|\\n| 50          | 150,000     |\\n| 75          | 225,000     |\\n| 100         | 300,000     |\\n| 125         | 375,000     |\\n| 150         | 450,000     |\\n\\nPodemos usar un algoritmo de Regresión Lineal para encontrar la mejor línea que se ajuste a estos datos.  En este caso sencillo, se puede observar que el precio es aproximadamente 3000€ por metro cuadrado.  Un algoritmo formal encontraría los valores óptimos de `m` y `b` para minimizar el MSE.\\n\\n**1.5 Casos de Aplicación**\\n\\n*   **Predicción de Ventas:** Predecir las ventas futuras basándose en el gasto en publicidad.\\n*   **Análisis Financiero:** Predecir el precio de las acciones basándose en indicadores económicos.\\n*   **Predicción de la Demanda Energética:** Predecir la demanda de energía eléctrica basándose en la temperatura y la hora del día.\\n*   **Estimación de Costos de Proyectos:** Predecir el costo de un proyecto de construcción basándose en el tamaño, los materiales y la mano de obra.\\n\\n**1.6 Ventajas y Desventajas**\\n\\n*   **Ventajas:**\\n    *   Fácil de entender e implementar.\\n    *   Computacionalmente eficiente.\\n    *   Útil para entender la relación entre variables.\\n\\n*   **Desventajas:**\\n    *   Asume una relación lineal entre las variables, lo cual no siempre es cierto.\\n    *   Sensible a los outliers (valores atípicos).\\n    *   Puede sufrir de multicolinealidad (alta correlación entre las variables independientes).\\n\\n**2. Árboles de Decisión**\\n\\n**2.1 Definición**\\n\\nUn Árbol de Decisión es un algoritmo de aprendizaje supervisado que se utiliza tanto para problemas de clasificación (predecir una variable categórica) como de regresión (predecir una variable continua). Representa una estructura de árbol donde cada nodo interno representa una prueba sobre un atributo, cada rama representa el resultado de la prueba y cada nodo hoja representa una decisión o predicción.\\n\\n**2.2 Cómo Funciona**\\n\\nEl algoritmo construye el árbol de arriba hacia abajo (de manera recursiva) seleccionando en cada nodo el atributo que mejor divide los datos.  La \"mejor\" división se determina utilizando métricas como:\\n\\n*   **Entropía e Ganancia de Información (para clasificación):** La entropía mide la impureza de un conjunto de datos. La ganancia de información mide la reducción en la entropía después de dividir los datos en función de un atributo. El algoritmo elige el atributo que maximiza la ganancia de información.\\n\\n*   **Error Cuadrático Medio (MSE) (para regresión):**  Similar a la regresión lineal, el MSE se utiliza para evaluar la calidad de la división en problemas de regresión. El algoritmo busca minimizar el MSE en cada nodo.\\n\\nEl proceso se repite hasta que se cumple una condición de parada, como alcanzar una profundidad máxima del árbol, tener un número mínimo de muestras en un nodo o no poder mejorar la división.\\n\\n**2.3 Ejemplo Práctico**\\n\\nSupongamos que queremos predecir si un cliente comprará un producto online (Sí/No) basándonos en su edad y si ha visitado el sitio web antes.\\n\\n| Edad | Visitó el Sitio Web | Compró |\\n|------|-----------------------|--------|\\n| 25   | Sí                    | Sí     |\\n| 30   | No                    | No     |\\n| 40   | Sí                    | Sí     |\\n| 22   | No                    | No     |\\n| 35   | Sí                    | No     |\\n\\nUn árbol de decisión podría verse así:\\n\\n```\\nSi Edad <= 32.5:\\n    Si Visitó el Sitio Web == Sí:\\n        Predicción: Sí\\n    Si Visitó el Sitio Web == No:\\n        Predicción: No\\nSi Edad > 32.5:\\n    Si Visitó el Sitio Web == Sí:\\n        Predicción: No\\n    Si Visitó el Sitio Web == No:\\n        Predicción: No\\n```\\n\\nEn este ejemplo simplificado, el árbol primero divide los datos basándose en la edad. Si la edad es menor o igual a 32.5, divide aún más basándose en si el cliente visitó el sitio web.\\n\\n**2.4 Casos de Aplicación**\\n\\n*   **Diagnóstico Médico:**  Predecir si un paciente tiene una enfermedad basándose en sus síntomas.\\n*   **Análisis de Riesgo Crediticio:** Predecir si un solicitante de crédito incumplirá con un préstamo.\\n*   **Segmentación de Clientes:**  Identificar grupos de clientes con características similares.\\n*   **Recomendación de Productos:**  Recomendar productos a los clientes basándose en su historial de compras.\\n\\n**2.5 Ventajas y Desventajas**\\n\\n*   **Ventajas:**\\n    *   Fácil de entender e interpretar (especialmente los árboles pequeños).\\n    *   Puede manejar datos numéricos y categóricos.\\n    *   No requiere preprocesamiento extensivo de los datos.\\n\\n*   **Desventajas:**\\n    *   Puede sobreajustar los datos (memorizar los datos de entrenamiento en lugar de generalizar).  Esto se puede mitigar con técnicas de poda (limitar la profundidad del árbol) o usando ensembles de árboles (como Random Forests).\\n    *   Puede ser sensible a pequeñas variaciones en los datos.\\n    *   Tiende a favorecer atributos con muchos niveles.\\n\\n**3. Clustering**\\n\\n**3.1 Definición**\\n\\nEl Clustering (o Agrupamiento) es un algoritmo de aprendizaje no supervisado que busca agrupar datos similares en clusters (grupos). El objetivo es maximizar la similitud dentro de cada cluster y minimizar la similitud entre clusters.\\n\\n**3.2 Algoritmos de Clustering Comunes**\\n\\n*   **K-Means:** Un algoritmo iterativo que asigna cada punto de datos al cluster cuyo centroide (media) es el más cercano.  Requiere especificar el número de clusters (K) de antemano.\\n\\n*   **Clustering Jerárquico:** Construye una jerarquía de clusters.  Puede ser aglomerativo (comienza con cada punto como un cluster individual y los fusiona iterativamente) o divisivo (comienza con un solo cluster que contiene todos los puntos y lo divide iterativamente).\\n\\n*   **DBSCAN (Density-Based Spatial Clustering of Applications with Noise):**  Agrupa los puntos de datos que están densamente agrupados, identificando clusters de forma arbitraria. No requiere especificar el número de clusters de antemano y puede identificar outliers (ruido).\\n\\n**3.3 K-Means en Detalle**\\n\\n1.  **Inicialización:** Seleccionar aleatoriamente K centroides iniciales.\\n2.  **Asignación:** Asignar cada punto de datos al cluster cuyo centroide es el más cercano (usualmente usando la distancia euclidiana).\\n3.  **Actualización:** Recalcular los centroides de cada cluster como la media de los puntos asignados a ese cluster.\\n4.  **Iteración:** Repetir los pasos 2 y 3 hasta que los centroides no cambien significativamente o se alcance un número máximo de iteraciones.\\n\\n**3.4 Ejemplo Práctico**\\n\\nSupongamos que tenemos datos de clientes con dos características: gasto promedio y frecuencia de compra. Queremos segmentar a los clientes en diferentes grupos para dirigir campañas de marketing específicas.\\n\\n| Gasto Promedio (€) | Frecuencia de Compra (por mes) |\\n|----------------------|---------------------------------|\\n| 50                   | 1                               |\\n| 100                  | 2                               |\\n| 20                   | 0.5                             |\\n| 150                  | 3                               |\\n| 75                   | 1.5                             |\\n\\nPodemos usar K-Means para agrupar a estos clientes en, por ejemplo, tres clusters:\\n\\n*   **Cluster 1:** Clientes con bajo gasto y baja frecuencia (clientes ocasionales).\\n*   **Cluster 2:** Clientes con gasto medio y frecuencia media (clientes regulares).\\n*   **Cluster 3:** Clientes con alto gasto y alta frecuencia (clientes VIP).\\n\\n**3.5 Casos de Aplicación**\\n\\n*   **Segmentación de Clientes:** Identificar grupos de clientes con comportamientos similares para campañas de marketing personalizadas.\\n*   **Análisis de Imágenes:** Agrupar píxeles similares en una imagen para segmentar objetos.\\n*   **Detección de Anomalías:** Identificar puntos de datos que no pertenecen a ningún cluster, lo que puede indicar fraude o errores.\\n*   **Agrupamiento de Documentos:** Agrupar documentos similares en función de su contenido.\\n\\n**3.6 Ventajas y Desventajas (K-Means)**\\n\\n*   **Ventajas:**\\n    *   Fácil de implementar.\\n    *   Computacionalmente eficiente (especialmente para grandes conjuntos de datos).\\n    *   Escalable.\\n\\n*   **Desventajas:**\\n    *   Requiere especificar el número de clusters (K) de antemano.  Existen métodos como el \"método del codo\" (Elbow Method) o el análisis de la silueta para ayudar a determinar un K adecuado.\\n    *   Sensible a la inicialización de los centroides.  Se pueden usar múltiples inicializaciones y elegir la mejor solución.\\n    *   Asume que los clusters son esféricos y tienen tamaños similares.\\n    *   No funciona bien con datos no convexos o clusters de densidad variable.\\n\\n**Conclusión**\\n\\nEstos son solo algunos de los algoritmos básicos de Machine Learning. Cada uno tiene sus propias fortalezas y debilidades, y la elección del algoritmo adecuado depende del problema específico que se esté abordando y de las características de los datos.  Es fundamental comprender los fundamentos de estos algoritmos para poder aplicarlos de manera efectiva y construir modelos predictivos precisos.\\n\\n**Ejercicios Propuestos:**\\n\\n1.  Investiga y describe brevemente otros algoritmos de clustering (ej. Mean-Shift, Clustering Espectral).\\n2.  Implementa un modelo de regresión lineal simple usando Python y la librería scikit-learn. Utiliza un conjunto de datos de tu elección.\\n3.  Crea un árbol de decisión para clasificar correos electrónicos como spam o no spam.  Investiga cómo usar la técnica de poda para evitar el sobreajuste.\\n4.  Utiliza el algoritmo K-Means para segmentar imágenes en diferentes regiones de color.\\n5.  Compara las ventajas y desventajas de K-Means y Clustering Jerárquico. ¿En qué situaciones usarías uno u otro?\\n\\n¡Espero que estas notas de clase sean útiles!  Si tienes alguna pregunta, no dudes en consultar.',\n",
              "  'practice_problems': '¡Excelente! Aquí tienes un conjunto de problemas de práctica para Machine Learning Básico, cubriendo Regresión Lineal, Árboles de Decisión y Clustering, con distintos niveles de dificultad y soluciones paso a paso.\\n\\n**Curso:** Machine Learning Básico\\n\\n**Tema:** Regresión Lineal, Árboles de Decisión, Clustering\\n\\n---\\n\\n**Problemas de Práctica con Soluciones**\\n\\n**I. Regresión Lineal**\\n\\n**Problema 1 (Básico):**\\n\\n*Descripción:* Tienes los siguientes datos de experiencia laboral (años) y salario (en miles de dólares) de 5 empleados:\\n\\n| Experiencia (años) | Salario (miles $) |\\n|---|---|\\n| 1 | 30 |\\n| 3 | 55 |\\n| 5 | 75 |\\n| 7 | 90 |\\n| 9 | 110 |\\n\\nAplica regresión lineal simple para predecir el salario en función de la experiencia. Encuentra la ecuación de la recta de regresión (y = mx + b).\\n\\n*Solución:*\\n\\n1.  **Calcular las medias de X (experiencia) e Y (salario):**\\n    *   Media de X (X̄) = (1 + 3 + 5 + 7 + 9) / 5 = 5\\n    *   Media de Y (Ȳ) = (30 + 55 + 75 + 90 + 110) / 5 = 72\\n\\n2.  **Calcular la pendiente (m):**\\n    *   m = Σ[(Xi - X̄)(Yi - Ȳ)] / Σ[(Xi - X̄)^2]\\n\\n    | Experiencia (años) | Salario (miles $) |  Xi - X̄ | Yi - Ȳ | (Xi - X̄)(Yi - Ȳ) | (Xi - X̄)^2 |\\n    |---|---|---|---|---|---|\\n    | 1 | 30 | -4 | -42 | 168 | 16 |\\n    | 3 | 55 | -2 | -17 | 34 | 4 |\\n    | 5 | 75 | 0 | 3 | 0 | 0 |\\n    | 7 | 90 | 2 | 18 | 36 | 4 |\\n    | 9 | 110 | 4 | 38 | 152 | 16 |\\n    | **Suma** | | | | **390** | **40** |\\n\\n    *   m = 390 / 40 = 9.75\\n\\n3.  **Calcular la intersección (b):**\\n    *   b = Ȳ - m * X̄\\n    *   b = 72 - 9.75 * 5 = 23.25\\n\\n4.  **Ecuación de la recta de regresión:**\\n    *   y = 9.75x + 23.25\\n\\n*Interpretación:* Por cada año adicional de experiencia, el salario aumenta aproximadamente en 9.75 mil dólares. El salario base (cuando la experiencia es 0) es de 23.25 mil dólares.\\n\\n**Problema 2 (Intermedio):**\\n\\n*Descripción:*  Además de la experiencia laboral, ahora tienes datos sobre el nivel educativo (1: Bachiller, 2: Licenciatura, 3: Maestría) de los mismos 5 empleados del problema anterior.  Realiza una regresión lineal múltiple para predecir el salario en función de la experiencia y el nivel educativo.  Usa una librería como `scikit-learn` en Python.\\n\\n| Experiencia (años) | Nivel Educativo | Salario (miles $) |\\n|---|---|---|\\n| 1 | 1 | 30 |\\n| 3 | 2 | 55 |\\n| 5 | 2 | 75 |\\n| 7 | 3 | 90 |\\n| 9 | 3 | 110 |\\n\\n*Solución (en Python):*\\n\\n```python\\nimport pandas as pd\\nfrom sklearn.linear_model import LinearRegression\\n\\n# Datos\\ndata = {\\'Experiencia\\': [1, 3, 5, 7, 9],\\n        \\'Nivel Educativo\\': [1, 2, 2, 3, 3],\\n        \\'Salario\\': [30, 55, 75, 90, 110]}\\n\\ndf = pd.DataFrame(data)\\n\\n# Variables independientes (X) y variable dependiente (y)\\nX = df[[\\'Experiencia\\', \\'Nivel Educativo\\']]\\ny = df[\\'Salario\\']\\n\\n# Crear y entrenar el modelo de regresión lineal múltiple\\nmodel = LinearRegression()\\nmodel.fit(X, y)\\n\\n# Coeficientes (pendiente) e intercepto\\nprint(\"Coeficientes (Pendientes):\", model.coef_)\\nprint(\"Intercepto:\", model.intercept_)\\n\\n# Predicción para un empleado con 6 años de experiencia y nivel educativo 2\\nnueva_data = pd.DataFrame({\\'Experiencia\\': [6], \\'Nivel Educativo\\': [2]})\\nprediccion = model.predict(nueva_data)\\nprint(\"Predicción para 6 años de experiencia y nivel educativo 2:\", prediccion[0])\\n```\\n\\n*Explicación:*\\n\\n1.  **Importar librerías:** `pandas` para manejar los datos y `LinearRegression` de `scikit-learn` para el modelo.\\n2.  **Crear DataFrame:**  Se organizan los datos en un DataFrame de pandas.\\n3.  **Definir variables:** Se separan las variables independientes (X: Experiencia, Nivel Educativo) y la variable dependiente (y: Salario).\\n4.  **Crear y entrenar el modelo:** Se crea una instancia de `LinearRegression` y se entrena con los datos usando `model.fit(X, y)`.\\n5.  **Obtener coeficientes e intercepto:**  `model.coef_` proporciona los coeficientes para cada variable independiente (experiencia y nivel educativo), y `model.intercept_` proporciona el intercepto.\\n6.  **Predicción:** Se crea un nuevo DataFrame con los valores para los cuales se quiere realizar una predicción y se usa `model.predict()` para obtener el resultado.\\n\\n**Problema 3 (Avanzado):**\\n\\n*Descripción:*  Utiliza el mismo conjunto de datos del problema 2.  Además de realizar la regresión lineal múltiple, evalúa el rendimiento del modelo utilizando métricas como el R cuadrado (R²) y el error cuadrático medio (MSE).  Divide los datos en conjuntos de entrenamiento y prueba (80/20).\\n\\n*Solución (en Python):*\\n\\n```python\\nimport pandas as pd\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_squared_error, r2_score\\n\\n# Datos (mismo que antes)\\ndata = {\\'Experiencia\\': [1, 3, 5, 7, 9],\\n        \\'Nivel Educativo\\': [1, 2, 2, 3, 3],\\n        \\'Salario\\': [30, 55, 75, 90, 110]}\\n\\ndf = pd.DataFrame(data)\\n\\n# Variables independientes (X) y variable dependiente (y)\\nX = df[[\\'Experiencia\\', \\'Nivel Educativo\\']]\\ny = df[\\'Salario\\']\\n\\n# Dividir los datos en conjuntos de entrenamiento y prueba\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # random_state para reproducibilidad\\n\\n# Crear y entrenar el modelo\\nmodel = LinearRegression()\\nmodel.fit(X_train, y_train)\\n\\n# Predicciones en el conjunto de prueba\\ny_pred = model.predict(X_test)\\n\\n# Evaluar el modelo\\nmse = mean_squared_error(y_test, y_pred)\\nr2 = r2_score(y_test, y_pred)\\n\\nprint(\"Error Cuadrático Medio (MSE):\", mse)\\nprint(\"Coeficiente de Determinación (R²):\", r2)\\n```\\n\\n*Explicación:*\\n\\n1.  **Importar librerías:** Se añaden `train_test_split` para dividir los datos y `mean_squared_error` y `r2_score` para las métricas de evaluación.\\n2.  **Dividir los datos:**  `train_test_split` divide los datos en conjuntos de entrenamiento (80%) y prueba (20%).  `random_state` asegura que la división sea la misma cada vez que se ejecuta el código (para reproducibilidad).\\n3.  **Entrenar el modelo:** Se entrena el modelo con el conjunto de entrenamiento.\\n4.  **Realizar predicciones:** Se realizan predicciones en el conjunto de prueba.\\n5.  **Evaluar el modelo:** Se calculan el MSE y el R² comparando las predicciones con los valores reales del conjunto de prueba.\\n\\n*Interpretación:*\\n\\n*   **MSE:**  Mide el error promedio al cuadrado entre las predicciones y los valores reales. Un valor más bajo indica un mejor ajuste.\\n*   **R²:**  Mide la proporción de la varianza en la variable dependiente que es predecible a partir de las variables independientes.  Varía entre 0 y 1. Un valor más cercano a 1 indica un mejor ajuste.\\n\\n**II. Árboles de Decisión**\\n\\n**Problema 4 (Básico):**\\n\\n*Descripción:*  Describe con tus propias palabras cómo funciona un árbol de decisión para clasificación.  Explica los conceptos de nodo raíz, nodos internos, nodos hoja y las decisiones que se toman en cada nodo.\\n\\n*Solución:*\\n\\nUn árbol de decisión es un modelo de aprendizaje automático que se utiliza para clasificar datos en diferentes categorías o clases.  Funciona dividiendo el conjunto de datos en subconjuntos más pequeños basados en una serie de preguntas o decisiones, hasta que se llega a un punto en el que todos los datos en un subconjunto pertenecen a la misma clase.\\n\\n*   **Nodo Raíz:** Es el nodo inicial del árbol. Representa todo el conjunto de datos original. El algoritmo selecciona la mejor característica para dividir los datos en este nodo.\\n*   **Nodos Internos:** Son los nodos que se encuentran entre el nodo raíz y los nodos hoja. Cada nodo interno representa una prueba o condición sobre una característica específica. La respuesta a la prueba (por ejemplo, \"sí\" o \"no\") determina qué rama del árbol se sigue.\\n*   **Nodos Hoja:** Son los nodos finales del árbol. Cada nodo hoja representa una clase o categoría.  Cuando se llega a un nodo hoja, se asigna la instancia de datos a la clase representada por ese nodo.\\n\\nEn cada nodo interno, se elige la característica que mejor separa los datos en subconjuntos más puros (es decir, subconjuntos donde la mayoría de los datos pertenecen a la misma clase).  Esta elección se basa en métricas como la ganancia de información o el índice de Gini. El proceso se repite recursivamente para cada subconjunto hasta que se cumplen ciertos criterios de parada, como alcanzar una profundidad máxima del árbol o tener un número mínimo de instancias en un nodo.\\n\\n**Problema 5 (Intermedio):**\\n\\n*Descripción:* Tienes los siguientes datos sobre si una persona comprará un producto online basado en su edad y si tiene tarjeta de crédito:\\n\\n| Edad | Tarjeta de Crédito | Comprará |\\n|---|---|---|\\n| 25 | Sí | Sí |\\n| 30 | Sí | Sí |\\n| 35 | No | No |\\n| 40 | Sí | Sí |\\n| 45 | No | No |\\n| 50 | Sí | No |\\n| 55 | No | No |\\n\\nConstruye manualmente un árbol de decisión simple (máximo 2 niveles) para predecir si una persona comprará o no.  Elige la característica para el nodo raíz basándote en la intuición (no necesitas calcular la ganancia de información).\\n\\n*Solución:*\\n\\n1.  **Nodo Raíz:**  Elijo la característica \"Edad\" como nodo raíz. Intuitivamente, la edad podría ser un factor importante. Dividiré en dos ramas:  \"Edad <= 40\" y \"Edad > 40\".\\n\\n2.  **Rama \"Edad <= 40\":**\\n    *   Esta rama contiene los datos: (25, Sí, Sí), (30, Sí, Sí), (35, No, No), (40, Sí, Sí).\\n    *   De estos, 3 compran y 1 no compra.  Podemos crear un nodo hoja que prediga \"Sí\" (Comprará) para esta rama.  Aunque no es perfecto, es la predicción más probable.\\n\\n3.  **Rama \"Edad > 40\":**\\n    *   Esta rama contiene los datos: (45, No, No), (50, Sí, No), (55, No, No).\\n    *   De estos, 0 compran y 3 no compran.  Creamos un nodo hoja que prediga \"No\" (No Comprará) para esta rama.\\n\\n*Representación del Árbol:*\\n\\n```\\n                       Edad',\n",
              "  'discussion_questions': '¡Excelente! Aquí te presento un conjunto de preguntas para discusión sobre Machine Learning Básico (Regresión Lineal, Árboles de Decisión y Clustering), diseñadas para promover el pensamiento crítico, el debate y la conexión con problemas reales.\\n\\n**Preguntas para Discusión: Machine Learning Básico**\\n\\n**I. Regresión Lineal:**\\n\\n1.  **Pregunta:** La regresión lineal asume una relación lineal entre las variables independientes y la variable dependiente. ¿En qué situaciones del mundo real esta suposición podría ser problemática y cómo podríamos abordar estas limitaciones?\\n\\n    *   **Nota para el Instructor:** Se espera que los estudiantes identifiquen situaciones no lineales comunes (por ejemplo, relaciones exponenciales, logarítmicas, cuadráticas). Animar a la discusión sobre transformaciones de datos (logarítmicas, polinómicas) o el uso de modelos más complejos (regresión no lineal, modelos basados en árboles) como posibles soluciones. Se puede mencionar la importancia de la visualización de datos para identificar no linealidades.\\n\\n2.  **Pregunta:**  En el contexto de la regresión lineal, ¿cuál es la diferencia entre multicolinealidad y heterocedasticidad, y cómo afectan la fiabilidad de nuestros resultados? ¿Qué técnicas podemos usar para detectar y mitigar estos problemas?\\n\\n    *   **Nota para el Instructor:**  Esta pregunta busca evaluar la comprensión de conceptos estadísticos clave que pueden invalidar los supuestos de la regresión lineal.  Se espera que los estudiantes mencionen el uso de matrices de correlación, VIF (Variance Inflation Factor) para multicolinealidad y la inspección de los residuos para heterocedasticidad.  Como mitigación, se puede discutir la eliminación de variables redundantes, la regularización (Ridge, Lasso) y la transformación de la variable dependiente.\\n\\n3.  **Pregunta:**  Imagina que estás creando un modelo de regresión lineal para predecir el precio de una casa.  Identificas varias variables predictoras, pero algunas tienen un fuerte significado ético (por ejemplo, la raza o el código postal del comprador).  ¿Cómo equilibrarías la precisión del modelo con la necesidad de evitar la discriminación y garantizar la equidad?\\n\\n    *   **Nota para el Instructor:**  Esta pregunta introduce un componente ético crucial.  Se espera que los estudiantes reflexionen sobre la importancia de la transparencia del modelo, la eliminación de variables problemáticas (aunque esto pueda disminuir la precisión), el uso de técnicas de \"fairness-aware machine learning\" (si se han cubierto en el curso) y la evaluación del impacto del modelo en diferentes grupos demográficos.  Se puede debatir sobre la diferencia entre correlación y causalidad, y cómo la correlación espuria puede llevar a decisiones injustas.\\n\\n**II. Árboles de Decisión:**\\n\\n1.  **Pregunta:** Los árboles de decisión son conocidos por ser fáciles de interpretar, pero también propensos al sobreajuste (overfitting). ¿Cómo podemos equilibrar la interpretabilidad con la generalización en los árboles de decisión? Discute diferentes técnicas de poda y cómo afectan el rendimiento del modelo.\\n\\n    *   **Nota para el Instructor:** Se espera que los estudiantes mencionen la poda (pre-poda y post-poda), la limitación de la profundidad del árbol, el número mínimo de muestras por nodo y el uso de validación cruzada para evaluar el rendimiento. Animar a la discusión sobre las ventajas y desventajas de cada técnica.\\n\\n2.  **Pregunta:**  Los árboles de decisión pueden ser sensibles a pequeños cambios en los datos de entrenamiento. ¿Cómo podemos mitigar esta inestabilidad y mejorar la robustez del modelo? Considera el uso de métodos de ensemble como Random Forests y Gradient Boosting.\\n\\n    *   **Nota para el Instructor:**  Esta pregunta introduce la idea de los métodos de ensemble. Se espera que los estudiantes expliquen cómo Random Forests y Gradient Boosting combinan múltiples árboles para reducir la varianza y mejorar la precisión. Se puede discutir brevemente la diferencia entre bagging (Random Forests) y boosting (Gradient Boosting).\\n\\n3.  **Pregunta:**  Considera un escenario donde estás usando un árbol de decisión para diagnosticar una enfermedad.  El árbol te da un diagnóstico con alta precisión, pero no te explica *por qué* llegó a esa conclusión de una manera que un médico pueda entender fácilmente. ¿Cómo abordarías este problema de \"explicabilidad\" en un contexto médico?\\n\\n    *   **Nota para el Instructor:**  Esta pregunta se centra en la importancia de la interpretabilidad en aplicaciones críticas.  Se espera que los estudiantes reflexionen sobre la necesidad de simplificar el árbol (a costa de una posible pérdida de precisión), el uso de técnicas de visualización para explicar las decisiones del árbol, o la combinación del árbol con otras técnicas (como reglas de asociación) para generar explicaciones más comprensibles. Se puede mencionar la importancia de la confianza en el modelo en contextos de alto riesgo.\\n\\n**III. Clustering:**\\n\\n1.  **Pregunta:**  K-means es un algoritmo de clustering popular, pero requiere que especifiquemos el número de clusters (K) de antemano. ¿Qué métodos podemos usar para determinar un valor \"óptimo\" para K, y cuáles son las limitaciones de estos métodos?\\n\\n    *   **Nota para el Instructor:** Se espera que los estudiantes mencionen el método del codo (elbow method), el coeficiente de silueta y el análisis de la estructura del dominio. Animar a la discusión sobre las limitaciones de cada método (por ejemplo, el método del codo puede ser subjetivo, el coeficiente de silueta puede no ser adecuado para todos los tipos de datos).\\n\\n2.  **Pregunta:**  Compara y contrasta K-means con otros algoritmos de clustering como DBSCAN y Clustering Jerárquico. ¿En qué tipo de datos y aplicaciones cada algoritmo sería más adecuado?\\n\\n    *   **Nota para el Instructor:**  Esta pregunta busca evaluar la comprensión de las fortalezas y debilidades de diferentes algoritmos de clustering. Se espera que los estudiantes mencionen que K-means es sensible a la escala y a los outliers, mientras que DBSCAN es bueno para detectar clusters de formas arbitrarias y manejar outliers. El clustering jerárquico proporciona una estructura jerárquica de los datos que puede ser útil para la exploración.\\n\\n3.  **Pregunta:**  Imagina que estás usando clustering para segmentar clientes para una campaña de marketing.  Después de aplicar K-means, obtienes varios clusters, pero no estás seguro de cómo interpretar estos clusters y convertirlos en estrategias de marketing efectivas. ¿Qué pasos seguirías para analizar y validar los resultados del clustering y generar insights accionables?\\n\\n    *   **Nota para el Instructor:**  Esta pregunta se centra en la aplicación práctica del clustering.  Se espera que los estudiantes mencionen la necesidad de analizar las características de cada cluster (por ejemplo, utilizando estadísticas descriptivas), visualizar los clusters, validar los clusters utilizando métricas internas (como el coeficiente de silueta) y externas (si se dispone de etiquetas), y trabajar con expertos en marketing para interpretar los clusters y desarrollar estrategias personalizadas.  Se puede discutir la importancia de la iteración y la experimentación en el proceso de clustering.\\n\\n**IV. Conexiones entre Temas:**\\n\\n1.  **Pregunta:**  ¿Cómo se podrían combinar las técnicas de regresión lineal, árboles de decisión y clustering para resolver un problema de negocio complejo? Da un ejemplo específico y explica cómo cada técnica contribuiría a la solución.\\n\\n    *   **Nota para el Instructor:**  Esta pregunta busca fomentar la integración de los diferentes temas del curso.  Se espera que los estudiantes propongan ejemplos creativos y justifiquen el uso de cada técnica. Por ejemplo, se podría usar la regresión lineal para predecir el valor de un cliente, los árboles de decisión para segmentar a los clientes en función de su probabilidad de churn, y el clustering para identificar grupos de clientes con necesidades similares.\\n\\n2.  **Pregunta:**  En el contexto del Machine Learning, ¿cómo se relaciona el concepto de \"bias-variance tradeoff\" con la elección de un modelo (regresión lineal, árbol de decisión, clustering)?\\n\\n    *   **Nota para el Instructor:**  Esta pregunta relaciona los modelos específicos con un concepto fundamental en Machine Learning.  Se espera que los estudiantes expliquen cómo los modelos más simples (como la regresión lineal) tienden a tener un alto bias y baja varianza, mientras que los modelos más complejos (como los árboles de decisión profundos) tienden a tener un bajo bias y alta varianza. El clustering también puede verse afectado por este tradeoff, por ejemplo, un número K demasiado pequeño puede llevar a un alto bias, mientras que un número K demasiado grande puede llevar a alta varianza.\\n\\nEstas preguntas están diseñadas para generar un debate rico y significativo en clase. ¡Espero que te sean útiles!\\n',\n",
              "  'learning_objectives': '¡Absolutamente! Aquí tienes una serie de objetivos de aprendizaje SMART para el tema \"Machine Learning Básico\", considerando los subtemas de Regresión Lineal, Árboles de Decisión y Clustering, con verbos de la taxonomía de Bloom y alineados con los objetivos generales del curso:\\n\\n**Objetivos Generales del Curso (Recordatorio):**\\n\\n*   Comprender los fundamentos teóricos de la IA\\n*   Aplicar algoritmos de búsqueda y optimización\\n*   Desarrollar modelos básicos de machine learning\\n*   Analizar casos de estudio de aplicaciones reales\\n*   Implementar soluciones simples de PLN\\n\\n**Tema: Machine Learning Básico**\\n\\n**Subtema: Regresión Lineal**\\n\\n*   **Conocimiento (Recordar):**\\n    *   **Objetivo:** En la semana 1, los estudiantes **definirán** (Recordar) los conceptos clave de la regresión lineal (variables dependientes e independientes, función de costo, gradiente descendente) con un 100% de precisión en un cuestionario.\\n*   **Comprensión (Entender):**\\n    *   **Objetivo:** Al finalizar la semana 1, los estudiantes **explicarán** (Comprender) cómo la función de costo y el gradiente descendente se utilizan para optimizar los parámetros de un modelo de regresión lineal, demostrándolo en una explicación escrita con un mínimo de 80% de los conceptos correctos.\\n*   **Aplicación (Aplicar):**\\n    *   **Objetivo:** En la semana 2, los estudiantes **aplicarán** (Aplicar) un algoritmo de regresión lineal simple utilizando una biblioteca de Python (por ejemplo, scikit-learn) para predecir valores en un conjunto de datos dado, obteniendo un R-cuadrado superior a 0.7 en la predicción.\\n*   **Análisis (Analizar):**\\n    *   **Objetivo:** Al finalizar la semana 2, los estudiantes **compararán** (Analizar) el rendimiento de diferentes modelos de regresión lineal (simple vs. múltiple) en términos de error cuadrático medio (MSE) y R-cuadrado en un conjunto de datos dado, justificando su elección del mejor modelo en un informe conciso (máximo 500 palabras).\\n*   **Evaluación (Evaluar):**\\n    *   **Objetivo:** En la semana 3, los estudiantes **evaluarán** (Evaluar) la validez de los supuestos de la regresión lineal (linealidad, independencia, homocedasticidad, normalidad) en un conjunto de datos, identificando posibles violaciones y proponiendo soluciones para mitigar sus efectos en un informe escrito.\\n\\n**Subtema: Árboles de Decisión**\\n\\n*   **Conocimiento (Recordar):**\\n    *   **Objetivo:** En la semana 3, los estudiantes **enumerarán** (Recordar) los diferentes criterios de división utilizados en los árboles de decisión (entropía, ganancia de información, índice de Gini) con un 100% de precisión en un cuestionario.\\n*   **Comprensión (Entender):**\\n    *   **Objetivo:** Al finalizar la semana 3, los estudiantes **describirán** (Comprender) cómo un árbol de decisión toma decisiones basadas en la división recursiva de los datos, ilustrando el proceso con un ejemplo concreto en una presentación oral breve (5 minutos).\\n*   **Aplicación (Aplicar):**\\n    *   **Objetivo:** En la semana 4, los estudiantes **construirán** (Aplicar) un modelo de árbol de decisión utilizando una biblioteca de Python para clasificar datos en un conjunto de datos dado, alcanzando una precisión superior al 80% en la clasificación.\\n*   **Análisis (Analizar):**\\n    *   **Objetivo:** Al finalizar la semana 4, los estudiantes **analizarán** (Analizar) el impacto de la profundidad del árbol en el rendimiento del modelo, identificando el riesgo de sobreajuste y proponiendo técnicas de poda para mejorar la generalización en un informe.\\n*   **Evaluación (Evaluar):**\\n    *   **Objetivo:** En la semana 5, los estudiantes **compararán** (Evaluar) el rendimiento de un árbol de decisión con un modelo de regresión lineal en un conjunto de datos específico, justificando la elección del modelo más adecuado en función de las características de los datos y los objetivos del problema.\\n\\n**Subtema: Clustering**\\n\\n*   **Conocimiento (Recordar):**\\n    *   **Objetivo:** En la semana 5, los estudiantes **identificarán** (Recordar) los diferentes tipos de algoritmos de clustering (K-medias, clustering jerárquico, DBSCAN) con un 100% de precisión en un cuestionario.\\n*   **Comprensión (Entender):**\\n    *   **Objetivo:** Al finalizar la semana 5, los estudiantes **explicarán** (Comprender) el principio de funcionamiento del algoritmo K-medias, detallando el proceso de asignación de puntos a clústeres y la actualización de centroides en una presentación escrita.\\n*   **Aplicación (Aplicar):**\\n    *   **Objetivo:** En la semana 6, los estudiantes **aplicarán** (Aplicar) el algoritmo K-medias utilizando una biblioteca de Python para segmentar datos en un conjunto de datos dado, eligiendo el número óptimo de clústeres utilizando el método del codo.\\n*   **Análisis (Analizar):**\\n    *   **Objetivo:** Al finalizar la semana 6, los estudiantes **analizarán** (Analizar) la estructura de los clústeres resultantes, interpretando las características de cada grupo y proponiendo posibles aplicaciones para la segmentación en un informe.\\n*   **Creación (Crear):**\\n    *   **Objetivo:** En la semana 7, los estudiantes **diseñarán** (Crear) un pipeline de Machine Learning que combine una técnica de reducción de dimensionalidad (PCA) con un algoritmo de clustering (K-means) para segmentar datos de alta dimensión, justificando la elección de cada componente y evaluando el rendimiento del pipeline.\\n\\n**Notas Adicionales:**\\n\\n*   Estos objetivos son solo ejemplos y pueden ajustarse según las necesidades específicas del curso y el nivel de los estudiantes.\\n*   Es importante proporcionar a los estudiantes ejemplos concretos y ejercicios prácticos para que puedan aplicar los conocimientos adquiridos.\\n*   La evaluación debe estar alineada con los objetivos de aprendizaje, utilizando diferentes métodos (cuestionarios, informes, presentaciones, proyectos) para evaluar diferentes niveles cognitivos.\\n*   Considera incluir rúbricas detalladas para que los estudiantes comprendan los criterios de evaluación y puedan mejorar su desempeño.\\n\\nEspero que estos objetivos te sean de gran utilidad. ¡Mucho éxito con tu curso!\\n',\n",
              "  'suggested_resources': '¡Absolutamente! Aquí tienes una lista de recursos de aprendizaje para Machine Learning Básico, enfocada en los temas de Regresión Lineal, Árboles de Decisión y Clustering, con un enfoque en la claridad, precisión y utilidad para estudiantes universitarios:\\n\\n**I. Libros de Texto (Principales y Complementarios)**\\n\\n*   **Principal:**\\n    *   **\"Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow\"** (Aurélien Géron, 2022): *Relevancia:* Un libro muy práctico que cubre una amplia gama de algoritmos de Machine Learning, incluyendo los básicos, con ejemplos claros en Python utilizando Scikit-Learn, Keras y TensorFlow. *Utilidad:* Ideal para aprender haciendo, con muchos ejercicios y código.\\n*   **Complementarios:**\\n    *   **\"The Elements of Statistical Learning\"** (Hastie, Tibshirani, Friedman, 2009): *Relevancia:* Un clásico que proporciona una base teórica sólida para el Machine Learning. *Utilidad:* Aunque es más denso matemáticamente, es invaluable para entender los fundamentos. (Disponible gratuitamente en línea: [https://web.stanford.edu/~hastie/ElemStatLearn/](https://web.stanford.edu/~hastie/ElemStatLearn/))\\n    *   **\"Pattern Recognition and Machine Learning\"** (Christopher Bishop, 2006): *Relevancia:* Otro libro de texto fundamental que cubre una amplia gama de temas de Machine Learning con un enfoque en la probabilidad y la estadística. *Utilidad:* Proporciona una comprensión profunda de los modelos y algoritmos.\\n    *   **\"Python Machine Learning\"** (Sebastian Raschka, Vahid Mirjalili, 2019): *Relevancia:* Un buen recurso para aprender Machine Learning con Python y Scikit-Learn. *Utilidad:* Cubre los conceptos básicos y algoritmos con ejemplos prácticos y explicaciones claras.\\n\\n**II. Artículos Académicos Relevantes y Actualizados**\\n\\n*   **Regresión Lineal:**\\n    *   **\"Least Angle Regression\"** (Efron, Hastie, Johnstone, Tibshirani, 2004): *Relevancia:* Presenta el algoritmo LARS, una alternativa eficiente para la regresión lineal con selección de variables. *Utilidad:* Útil para comprender métodos de regularización y selección de características.\\n    *   **\"Regularization Paths for Generalized Linear Models via Coordinate Descent\"** (Friedman, Hastie, Tibshirani, 2010): *Relevancia:* Explica el uso de descenso de coordenadas para la regularización en modelos lineales generalizados. *Utilidad:* Ayuda a entender cómo implementar la regularización L1 (Lasso) y L2 (Ridge) en la práctica.\\n*   **Árboles de Decisión:**\\n    *   **\"Classification and Regression Trees\"** (Breiman, Friedman, Olshen, Stone, 1984): *Relevancia:* El artículo original que introduce el algoritmo CART (Classification and Regression Trees). *Utilidad:* Fundamental para entender la construcción y el uso de árboles de decisión.\\n    *   **\"Random Forests\"** (Breiman, 2001): *Relevancia:* Introduce el algoritmo de Random Forest, una técnica de ensemble learning basada en árboles de decisión. *Utilidad:* Proporciona una comprensión profunda de cómo funcionan los Random Forests y por qué son tan efectivos.\\n*   **Clustering:**\\n    *   **\"k-means++: The Advantages of Careful Seeding\"** (Arthur, Vassilvitskii, 2007): *Relevancia:* Propone una mejora al algoritmo k-means para una inicialización más robusta. *Utilidad:* Ayuda a entender cómo la inicialización afecta el rendimiento de k-means.\\n    *   **\"Density-Based Clustering Based on Connected High-Density Components\"** (Ester, Kriegel, Sander, Xu, 1996): *Relevancia:* Introduce el algoritmo DBSCAN, un método de clustering basado en la densidad. *Utilidad:* Útil para comprender métodos de clustering que no requieren especificar el número de clusters.\\n\\n**III. Recursos en Línea de Calidad**\\n\\n*   **Cursos:**\\n    *   **\"Machine Learning\" (Andrew Ng, Coursera):** *Relevancia:* Un curso introductorio muy popular que cubre los fundamentos del Machine Learning, incluyendo regresión lineal, árboles de decisión y clustering. *Utilidad:* Proporciona una base sólida en los conceptos y algoritmos básicos.\\n    *   **\"Machine Learning A-Z: Hands-On Python & R In Data Science\" (Kirill Eremenko, Hadelin de Ponteves, Udemy):** *Relevancia:* Un curso práctico que cubre una amplia gama de algoritmos de Machine Learning con ejemplos en Python y R. *Utilidad:* Ideal para aprender haciendo y aplicar los algoritmos a problemas reales.\\n*   **Tutoriales:**\\n    *   **Scikit-Learn Documentation:** *Relevancia:* La documentación oficial de Scikit-Learn proporciona tutoriales y ejemplos para todos los algoritmos de Machine Learning implementados en la biblioteca. *Utilidad:* Esencial para aprender a usar Scikit-Learn de manera efectiva.\\n    *   **Kaggle Learn:** *Relevancia:* Ofrece cursos cortos y prácticos sobre diversos temas de Machine Learning, incluyendo regresión lineal, árboles de decisión y clustering. *Utilidad:* Ideal para aprender conceptos específicos de manera rápida y aplicada.\\n*   **Videos:**\\n    *   **StatQuest with Josh Starmer (YouTube):** *Relevancia:* Josh Starmer explica conceptos estadísticos y de Machine Learning de manera clara y concisa. *Utilidad:* Útil para comprender los fundamentos teóricos de los algoritmos.\\n    *   **3Blue1Brown (YouTube):** *Relevancia:* Ofrece explicaciones visuales e intuitivas de conceptos matemáticos relacionados con el Machine Learning. *Utilidad:* Ayuda a desarrollar una comprensión profunda de las matemáticas detrás de los algoritmos.\\n\\n**IV. Herramientas y Software Relevantes**\\n\\n*   **Python:** El lenguaje de programación más utilizado en Machine Learning.\\n*   **Scikit-Learn:** Una biblioteca de Python que proporciona implementaciones de muchos algoritmos de Machine Learning, incluyendo regresión lineal, árboles de decisión y clustering.\\n*   **NumPy:** Una biblioteca de Python para computación numérica.\\n*   **Pandas:** Una biblioteca de Python para análisis de datos.\\n*   **Matplotlib y Seaborn:** Bibliotecas de Python para visualización de datos.\\n\\n**V. Recursos para Diferentes Niveles de Conocimiento Previo**\\n\\n*   **Principiantes:**\\n    *   Cursos introductorios en línea (Coursera, Udemy)\\n    *   Tutoriales básicos de Scikit-Learn\\n    *   Videos explicativos (StatQuest, 3Blue1Brown)\\n*   **Intermedio:**\\n    *   Libros de texto (Hands-On Machine Learning)\\n    *   Artículos académicos relevantes\\n    *   Tutoriales avanzados de Scikit-Learn\\n*   **Avanzado:**\\n    *   Libros de texto (The Elements of Statistical Learning, Pattern Recognition and Machine Learning)\\n    *   Artículos académicos de investigación\\n    *   Implementación de algoritmos desde cero\\n\\n**Recursos Adicionales Específicos por Tema:**\\n\\n*   **Regresión Lineal:**\\n    *   **Video:** \"Linear Regression, Clearly Explained!!!\" (StatQuest)\\n    *   **Tutorial:** \"Linear Regression in Python\" (Real Python)\\n*   **Árboles de Decisión:**\\n    *   **Video:** \"Decision Trees\" (Brandon Foltz)\\n    *   **Tutorial:** \"Decision Tree Algorithm With Python\" (Machine Learning Mastery)\\n*   **Clustering:**\\n    *   **Video:** \"K-Means Clustering Clearly Explained!!!\" (StatQuest)\\n    *   **Tutorial:** \"A Complete Guide to K-Means Clustering Algorithm\" (Analytics Vidhya)\\n\\n**Consejos Adicionales:**\\n\\n*   **Experimenta:** No tengas miedo de probar diferentes algoritmos y parámetros.\\n*   **Visualiza:** Utiliza herramientas de visualización para comprender los datos y los resultados de los modelos.\\n*   **Aplica:** Trabaja en proyectos prácticos para consolidar tus conocimientos.\\n*   **Participa:** Únete a comunidades en línea y participa en competiciones de Machine Learning (Kaggle).\\n\\nEspero que esta lista de recursos te sea de gran ayuda. ¡Mucha suerte con tu aprendizaje de Machine Learning!\\n'}}"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contenido"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creamos la funcion principal para exportar el contenido educativo en formato pdf."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def dict_to_pdf(materials: dict, output_pdf: str = \"materiales_curso.pdf\"):\n",
        "    \"\"\"\n",
        "    Convierte un diccionario de materiales a un PDF.\n",
        "    \n",
        "    El diccionario se transforma en un string Markdown que luego se convierte a HTML y finalmente a PDF usando pypandoc.\n",
        "    \n",
        "    Args:\n",
        "        materials: Diccionario con la estructura de temas y secciones.\n",
        "        output_pdf: Nombre del archivo PDF de salida.\n",
        "    \"\"\"\n",
        "    # Construir un string Markdown combinando cada tema y sus secciones\n",
        "    md_content = \"\"\n",
        "    for topic_id, content in materials.items():\n",
        "        md_content += f\"# Tema {topic_id}\\n\\n\"\n",
        "        for section, text in content.items():\n",
        "            section_title = section.replace('_', ' ').title()\n",
        "            md_content += f\"## {section_title}\\n\\n\"\n",
        "            md_content += text + \"\\n\\n\"\n",
        "        md_content += \"\\n---\\n\\n\"  # separador entre temas\n",
        "\n",
        "    # Convertir el Markdown a HTML (esto es opcional, ya que pypandoc puede convertir directamente desde Markdown)\n",
        "    html = markdown.markdown(md_content)\n",
        "    \n",
        "    # Opciones adicionales para pypandoc (usa XeLaTeX y una fuente que soporte Unicode)\n",
        "    extra_args = [\n",
        "        '--pdf-engine=xelatex',\n",
        "        '-V', 'mainfont=Times New Roman',\n",
        "    ]\n",
        "    \n",
        "    # Convertir HTML a PDF\n",
        "    pypandoc.convert_text(html, 'pdf', format='html', outputfile=output_pdf, extra_args=extra_args)\n",
        "    print(f\"✅ Archivo PDF guardado: {output_pdf}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archivo PDF guardado: materiales_curso.pdf\n"
          ]
        }
      ],
      "source": [
        "dict_to_pdf(contenido,\"materiales_curso.pdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como complemento, vamos a crear una función que nos permita exportar el contenido educativo en formato .docx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def dict_to_docx(materials: dict, filename: str = \"materiales_curso.docx\"):\n",
        "    \"\"\"Convierte el diccionario de materiales a PDF conservando formato Markdown\"\"\"\n",
        "    \n",
        "    # Crear documento Word\n",
        "    doc = Document()\n",
        "    \n",
        "    # Configuración de estilos\n",
        "    style = doc.styles['Normal']\n",
        "    font = style.font\n",
        "    font.name = 'Arial'\n",
        "    font.size = Pt(11)\n",
        "    \n",
        "    # Función para añadir texto con formato\n",
        "    def add_section(title: str, content: str, level: int = 1):\n",
        "        # Añadir título\n",
        "        heading = doc.add_heading(level=level)\n",
        "        heading_run = heading.add_run(title)\n",
        "        heading_run.bold = True\n",
        "        \n",
        "        # Convertir Markdown a HTML y luego a texto formateado\n",
        "        md = MarkdownIt()\n",
        "        tokens = md.parse(content)\n",
        "        \n",
        "        # Procesar tokens Markdown\n",
        "        for token in tokens:\n",
        "            if token.type == 'inline':\n",
        "                p = doc.add_paragraph()\n",
        "                p.alignment = WD_PARAGRAPH_ALIGNMENT.JUSTIFY\n",
        "                \n",
        "                # Manejar diferentes formatos\n",
        "                if 'strong' in token.map:\n",
        "                    run = p.add_run(token.content)\n",
        "                    run.bold = True\n",
        "                elif 'em' in token.map:\n",
        "                    run = p.add_run(token.content)\n",
        "                    run.italic = True\n",
        "                else:\n",
        "                    p.add_run(token.content)\n",
        "                \n",
        "                # Manejar listas\n",
        "                if token.type == 'list_item':\n",
        "                    p.style = 'List Bullet'\n",
        "                \n",
        "        doc.add_paragraph()  # Espacio entre secciones\n",
        "\n",
        "    # Generar contenido\n",
        "    for topic_id, content in materials.items():\n",
        "        # Tema principal\n",
        "        doc.add_heading(f'Tema {topic_id}', level=0)\n",
        "        \n",
        "        # Secciones\n",
        "        for section, text in content.items():\n",
        "            section_title = section.replace('_', ' ').title()\n",
        "            add_section(section_title, text, level=1)\n",
        "            \n",
        "        doc.add_page_break()\n",
        "\n",
        "    # Guardar archivo en la ruta especificada\n",
        "    doc.save(filename)\n",
        "    print(f\"Archivo guardado en: {filename}\")\n",
        "\n",
        "# Ejemplo de uso\n",
        "\n",
        "\n",
        "# Guardar en la ruta deseada\n",
        "# output_path = \"./materiales_curso.docx\"  # Cambia esta ruta\n",
        "# dict_to_docx(contenido, output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def save_materials_as_text_files(materials: dict, output_dir: str):\n",
        "    \"\"\"\n",
        "    Guarda los materiales generados en archivos de texto.\n",
        "    \n",
        "    Cada tema se guarda en una subcarpeta, y para cada tipo de contenido se crea un archivo.\n",
        "    \n",
        "    Args:\n",
        "        materials: Diccionario con los materiales generados.\n",
        "        output_dir: Directorio base donde se guardarán los archivos.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    \n",
        "    for topic_id, content in materials.items():\n",
        "        # Crear una subcarpeta para cada tema, usando el ID o el título (si se prefiere)\n",
        "        topic_dir = os.path.join(output_dir, f\"tema_{topic_id}\")\n",
        "        if not os.path.exists(topic_dir):\n",
        "            os.makedirs(topic_dir)\n",
        "        \n",
        "        # Guardar cada tipo de material en un archivo distinto\n",
        "        for content_type, text in content.items():\n",
        "            filename = os.path.join(topic_dir, f\"{content_type}.txt\")\n",
        "            with open(filename, 'w', encoding='utf-8') as f:\n",
        "                f.write(text)\n",
        "    print(f\"Materiales guardados en: {output_dir}\")\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "# save_materials_as_text_files(contenido, \"materiales_generados\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para evualar el contenido vamos a crear una clase que analiza la calidad del contenido educativo generado. En esencia, lo que hace es lo siguiente:\n",
        "1. Evaluación por Tema:\n",
        "\n",
        "* Para cada tema del curso, el evaluador examina diferentes tipos de contenido (notas de clase, problemas de práctica, preguntas para discusión, objetivos de aprendizaje y recursos sugeridos).\n",
        "* Cada uno de estos componentes se evalúa mediante funciones específicas que calculan una puntuación basada en varios criterios, como la cobertura de subtemas, la legibilidad (por ejemplo, la longitud promedio de las oraciones), el uso adecuado de terminología del dominio y otros indicadores como la presencia de ejemplos, soluciones o la variedad de recursos.\n",
        "*Se calcula una puntuación promedio para cada tema a partir de las evaluaciones individuales de cada tipo de contenido.\n",
        "\n",
        "2. Cálculo de Métricas Globales:\n",
        "\n",
        "* **Relevancia**: Se mide comparando la cobertura de subtemas esperados en el syllabus con lo que efectivamente se aborda en el contenido. Se calcula la proporción de subtemas que están cubiertos en, por ejemplo, las notas de clase.\n",
        "+ **Consistencia**: Se evalúa la coherencia del contenido mediante la similitud semántica entre diferentes secciones o temas. Para ello, se representa cada bloque de contenido con vectores TF-IDF y se calcula la similitud de coseno entre ellos. Una mayor similitud indica mayor consistencia en el estilo y terminología.\n",
        "* **Legibilidad**: Se estima a partir de la longitud promedio de las oraciones. Se asume que oraciones más cortas facilitan la comprensión, por lo que se traduce ese promedio en una puntuación de legibilidad.\n",
        "* **Uso de Terminología Específica**: Se extraen términos clave del syllabus usando técnicas TF-IDF y luego se verifica la densidad de estos términos en el contenido generado, midiendo qué tan bien se integra la terminología relevante del dominio.\n",
        "\n",
        "3. Integración de Resultados:\n",
        "\n",
        "*Las puntuaciones individuales para cada tipo de contenido se promedian para obtener una puntuación global por tema.\n",
        "*Además, se calculan promedios globales para cada tipo de contenido (por ejemplo, promedios de las notas de clase, problemas de práctica, etc.) y se combinan con las métricas globales (relevancia, consistencia, legibilidad y uso de terminología) para obtener una puntuación global promedio del contenido generado.\n",
        "\n",
        "En resumen, el evaluador toma el contenido generado, lo compara con la estructura y los subtemas definidos en el syllabus, y aplica varios análisis (por ejemplo, de cobertura de subtemas, similitud semántica, legibilidad y densidad terminológica) para producir una evaluación cuantitativa que refleja la calidad y coherencia del material educativo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "class Evaluator:\n",
        "    \"\"\"Evalúa la calidad del contenido educativo generado.\"\"\"\n",
        "    \n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.logger = logging.getLogger(\"educational_agent.evaluator\")\n",
        "        \n",
        "    def evaluate_content(self, generated_content: Dict[str, Dict[str, str]], \n",
        "                         syllabus_data: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Evalúa el contenido generado utilizando diversas métricas:\n",
        "          - Relevancia (a través de la cobertura de subtemas)\n",
        "          - Consistencia (usando, por ejemplo, similitud de coseno entre secciones)\n",
        "          - Legibilidad (a través de la longitud promedio de oraciones)\n",
        "          - Uso de terminología específica del dominio (extracción TF-IDF)\n",
        "          \n",
        "        Args:\n",
        "            generated_content: Diccionario con materiales generados, organizado por tema y tipo.\n",
        "            syllabus_data: Datos estructurados del programa del curso.\n",
        "            \n",
        "        Returns:\n",
        "            Diccionario con resultados de evaluación.\n",
        "        \"\"\"\n",
        "        self.logger.info(\"Iniciando evaluación del contenido generado\")\n",
        "        \n",
        "        evaluation_results = {\n",
        "            \"topic_scores\": {},\n",
        "            \"content_type_scores\": {\n",
        "                \"lecture_notes\": 0,\n",
        "                \"practice_problems\": 0,\n",
        "                \"discussion_questions\": 0,\n",
        "                \"learning_objectives\": 0,\n",
        "                \"suggested_resources\": 0\n",
        "            },\n",
        "            \"overall_metrics\": {\n",
        "                \"relevance_score\": 0,\n",
        "                \"consistency_score\": 0,\n",
        "                \"readability_score\": 0,\n",
        "                \"domain_terminology_score\": 0\n",
        "            },\n",
        "            \"average_score\": 0\n",
        "        }\n",
        "        \n",
        "        # Extraer terminología del syllabus para evaluar uso de términos\n",
        "        course_terminology = self._extract_domain_terminology(syllabus_data)\n",
        "        \n",
        "        # Evaluar cada tema\n",
        "        for topic_id, topic_content in generated_content.items():\n",
        "            # Buscar la información del tema en el syllabus (ejemplo: usando id)\n",
        "            topic_info = next((t for t in syllabus_data[\"topics\"] if t[\"id\"] == topic_id), None)\n",
        "            if not topic_info:\n",
        "                self.logger.warning(f\"No se encontró información para el tema {topic_id} en el syllabus\")\n",
        "                continue\n",
        "            \n",
        "            # Evaluar cada tipo de contenido para el tema actual\n",
        "            lecture = topic_content.get(\"lecture_notes\", \"\")\n",
        "            practice = topic_content.get(\"practice_problems\", \"\")\n",
        "            discussion = topic_content.get(\"discussion_questions\", \"\")\n",
        "            objectives = topic_content.get(\"learning_objectives\", \"\")\n",
        "            resources = topic_content.get(\"suggested_resources\", \"\")\n",
        "            \n",
        "            topic_scores = {\n",
        "                \"lecture_notes\": self._evaluate_lecture_notes(lecture, topic_info, course_terminology),\n",
        "                \"practice_problems\": self._evaluate_practice_problems(practice, topic_info),\n",
        "                \"discussion_questions\": self._evaluate_discussion_questions(discussion, topic_info),\n",
        "                \"learning_objectives\": self._evaluate_learning_objectives(objectives, topic_info),\n",
        "                \"suggested_resources\": self._evaluate_suggested_resources(resources, topic_info)\n",
        "            }\n",
        "            \n",
        "            # Puntuación promedio para el tema\n",
        "            topic_avg = sum(topic_scores.values()) / len(topic_scores)\n",
        "            topic_scores[\"average\"] = topic_avg\n",
        "            \n",
        "            evaluation_results[\"topic_scores\"][topic_id] = topic_scores\n",
        "            \n",
        "            # Acumular para cada tipo de contenido\n",
        "            for key, score in topic_scores.items():\n",
        "                if key != \"average\" and key in evaluation_results[\"content_type_scores\"]:\n",
        "                    evaluation_results[\"content_type_scores\"][key] += score\n",
        "        \n",
        "        # Promediar para cada tipo de contenido\n",
        "        num_topics = len(generated_content)\n",
        "        if num_topics > 0:\n",
        "            for key in evaluation_results[\"content_type_scores\"]:\n",
        "                evaluation_results[\"content_type_scores\"][key] /= num_topics\n",
        "        \n",
        "        # Métricas globales: por ejemplo, podemos usar la similitud entre secciones para consistencia\n",
        "        overall_consistency = self._evaluate_consistency(generated_content)\n",
        "        overall_readability = self._calculate_readability(self._join_all_texts(generated_content))\n",
        "        overall_terminology = self._calculate_terminology_usage(self._join_all_texts(generated_content), course_terminology)\n",
        "        \n",
        "        evaluation_results[\"overall_metrics\"][\"consistency_score\"] = overall_consistency\n",
        "        evaluation_results[\"overall_metrics\"][\"readability_score\"] = overall_readability\n",
        "        evaluation_results[\"overall_metrics\"][\"domain_terminology_score\"] = overall_terminology\n",
        "        \n",
        "        # Relevancia: podemos considerar el promedio de cobertura de subtemas\n",
        "        overall_relevance = np.mean([\n",
        "            self._calculate_subtopic_coverage(topic_content.get(\"lecture_notes\", \"\"), topic_info[\"subtopics\"])\n",
        "            for topic_id, topic_content in generated_content.items()\n",
        "            if topic_id in [t[\"id\"] for t in syllabus_data[\"topics\"]]\n",
        "        ])\n",
        "        evaluation_results[\"overall_metrics\"][\"relevance_score\"] = overall_relevance\n",
        "        \n",
        "        # Puntuación global promedio\n",
        "        content_type_avg = np.mean(list(evaluation_results[\"content_type_scores\"].values()))\n",
        "        overall_metrics_avg = np.mean(list(evaluation_results[\"overall_metrics\"].values()))\n",
        "        evaluation_results[\"average_score\"] = (content_type_avg + overall_metrics_avg) / 2\n",
        "        \n",
        "        self.logger.info(f\"Evaluación completada. Puntuación promedio: {evaluation_results['average_score']:.2f}\")\n",
        "        return evaluation_results\n",
        "\n",
        "    def _join_all_texts(self, generated_content: Dict[str, Dict[str, str]]) -> str:\n",
        "        \"\"\"Une todo el texto de todos los temas y secciones para análisis global.\"\"\"\n",
        "        texts = []\n",
        "        for topic_content in generated_content.values():\n",
        "            for text in topic_content.values():\n",
        "                texts.append(text)\n",
        "        return \"\\n\".join(texts)\n",
        "\n",
        "    def _calculate_readability(self, text: str) -> float:\n",
        "        \"\"\"\n",
        "        Calcula la legibilidad basada en la longitud promedio de las oraciones.\n",
        "        Se asume que oraciones más cortas son más fáciles de leer.\n",
        "        \"\"\"\n",
        "        sentences = sent_tokenize(text)\n",
        "        words = word_tokenize(text)\n",
        "        if not sentences:\n",
        "            return 0.0\n",
        "        avg_sentence_length = len(words) / len(sentences)\n",
        "        if avg_sentence_length <= 15:\n",
        "            return 1.0\n",
        "        elif avg_sentence_length >= 30:\n",
        "            return 0.0\n",
        "        else:\n",
        "            return (30 - avg_sentence_length) / 15\n",
        "\n",
        "    def _extract_domain_terminology(self, syllabus_data: Dict[str, Any]) -> List[str]:\n",
        "        \"\"\"\n",
        "        Extrae términos clave del syllabus usando TF-IDF o simplemente \n",
        "        combinando palabras relevantes de la descripción, objetivos, y temario.\n",
        "        \"\"\"\n",
        "        combined_text = syllabus_data.get(\"description\", \"\")\n",
        "        for obj in syllabus_data.get(\"objectives\", []):\n",
        "            combined_text += \" \" + obj\n",
        "        for topic in syllabus_data.get(\"topics\", []):\n",
        "            combined_text += \" \" + topic.get(\"title\", \"\")\n",
        "            for subtopic in topic.get(\"subtopics\", []):\n",
        "                combined_text += \" \" + subtopic\n",
        "        for bib in syllabus_data.get(\"bibliography\", []):\n",
        "            combined_text += \" \" + bib\n",
        "\n",
        "        vectorizer = TfidfVectorizer(max_features=50, stop_words='english', ngram_range=(1, 2))\n",
        "        try:\n",
        "            tfidf_matrix = vectorizer.fit_transform([combined_text])\n",
        "            feature_names = vectorizer.get_feature_names_out()\n",
        "            return list(feature_names)\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error extrayendo terminología: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _calculate_terminology_usage(self, text: str, terminology: List[str]) -> float:\n",
        "        \"\"\"Calcula la densidad de uso de la terminología específica en el contenido.\"\"\"\n",
        "        content_lower = text.lower()\n",
        "        term_count = sum(1 for term in terminology if term.lower() in content_lower)\n",
        "        word_count = len(word_tokenize(text))\n",
        "        term_density = (term_count * 1000) / word_count if word_count > 0 else 0\n",
        "        # Supongamos que 5 términos por 1000 palabras es ideal\n",
        "        return min(1.0, term_density / 5)\n",
        "\n",
        "    def _calculate_subtopic_coverage(self, content: str, subtopics: List[str]) -> float:\n",
        "        \"\"\"Calcula la proporción de subtemas cubiertos en el contenido.\"\"\"\n",
        "        content_lower = content.lower()\n",
        "        covered = 0\n",
        "        for sub in subtopics:\n",
        "            sub_terms = [w.lower() for w in word_tokenize(sub) if len(w) > 3]\n",
        "            if sub_terms and sum(1 for term in sub_terms if term in content_lower) / len(sub_terms) >= 0.5:\n",
        "                covered += 1\n",
        "        return covered / len(subtopics) if subtopics else 0\n",
        "\n",
        "    def _evaluate_lecture_notes(self, lecture_notes: str, topic_info: Dict[str, Any], course_terminology: List[str]) -> float:\n",
        "        \"\"\"Evalúa la calidad de las notas de clase combinando varias métricas.\"\"\"\n",
        "        scores = []\n",
        "        # Cobertura de subtemas\n",
        "        scores.append(self._calculate_subtopic_coverage(lecture_notes, topic_info.get(\"subtopics\", [])))\n",
        "        # Uso de terminología\n",
        "        scores.append(self._calculate_terminology_usage(lecture_notes, course_terminology))\n",
        "        # Legibilidad\n",
        "        scores.append(self._calculate_readability(lecture_notes))\n",
        "        # Estructura y organización\n",
        "        scores.append(self._evaluate_content_structure(lecture_notes))\n",
        "        # Presencia de ejemplos\n",
        "        scores.append(self._evaluate_examples_presence(lecture_notes))\n",
        "        return sum(scores) / len(scores)\n",
        "\n",
        "    def _evaluate_practice_problems(self, practice_problems: str, topic_info: Dict[str, Any]) -> float:\n",
        "        \"\"\"Evalúa la calidad de los problemas de práctica.\"\"\"\n",
        "        scores = []\n",
        "        scores.append(self._calculate_subtopic_coverage(practice_problems, topic_info.get(\"subtopics\", [])))\n",
        "        scores.append(self._evaluate_solutions_presence(practice_problems))\n",
        "        scores.append(self._evaluate_difficulty_variety(practice_problems))\n",
        "        scores.append(self._evaluate_problem_clarity(practice_problems))\n",
        "        return sum(scores) / len(scores)\n",
        "\n",
        "    def _evaluate_discussion_questions(self, discussion_questions: str, topic_info: Dict[str, Any]) -> float:\n",
        "        \"\"\"Evalúa la calidad de las preguntas para discusión.\"\"\"\n",
        "        scores = []\n",
        "        scores.append(self._calculate_subtopic_coverage(discussion_questions, topic_info.get(\"subtopics\", [])))\n",
        "        scores.append(self._evaluate_critical_thinking(discussion_questions))\n",
        "        scores.append(self._evaluate_open_ended_questions(discussion_questions))\n",
        "        return sum(scores) / len(scores)\n",
        "\n",
        "    def _evaluate_learning_objectives(self, learning_objectives: str, topic_info: Dict[str, Any]) -> float:\n",
        "        \"\"\"Evalúa la calidad de los objetivos de aprendizaje.\"\"\"\n",
        "        scores = []\n",
        "        scores.append(self._calculate_subtopic_coverage(learning_objectives, topic_info.get(\"subtopics\", [])))\n",
        "        scores.append(self._evaluate_bloom_taxonomy_usage(learning_objectives))\n",
        "        scores.append(self._evaluate_measurable_objectives(learning_objectives))\n",
        "        return sum(scores) / len(scores)\n",
        "\n",
        "    def _evaluate_suggested_resources(self, suggested_resources: str, topic_info: Dict[str, Any]) -> float:\n",
        "        \"\"\"Evalúa la calidad de los recursos sugeridos.\"\"\"\n",
        "        scores = []\n",
        "        scores.append(self._calculate_subtopic_coverage(suggested_resources, topic_info.get(\"subtopics\", [])))\n",
        "        scores.append(self._evaluate_resource_variety(suggested_resources))\n",
        "        scores.append(self._evaluate_resource_detail(suggested_resources))\n",
        "        return sum(scores) / len(scores)\n",
        "    \n",
        "    # Métodos \"stub\" o simples para completar la evaluación\n",
        "    def _evaluate_content_structure(self, text: str) -> float:\n",
        "        paragraphs = [p for p in text.split(\"\\n\\n\") if p.strip()]\n",
        "        num_paragraphs = len(paragraphs)\n",
        "        return 1.0 if num_paragraphs >= 5 else (num_paragraphs / 5.0 if num_paragraphs else 0.0)\n",
        "\n",
        "    def _evaluate_examples_presence(self, text: str) -> float:\n",
        "        return 1.0 if \"ejemplo\" in text.lower() else 0.0\n",
        "\n",
        "    def _evaluate_solutions_presence(self, text: str) -> float:\n",
        "        return 1.0 if \"solución\" in text.lower() or \"solución:\" in text.lower() else 0.0\n",
        "\n",
        "    def _evaluate_difficulty_variety(self, text: str) -> float:\n",
        "        # Este método puede analizar si se presentan problemas de distintos niveles; por ahora se devuelve un valor fijo\n",
        "        return 0.8\n",
        "\n",
        "    def _evaluate_problem_clarity(self, text: str) -> float:\n",
        "        # Un ejemplo simple: si el texto tiene muchos signos de interrogación o puntos, se asume claridad\n",
        "        return 0.8\n",
        "\n",
        "    def _evaluate_critical_thinking(self, text: str) -> float:\n",
        "        # Ejemplo simple: buscar palabras clave como \"analiza\", \"discute\", \"reflexiona\"\n",
        "        keywords = [\"analiza\", \"discute\", \"reflexiona\", \"argumenta\"]\n",
        "        count = sum(1 for kw in keywords if kw in text.lower())\n",
        "        return min(1.0, count / len(keywords))\n",
        "\n",
        "    def _evaluate_open_ended_questions(self, text: str) -> float:\n",
        "        # Considerar preguntas que no tengan respuestas cerradas (por ejemplo, que terminen en \"?\")\n",
        "        questions = [line for line in text.splitlines() if \"?\" in line]\n",
        "        if not questions:\n",
        "            return 0.0\n",
        "        # Suponiendo que más del 50% de las preguntas son abiertas es bueno\n",
        "        open_count = sum(1 for q in questions if not re.search(r'\\b(?:sí|no)\\b', q.lower()))\n",
        "        return open_count / len(questions)\n",
        "\n",
        "    def _evaluate_bloom_taxonomy_usage(self, text: str) -> float:\n",
        "        # Buscar verbos de la taxonomía de Bloom (ej. \"analiza\", \"aplica\", \"compara\")\n",
        "        bloom_verbs = [\"analiza\", \"aplica\", \"compara\", \"evalúa\", \"crea\", \"sintetiza\", \"interpreta\"]\n",
        "        count = sum(1 for verb in bloom_verbs if verb in text.lower())\n",
        "        return min(1.0, count / len(bloom_verbs))\n",
        "\n",
        "    def _evaluate_measurable_objectives(self, text: str) -> float:\n",
        "        # Verificar si se incluyen indicadores cuantificables o verbos medibles\n",
        "        return 0.8 if any(kw in text.lower() for kw in [\"porcentaje\", \"número\", \"cuantifica\"]) else 0.5\n",
        "\n",
        "    def _evaluate_resource_variety(self, text: str) -> float:\n",
        "        # Ejemplo: contar la cantidad de recursos listados\n",
        "        lines = [l for l in text.splitlines() if l.strip()]\n",
        "        return min(1.0, len(lines) / 5.0)\n",
        "\n",
        "    def _evaluate_resource_detail(self, text: str) -> float:\n",
        "        # Evaluar si cada recurso viene con una breve descripción (esto es un ejemplo simple)\n",
        "        return 0.8\n",
        "\n",
        "    def _evaluate_consistency(self, generated_content: Dict[str, Dict[str, str]]) -> float:\n",
        "        \"\"\"\n",
        "        Evalúa la consistencia semántica entre secciones usando TF-IDF y similitud de coseno.\n",
        "        Se asume que mayor similitud entre secciones relacionadas (por ejemplo, entre 'lecture_notes'\n",
        "        y 'learning_objectives') indica mayor consistencia.\n",
        "        \"\"\"\n",
        "        texts = []\n",
        "        for topic_content in generated_content.values():\n",
        "            # Concatenar todos los textos de un tema\n",
        "            combined = \" \".join(topic_content.values())\n",
        "            texts.append(combined)\n",
        "        if len(texts) < 2:\n",
        "            return 1.0  # Si solo hay un tema, no se puede evaluar consistencia entre temas\n",
        "        \n",
        "        vectorizer = TfidfVectorizer(stop_words='english')\n",
        "        tfidf = vectorizer.fit_transform(texts)\n",
        "        similarity_matrix = cosine_similarity(tfidf)\n",
        "        # Excluir la diagonal y calcular el promedio de similitud\n",
        "        n = similarity_matrix.shape[0]\n",
        "        sum_sim = np.sum(similarity_matrix) - n  # restar la diagonal\n",
        "        num_elements = n * (n - 1)\n",
        "        avg_similarity = sum_sim / num_elements if num_elements > 0 else 1.0\n",
        "        return avg_similarity\n",
        "\n",
        "\n",
        "    \n",
        "# evaluator = Evaluator(config)  # Puedes pasar una configuración si la tienes\n",
        "# evaluacion = evaluator.evaluate_content(contenido, syllabus_data)\n",
        "# print(evaluacion)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div style=\"background-color:#f8f9fa; padding:20px; border-radius:10px; margin-bottom:20px; color:#000000;\">\n",
              "                <h2 style=\"color:#0066cc;\">🎓 Asistente de Generación de Materiales Educativos</h2>\n",
              "                <p>Este asistente te ayudará a generar materiales educativos a partir del programa de un curso.</p>\n",
              "                <p>Para comenzar, sube un archivo PDF, txt o .docx con el programa del curso utilizando el widget de carga.</p>\n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd52e0e90d074ca9b5cae2f3e79fef85",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(FileUpload(value=(), accept='.pdf', description='Programa de curso:'), Button(button_style='pri…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "class InteractiveEducationalAgent:\n",
        "    \"\"\"Versión interactiva del agente educativo para Jupyter, simulando la carga de archivo.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.config = Config()\n",
        "        self.file_path = None\n",
        "        self.materials = None\n",
        "        self.evaluation = None\n",
        "        \n",
        "        # Crear los componentes interactivos\n",
        "        self._create_widgets()\n",
        "        self._display_welcome()\n",
        "    \n",
        "    def _create_widgets(self):\n",
        "        \"\"\"Crear los widgets interactivos.\"\"\"\n",
        "        # Widget para cargar el archivo PDF (aunque no se usará para el procesamiento)\n",
        "        self.upload_widget = widgets.FileUpload(\n",
        "            description='Programa de curso:',\n",
        "            accept='.pdf', \n",
        "            multiple=False\n",
        "        )\n",
        "        self.upload_widget.observe(self._handle_upload, names='value')\n",
        "        \n",
        "        # Botón para procesar el archivo\n",
        "        self.process_button = widgets.Button(\n",
        "            description='Procesar Programa',\n",
        "            disabled=True,\n",
        "            button_style='primary',\n",
        "            icon='check'\n",
        "        )\n",
        "        self.process_button.on_click(self._on_process_click)\n",
        "        \n",
        "        # Salida de estado\n",
        "        self.output = widgets.Output()\n",
        "        \n",
        "        # Barra de progreso\n",
        "        self.progress = widgets.IntProgress(\n",
        "            value=0,\n",
        "            min=0,\n",
        "            max=10,\n",
        "            description='Progreso:',\n",
        "            bar_style='info',\n",
        "            orientation='horizontal'\n",
        "        )\n",
        "    \n",
        "    def _display_welcome(self):\n",
        "        \"\"\"Mostrar la interfaz de bienvenida.\"\"\"\n",
        "        welcome_html = \"\"\"\n",
        "            <div style=\"background-color:#f8f9fa; padding:20px; border-radius:10px; margin-bottom:20px; color:#000000;\">\n",
        "                <h2 style=\"color:#0066cc;\">🎓 Asistente de Generación de Materiales Educativos</h2>\n",
        "                <p>Este asistente te ayudará a generar materiales educativos a partir del programa de un curso.</p>\n",
        "                <p>Para comenzar, sube un archivo PDF, txt o .docx con el programa del curso utilizando el widget de carga.</p>\n",
        "            </div>\n",
        "        \"\"\"\n",
        "        display(HTML(welcome_html))\n",
        "        display(widgets.VBox([self.upload_widget, self.process_button, self.progress, self.output]))\n",
        "    \n",
        "    def _handle_upload(self, change):\n",
        "        \"\"\"Manejar la carga del archivo.\"\"\"\n",
        "        if change['new']:\n",
        "            # Se obtiene el primer archivo subido\n",
        "            file_data = change['new'][0]  # Access the first element of the tuple\n",
        "            filename = file_data['name']  # Access the filename directly\n",
        "            content = file_data['content']  # Access the file content\n",
        "            \n",
        "            # Guardar el archivo localmente\n",
        "            with open(filename, 'wb') as f:\n",
        "                f.write(content)\n",
        "            \n",
        "            self.file_path = filename  # Se guarda el nombre, pero no se usará para el procesamiento real\n",
        "            self.process_button.disabled = False\n",
        "            \n",
        "            with self.output:\n",
        "                clear_output()\n",
        "                print(f\"✅ Archivo cargado: {filename}\")\n",
        "    \n",
        "    def _on_process_click(self, b):\n",
        "        \"\"\"Manejar el clic del botón de procesamiento.\"\"\"\n",
        "        if not self.file_path:\n",
        "            with self.output:\n",
        "                clear_output()\n",
        "                print(\"❌ Por favor, primero carga un archivo PDF.\")\n",
        "            return\n",
        "        \n",
        "        with self.output:\n",
        "            clear_output()\n",
        "            print(\"🚀 Iniciando procesamiento)...\\n\")\n",
        "            \n",
        "            # Inicializar componentes\n",
        "            self.progress.value = 1\n",
        "            print(\"Inicializando componentes...\")\n",
        "            llm_engine = LLMEngine(self.config)\n",
        "            self.progress.value = 2\n",
        "            generator = ContentGenerator(llm_engine, self.config)\n",
        "            self.progress.value = 3\n",
        "            processor = DocumentProcessor(self.config)\n",
        "            self.progress.value = 4\n",
        "            evaluator = Evaluator(self.config)\n",
        "            \n",
        "            # Procesar el archivo: se ignora el archivo cargado y se usa el fijo 'PROGRAMA_DE_CURSO.pdf'\n",
        "            self.progress.value = 5\n",
        "            syllabus_data =  processor.process_file(self.file_path)\n",
        "            \n",
        "            # Generar materiales\n",
        "            self.progress.value = 6\n",
        "            print(\"\\n📝 Generando materiales educativos...\")\n",
        "            self.materials = generator.generate_all_materials(syllabus_data)\n",
        "            \n",
        "            # Evaluar contenido\n",
        "            self.progress.value = 8\n",
        "            print(\"\\n🔍 Evaluando calidad del contenido...\")\n",
        "            self.evaluation = evaluator.evaluate_content(self.materials, syllabus_data)\n",
        "            \n",
        "            # Generar PDF\n",
        "            self.progress.value = 9\n",
        "            print(\"\\n📄 Generando documento PDF...\")\n",
        "            pdf_success = dict_to_pdf(self.materials, \"materiales_curso.pdf\")\n",
        "            \n",
        "            # Finalizar\n",
        "            self.progress.value = 10\n",
        "            \n",
        "            print(\"\\n✅ Proceso completado con éxito!\")\n",
        "                # display(FileLink('materiales_curso.pdf'))\n",
        "                \n",
        "                # Mostrar resumen de evaluación\n",
        "            evaluation_html = \"\"\"\n",
        "                <div style=\"background-color:#f0f7ff; padding:15px; border-radius:5px; margin-top:20px;\">\n",
        "                    <h3>📊 Resumen de evaluación</h3>\n",
        "                    <table style=\"width:100%; border-collapse: collapse;\" border=\"1\">\n",
        "                        <tr><th>Tipo de Contenido</th><th>Puntuación</th></tr>\n",
        "                \"\"\"\n",
        "\n",
        "                # Agregar filas de content_type_scores\n",
        "            for key, value in self.evaluation[\"content_type_scores\"].items():\n",
        "                    evaluation_html += f\"\"\"\n",
        "                    <tr>\n",
        "                        <td>{key.replace(\"_\", \" \").title()}</td>\n",
        "                        <td>{value * 100:.0f}%</td>\n",
        "                    </tr>\n",
        "                    \"\"\"\n",
        "\n",
        "                # Agregar métricas generales\n",
        "            evaluation_html += \"\"\"\n",
        "                    <tr><th colspan=\"2\">Métricas Generales</th></tr>\n",
        "                \"\"\"\n",
        "\n",
        "            for key, value in  self.evaluation[\"overall_metrics\"].items():\n",
        "                    evaluation_html += f\"\"\"\n",
        "                    <tr>\n",
        "                        <td>{key.replace(\"_\", \" \").title()}</td>\n",
        "                        <td>{value * 100:.0f}%</td>\n",
        "                    </tr>\n",
        "                    \"\"\"\n",
        "\n",
        "                # Agregar promedio general\n",
        "            evaluation_html += f\"\"\"\n",
        "                    <tr>\n",
        "                        <td><b>Puntuación Promedio</b></td>\n",
        "                        <td><b>{ self.evaluation[\"average_score\"] * 100:.0f}%</b></td>\n",
        "                    </tr>\n",
        "                \"\"\"\n",
        "\n",
        "            evaluation_html += \"</table></div>\"\n",
        "\n",
        "                # Mostrar HTML en Jupyter Notebook\n",
        "            display(HTML(evaluation_html))\n",
        "\n",
        "\n",
        "# Crear y mostrar el agente inte\n",
        "agent = InteractiveEducationalAgent()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
